{"id":"scribe-g6j","title":"Tech Debt Remediation Q1 2025","description":"Comprehensive tech debt remediation epic based on thorough codebase analysis. Covers:\n- Large file refactoring (10+ files over 400 lines)\n- Code duplication elimination (9 major duplication patterns)\n- Dead code removal (~40 unused exports)\n- Test coverage improvements (CLI utilities, Lexical nodes)\n- Documentation gaps (5 modules lacking docs)\n- Legacy patterns cleanup (any usage, inconsistent handler patterns)\n\n## Priority Areas\n1. content-extractor.ts (1031 lines) - highest impact refactor\n2. Duplicate content creation functions (6+ locations)\n3. CLI utilities missing tests (cli-installer.ts, input.ts)\n4. Error system consolidation (2 separate ErrorCode enums)\n\n## Refined Dependency Graph\n\n### Wave 1: Fully Parallel (No blockers - start immediately)\nThese 22 tasks can run in parallel with no dependencies:\n\n**P1 (Critical Path):**\n- g6j.1: Refactor content-extractor.ts → UNBLOCKS g6j.28\n- g6j.5: Merge CLI ErrorCode enum into shared package\n- g6j.21: Add unit tests for cli-installer.ts\n- g6j.22: Add unit tests for CLI input.ts\n\n**P1 Content Consolidation (parallel with each other):**\n- g6j.7: Consolidate createDailyContent → UNBLOCKS g6j.12, g6j.2\n- g6j.8: Consolidate createMeetingContent → UNBLOCKS g6j.12, g6j.2\n- g6j.9: Consolidate createPersonContent → UNBLOCKS g6j.12, g6j.2\n\n**P2 Independent:**\n- g6j.3: Split TableKeyboardPlugin.tsx into modules\n- g6j.6: Consolidate wrapError function\n- g6j.10: Standardize createEmptyContent\n- g6j.16: Remove deprecated LexicalState/LexicalNode\n- g6j.23-26: Unit tests (config.ts, PersonMentionNode, InlineLinkNode, tasksHandlers)\n- g6j.27: Fix skipped rollback tests\n- g6j.33: Refactor handlers to use EngineOrchestrator\n\n**P3 Dead Code Removal (fully parallel):**\n- g6j.13: Remove unused error exports\n- g6j.14: Remove unused date utility exports\n- g6j.15: Remove unused note type guards\n- g6j.17: Clean up storage-fs internal exports\n\n**P3 Documentation (fully parallel):**\n- g6j.29: JSDoc for createCLI\n- g6j.30: JSDoc for createWindow\n- g6j.31: Document magic numbers\n- g6j.34: Convert Promise .then() to async/await\n\n**P3 Hooks Refactoring:**\n- g6j.4: Extract autocomplete hooks\n- g6j.11: Consolidate desktop logger\n\n### Wave 2: After Content Consolidation (g6j.7, g6j.8, g6j.9)\n- g6j.2: Consolidate note-factory.ts patterns (needs content functions)\n- g6j.12: Migrate test helpers to @scribe/test-utils\n\n### Wave 3: After g6j.1\n- g6j.28: Document escapeMarkdownText algorithm (after refactor)\n\n### Wave 4: After g6j.12 + g6j.2\n- g6j.32: Create test utilities to eliminate `as any` casts\n\n## Closed as Already Done\n- g6j.18, g6j.19, g6j.20 (design-system primitive tests already exist)\n\n## Recommended Execution Order\n1. Start Wave 1 tasks in parallel (max parallelism)\n2. As g6j.7, g6j.8, g6j.9 complete → start g6j.2, g6j.12\n3. As g6j.1 completes → start g6j.28\n4. As g6j.12 + g6j.2 complete → start g6j.32","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-23T13:26:29.700381-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"epic"}
{"id":"scribe-g6j.1","title":"Refactor content-extractor.ts (1031 lines) into modular components","description":"Refactor content-extractor.ts (1031 lines) into modular components.\n\nThe largest file in the codebase. Converts Scribe notes (Lexical editor format) to Markdown format.\n\n**Current responsibilities (too many):**\n- Markdown escaping logic (~156 lines, lines 247-402 - `escapeMarkdownText`)\n- Block-level node conversion (headings, paragraphs, lists, tables, code)\n- Inline content extraction (text, links, mentions)\n- YAML frontmatter generation\n- Context tracking during conversion\n\n**Proposed refactor - create new files in packages/shared/src/:**\n1. `markdown-escaper.ts` - All escapeMarkdownText logic (~156 lines)\n2. `block-converters.ts` - Block-level node conversion\n3. `inline-converters.ts` - Inline content extraction\n4. `frontmatter.ts` - YAML frontmatter generation\n5. Keep `content-extractor.ts` as orchestrator (public API only, ~100 lines)\n\n**Implementation Steps:**\n1. Extract escapeMarkdownText to markdown-escaper.ts first (most isolated, lines 247-402)\n2. Extract frontmatter generation to frontmatter.ts\n3. Extract block converters (maintains internal helper functions)\n4. Extract inline converters\n5. Update content-extractor.ts to import and orchestrate\n6. Ensure all tests pass: `bun test packages/shared`\n7. Update package exports in packages/shared/src/index.ts if needed\n\n**Key files:**\n- packages/shared/src/content-extractor.ts (source)\n- packages/shared/src/content-extractor.test.ts (verify with existing tests)\n\n**Parallel safe:** No dependencies on other tasks.\n\n**UNBLOCKS:** scribe-g6j.28 (documentation of escapeMarkdownText algorithm)\n\nFiles: packages/shared/src/content-extractor.ts, packages/shared/src/markdown-escaper.ts (NEW), packages/shared/src/block-converters.ts (NEW), packages/shared/src/inline-converters.ts (NEW), packages/shared/src/frontmatter.ts (NEW)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T13:26:29.775576-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.10","title":"Standardize createEmptyContent across packages","description":"Standardize createEmptyContent across packages.\n\nThree different createEmptyContent implementations with structural differences:\n\n**Shared (packages/shared/src/content.ts, lines 17-36):** ✓ CANONICAL\n- Returns root with empty paragraph including format, indent, direction, version properties\n- Already exported from @scribe/shared\n\n**CLI (apps/cli/src/node-builder.ts, lines 149-159):** DIFFERENT STRUCTURE\n- Returns root with empty children array (no paragraph)\n- Inconsistent with shared package\n\n**Test-utils (packages/test-utils/src/note-factory.ts, lines 113-120):**\n- Returns root with empty children array\n- Re-exports from @scribe/shared in index.ts\n\n**Implementation Steps:**\n1. Verify shared createEmptyContent is the correct structure (with empty paragraph)\n2. Update CLI `apps/cli/src/node-builder.ts` to import from @scribe/shared instead of defining locally\n3. Remove local createEmptyContent from node-builder.ts\n4. Verify test-utils already re-exports from shared (it does in index.ts, but has local copy in note-factory.ts)\n5. Remove duplicate from note-factory.ts, use import from shared\n6. Run `bun test apps/cli` and `bun test packages/test-utils` to verify\n\n**Parallel safe:** No dependencies on other tasks. Can run in parallel with g6j.7, g6j.8, g6j.9.\n\nFiles: packages/shared/src/content.ts, apps/cli/src/node-builder.ts, packages/test-utils/src/note-factory.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:30.497212-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.11","title":"Consolidate desktop logger to extend shared logger","description":"Two separate logger systems with different APIs:\n\nShared (packages/shared/src/logger.ts, 265 lines):\n- Full-featured with child loggers and structured context\n- Uses LOG_LEVEL environment variable\n- API: log.debug('message', { key: value })\n\nDesktop (apps/desktop/electron/main/src/logger.ts, 125 lines):\n- Simpler logger with pre-configured contexts\n- Different API: log.debug('message', value1, value2)\n- Different output format\n\nSolution: Desktop logger should extend or use the shared logger for consistency. This ensures logging behavior is uniform across CLI and desktop.\n\nFiles: apps/desktop/electron/main/src/logger.ts, packages/shared/src/logger.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:30.580902-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.12","title":"Migrate test helpers to @scribe/test-utils package","description":"Migrate test helper code from desktop to @scribe/test-utils package.\n\n**BLOCKED BY:** scribe-g6j.7, scribe-g6j.8, scribe-g6j.9 (content function consolidation must complete first)\n\nDesktop (apps/desktop/test-helpers.ts):\n- setupTestContext, cleanupTestContext (lines 54-94)\n- createNoteContent, createNoteWithTitle, createAndIndexNote (lines 163-396)\n- createPersonContent, createDailyContent, createMeetingContent re-exports\n\nTest-utils (packages/test-utils/):\n- vault-factory.ts: createTestVault, cleanupTestVault (lines 76-182)\n- note-factory.ts: createTestNote, createMockNote, createGraphTestNote (lines 343-576)\n\n**Implementation Steps:**\n1. Wait for content function consolidation (g6j.7, g6j.8, g6j.9) to complete\n2. Import consolidated content functions into test-utils from @scribe/shared or templates\n3. Move desktop test helpers that create content to use shared imports\n4. Migrate commonly-used helpers from desktop/test-helpers.ts to @scribe/test-utils\n5. Update desktop integration tests to use @scribe/test-utils\n6. Run all integration tests to verify migration: `bun test apps/desktop`\n\n**UNBLOCKS:** scribe-g6j.32 (test utilities for `as any` elimination)\n\nFiles: apps/desktop/test-helpers.ts, packages/test-utils/src/vault-factory.ts, packages/test-utils/src/note-factory.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:30.660177-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.13","title":"Remove unused error type exports (SyncConflictError, MigrationError, etc)","description":"Unused error type exports in packages/shared/src/errors.ts:\n\nNever imported outside test files or exports:\n- SyncConflictError, isSyncConflictError (lines 362-370, 437-439)\n- MigrationError, isMigrationError (lines 375-383, 444-446)\n- TaskNotFoundError, isTaskNotFoundError (lines 352-357, 430-432)\n- isFileSystemError (lines 395-397) - only test file\n- isNoteError (lines 402-404) - only test file\n- isVaultError (lines 409-411) - never imported\n- isEngineError (lines 416-418) - never imported\n- isValidationError (lines 423-425) - only test file\n- getErrorMessageWithContext (lines 506-513) - only test file\n- FileSystemError, NoteError, VaultError, EngineError classes - never imported from package\n\nOptions:\n1. Remove unused exports from barrel\n2. Mark as internal-only\n3. Document as future API\n\nFiles: packages/shared/src/errors.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:30.743631-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.14","title":"Remove unused date utility exports (formatDateMMDDYYYY, startOfDay, etc)","description":"Unused date utility exports in packages/shared/src/date-utils.ts:\n\nNever imported anywhere:\n- formatDateMMDDYYYY (lines 108-117)\n- parseDateMMDDYYYY (lines 271-285)\n- startOfDay (lines 409-418)\n- endOfDay (lines 429-438)\n- getDaysBetween (lines 379-394)\n\nThese may be useful future APIs but are currently dead code.\n\nOptions:\n1. Remove from barrel export, keep in file for future use\n2. Remove entirely if not planned\n3. Document as available utilities\n\nFiles: packages/shared/src/date-utils.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:30.829382-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.15","title":"Remove unused note type guards (isRegularNote, isProjectNote, etc)","description":"Unused note type guards in packages/shared/src/types/note-types.ts:\n\nNever imported outside the file:\n- isRegularNote (lines 472-474)\n- isProjectNote (lines 516-518)\n- isTemplateNote (lines 538-540)\n- isSystemNote (lines 561-563)\n\nThese type guards are exported but never used in the codebase.\n\nOptions:\n1. Remove from exports if truly unused\n2. Keep if planned for future discriminated union handling\n3. Document intended usage\n\nFiles: packages/shared/src/types/note-types.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:30.916949-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.16","title":"Remove deprecated LexicalState and LexicalNode type aliases","description":"Deprecated type aliases still in codebase (packages/shared/src/types/editor-types.ts):\n\n- LexicalState (line 97) - @deprecated, use EditorContent\n- LexicalNode (line 102) - @deprecated, use EditorNode\n\nThese are marked deprecated but still exported. No imports found outside exports.\n\nSolution:\n1. Search for any remaining usages\n2. Remove the deprecated aliases\n3. Update any remaining code to use EditorContent/EditorNode\n\nFiles: packages/shared/src/types/editor-types.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.00205-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.17","title":"Clean up storage-fs internal exports (NoteValidator, AtomicFileWriter, etc)","description":"Internal utilities exported publicly from storage-fs (packages/storage-fs/src/index.ts):\n\nExported but only used internally or in tests:\n- NoteValidator, INoteValidator, ValidationResult (lines 10-14)\n- AtomicFileWriter, IAtomicFileWriter, AtomicWriteOptions (lines 16-20)\n- NoteMigrator, INoteMigrator, NOTE_FORMAT_VERSION (lines 22-26)\n- QuarantineManager, createQuarantineManager, IQuarantineManager (lines 27-31)\n\nThese are implementation details, not public API. QuarantineManager is accessed via vault method.\n\nSolution: Make these internal-only, remove from barrel export. If external testing needs access, expose via test-utils package instead.\n\nFiles: packages/storage-fs/src/index.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:31.093468-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.18","title":"Add unit tests for design-system Button primitive","description":"Design system Button primitive has no unit tests.\n\nFile: packages/design-system/src/primitives/Button/Button.tsx\n\nCurrent coverage: 0%\nPackage coverage: 17% overall\n\nTests needed:\n- Render with different variants\n- Click handler invocation\n- Disabled state\n- Loading state (if applicable)\n- Accessibility attributes\n\nFiles: packages/design-system/src/primitives/Button/Button.tsx","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.181248-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.19","title":"Add unit tests for design-system Calendar primitive","description":"Design system Calendar primitive has no unit tests.\n\nFile: packages/design-system/src/primitives/Calendar/Calendar.tsx\n\nCurrent coverage: 0%\nPackage coverage: 17% overall\n\nTests needed:\n- Date selection\n- Month navigation\n- Disabled dates\n- Date range handling\n- Keyboard navigation\n- Accessibility\n\nFiles: packages/design-system/src/primitives/Calendar/Calendar.tsx","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.268078-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.2","title":"Consolidate duplicate note-factory.ts patterns (619 lines)","description":"Consolidate duplicate note-factory.ts patterns (619 lines).\n\nThe note-factory.ts file has 619 lines with significant code duplication between factory functions.\n\n**Duplication pattern:** createTestNote, createMockNote, createGraphTestNote, and createContentTestNote all have nearly identical switch statements for handling note types (daily, meeting, person, etc.).\n\n**Content helpers (lines 109-291):** Should move to separate content-factory.ts or use imports from consolidated content functions (g6j.7, g6j.8, g6j.9).\n\n**BLOCKED BY:** Should wait for g6j.7, g6j.8, g6j.9 to complete so content functions are consolidated first.\n\n**Implementation Steps:**\n1. Wait for content consolidation tasks (g6j.7, g6j.8, g6j.9) to complete\n2. Import createDailyContent, createMeetingContent, createPersonContent from canonical sources\n3. Remove duplicate content creation logic from note-factory.ts\n4. Create a single base factory function with builder pattern\n5. Reduce 4 factory functions to 1 configurable factory OR keep named exports but share implementation\n6. Run `bun test packages/test-utils` to verify\n\n**UNBLOCKS:** scribe-g6j.32 (test utilities for `as any` elimination)\n\nFiles: packages/test-utils/src/note-factory.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:29.851436-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.20","title":"Add unit tests for design-system FloatingMenu primitive","description":"Design system FloatingMenu primitive has no unit tests.\n\nFile: packages/design-system/src/primitives/FloatingMenu/FloatingMenu.tsx (307 lines)\n\nCurrent coverage: 0%\nPackage coverage: 17% overall\n\nThis is one of the larger primitives. Tests needed:\n- Positioning calculations\n- Show/hide behavior\n- Keyboard navigation\n- Click outside handling\n- Anchor element tracking\n\nFiles: packages/design-system/src/primitives/FloatingMenu/FloatingMenu.tsx","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.354317-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.21","title":"Add unit tests for cli-installer.ts (312 lines, complex symlink logic)","description":"Add unit tests for cli-installer.ts (311 lines, complex symlink logic).\n\nFile: apps/desktop/electron/main/src/cli-installer.ts\n\nComplex logic includes:\n- Symlink creation and verification\n- PATH configuration detection (bash, zsh, fish)\n- Existing file handling (overwrite, skip)\n- Error recovery scenarios\n- Multiple file system operations\n- Cross-platform considerations (Darwin)\n\n**Tests needed:**\n- Test symlink creation success/failure\n- Test PATH detection for different shells (~/.zshrc, ~/.bashrc, ~/.config/fish/config.fish)\n- Test existing file handling (overwrite, skip, backup)\n- Mock filesystem operations for isolation\n- Error scenario coverage (permission denied, file exists, etc.)\n- Test uninstall/cleanup logic\n\n**Implementation approach:**\n1. Create `apps/desktop/electron/main/src/cli-installer.test.ts`\n2. Mock `fs` module for file system operations\n3. Mock `child_process` for shell detection\n4. Test each public function in isolation\n5. Test integration scenarios\n\nThis is HIGH PRIORITY - complex logic with file system side effects.\n\n**Parallel safe:** No dependencies on other tasks.\n\nFiles: apps/desktop/electron/main/src/cli-installer.ts, apps/desktop/electron/main/src/cli-installer.test.ts (NEW)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T13:26:31.439187-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.22","title":"Add unit tests for CLI input.ts (stdin/file reading)","description":"CLI input.ts (154 lines) has no tests for stdin/file reading logic.\n\nFile: apps/cli/src/input.ts\n\nComplex logic includes:\n- stdin reading with size limits\n- File input handling\n- Escape sequence processing\n- Error handling for edge cases\n\nTests needed:\n- Test stdin reading\n- Test file reading\n- Test escape sequence processing\n- Test size limit enforcement\n- Test error handling\n\nThis is HIGH PRIORITY - input handling is critical for CLI reliability.\n\n**Parallel safe:** No dependencies on other tasks.\n\nFiles: apps/cli/src/input.ts","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T13:26:31.516639-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.23","title":"Add unit tests for CLI config.ts","description":"CLI config.ts (50 lines) has no tests.\n\nFile: apps/cli/src/config.ts\n\nLogic includes:\n- Configuration file loading\n- JSON parsing error handling\n- Missing config file handling\n\nTests needed:\n- Test config loading success\n- Test malformed JSON handling\n- Test missing config file behavior\n- Test default values\n\n**Parallel safe:** No dependencies on other tasks.\n\nFiles: apps/cli/src/config.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.596928-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.24","title":"Add unit tests for PersonMentionNode.ts","description":"PersonMentionNode.ts (183 lines) is a Lexical decorator node with no tests.\n\nFile: apps/desktop/renderer/src/components/Editor/plugins/PersonMentionNode.ts\n\nComplex logic includes:\n- Serialization/deserialization\n- Clone operation\n- DOM creation\n- Click handling and navigation\n\nTests needed:\n- Test serialization to JSON\n- Test deserialization from JSON\n- Test clone produces correct copy\n- Test DOM output structure\n- Test click handler navigation\n\nFiles: apps/desktop/renderer/src/components/Editor/plugins/PersonMentionNode.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.673279-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.25","title":"Add unit tests for InlineLinkNode.ts","description":"InlineLinkNode.ts has no tests.\n\nFile: apps/desktop/renderer/src/components/Editor/plugins/InlineLinkNode.ts\n\nHandles external link rendering and URL validation.\n\nTests needed:\n- Test URL validation\n- Test rendering output\n- Test serialization/deserialization\n- Test link click behavior\n\nFiles: apps/desktop/renderer/src/components/Editor/plugins/InlineLinkNode.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.746966-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.26","title":"Add unit tests for tasksHandlers.ts toggleChecklistNode logic","description":"tasksHandlers.ts has integration tests but lacks unit tests for the toggleChecklistNode logic.\n\nFile: apps/desktop/electron/main/src/handlers/tasksHandlers.ts\n\nThe toggleChecklistNode function has complex fallback logic for finding and toggling task nodes in the editor state. This deserves isolated unit testing.\n\nTests needed:\n- Test finding checklist node by various identifiers\n- Test toggle behavior (checked -\u003e unchecked, unchecked -\u003e checked)\n- Test fallback logic when node not found\n- Test error handling\n\nFiles: apps/desktop/electron/main/src/handlers/tasksHandlers.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.824093-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.27","title":"Fix skipped rollback tests in useNoteState.test.ts","description":"Two tests are skipped in useNoteState.test.ts indicating incomplete rollback functionality.\n\nFile: apps/desktop/renderer/src/hooks/useNoteState.test.ts\n\nSkipped tests (lines 473-527):\n1. 'rolls back on save failure (success: false)' (line 475)\n2. 'rolls back on save exception' (line 501)\n\nComment: \"TODO: Fix rollback tests - they have timing issues with hook's ref-based rollback mechanism\"\n\nThis indicates:\n- Rollback functionality may not work correctly\n- Tests have timing issues with ref-based mechanism\n- Technical debt in both implementation and tests\n\nSolution: Fix the underlying rollback implementation, then unskip tests.\n\nFiles: apps/desktop/renderer/src/hooks/useNoteState.test.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.901162-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.28","title":"Document escapeMarkdownText algorithm in content-extractor.ts","description":"Document escapeMarkdownText algorithm in markdown-escaper.ts.\n\n**BLOCKED BY:** scribe-g6j.1 (refactor content-extractor first - this function will move to markdown-escaper.ts)\n\nThe escapeMarkdownText function (~156 lines, currently lines 247-402) is complex pattern matching without algorithmic documentation.\n\n**Current state:** No high-level comment explaining the algorithm approach, the state machine used for tracking line starts, emphasis characters, etc.\n\nThe function handles:\n- Detecting emphasis patterns (*bold*, _italic_, **strong**, __strong__)\n- Tracking line state (isAtLineStart for # \u003e - + * escaping)\n- Complex character escaping rules for Markdown special chars\n- Table context handling (pipe escaping)\n- Ordered list detection (1. 2. etc.)\n- Link bracket escaping\n\n**Implementation Steps:**\n1. Wait for g6j.1 to complete (function will move to markdown-escaper.ts)\n2. Add JSDoc block comment at function start explaining:\n   - Overall algorithm approach (character-by-character state machine)\n   - State tracking: isAtLineStart, context.isInTable\n   - Key decision points for escaping\n   - Edge cases handled (nested emphasis, line boundaries, mid-word patterns)\n3. Add inline comments for non-obvious patterns\n4. Consider adding ASCII diagrams for complex logic\n\nFiles: packages/shared/src/markdown-escaper.ts (after g6j.1)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:31.984868-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.29","title":"Add JSDoc to createCLI function in cli.ts","description":"The createCLI function in cli.ts lacks JSDoc documentation.\n\nFile: apps/cli/src/cli.ts\n\nMissing documentation for:\n- Function purpose\n- Return value (Command object)\n- Available global options\n- Subcommand organization\n- How to extend the CLI\n\nExample JSDoc needed:\n```typescript\n/**\n * Creates and configures the Scribe CLI application.\n * \n * @returns Configured Commander.js Command instance\n * \n * @example\n * const cli = createCLI();\n * cli.parseAsync(process.argv);\n */\n```\n\nFiles: apps/cli/src/cli.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:32.067917-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.3","title":"Split TableKeyboardPlugin.tsx into table utility modules","description":"TableKeyboardPlugin.tsx is 515 lines with ~15 internal helper functions for table manipulation.\n\nCurrent structure: All helper functions are internal but could be extracted:\n- tableSelectionUtils.ts - Selection-related helpers ($isSelectionInTable, $getTableCellFromSelection, etc.)\n- tableNavigationUtils.ts - Navigation helpers ($isFirstCellInTable, $isLastCellInTable, $exitTableBefore/After)\n- TableKeyboardPlugin.tsx - Just the React component registering commands\n\nBenefits: Reduces cognitive load when debugging table issues, enables reuse of table utilities.\n\nFiles: apps/desktop/renderer/src/components/Editor/plugins/TableKeyboardPlugin.tsx","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:29.926283-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.30","title":"Add JSDoc to createWindow function in main.ts","description":"The createWindow function in main.ts (lines 107-192) is 85 lines with no JSDoc.\n\nFile: apps/desktop/electron/main/src/main.ts\n\nComplex configuration includes:\n- Window dimensions and bounds\n- Preload script path\n- Web preferences (security settings)\n- Context menu setup\n- State restoration\n\nMissing documentation for:\n- Security settings rationale\n- Window configuration choices\n- Context menu behavior\n- State persistence\n\nFiles: apps/desktop/electron/main/src/main.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:32.149659-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.31","title":"Document magic numbers in fuzzy-search.ts and hash-utils.ts","description":"Magic numbers in fuzzy-search.ts and hash-utils.ts lack rationale documentation.\n\nfuzzy-search.ts:\n- FUZZY_MATCH_THRESHOLD = 0.3 (why 0.3?)\n- SUBSTRING_MATCH_BASE = 0.9 (why 0.9?)\n- ALL_WORDS_MATCH_SCORE = 0.85 (why 0.85?)\n\nhash-utils.ts:\n- DJB2_HASH_INITIAL = 5381 (why 5381?)\n- DJB2_HASH_MULTIPLIER = 33 (why 33?)\n- TEXT_HASH_LENGTH = 16 (why 16?)\n\nAdd inline comments explaining:\n- Why these specific values were chosen\n- What user testing/research informed the fuzzy search thresholds\n- That 5381 is a prime for good hash distribution\n- That 33 is traditional in DJB2 algorithm\n\nFiles: packages/shared/src/fuzzy-search.ts, packages/shared/src/hash-utils.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:32.232644-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.32","title":"Create test utilities to eliminate as any casts in integration tests","description":"Create test utilities to eliminate `as any` casts in integration tests.\n\n**BLOCKED BY:** scribe-g6j.12, scribe-g6j.2 (test infrastructure must be consolidated first)\n\nHigh-priority files with `as any` casts:\n- templates.integration.test.ts (lines 372, 509-510, 522) - child nodes\n- linked-notes.integration.test.ts (lines 145, 333, 648, 688, 789, 860) - paragraph content\n- date-based-mentions.integration.test.ts (lines 226-227, 593-594, 682-683) - timestamp overrides\n- delete-note.integration.test.ts (lines 420, 471) - test data\n- meeting.test.ts (lines 9, 17-18, 26-31, 42) - content types\n\n**Common patterns requiring utilities:**\n1. Timestamp overrides for deterministic testing\n2. Content type coercion for factory functions\n3. Child node access in editor content\n\n**Implementation Steps:**\n1. Wait for g6j.12 (test helpers migration) and g6j.2 (note-factory consolidation)\n2. Add to @scribe/test-utils:\n   - `function createTestNoteWithOverrides\u003cT extends Note\u003e(base: Partial\u003cT\u003e): T`\n   - `function withTimestamp\u003cT\u003e(obj: T, timestamp: number): T \u0026 { createdAt: number; updatedAt: number }`\n   - Generic content builders with proper typing\n3. Update integration tests to use new utilities\n4. Run linter to verify no new `as any` casts remain\n\nFiles: apps/desktop/test-helpers.ts, packages/test-utils/src/note-factory.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:32.311068-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.33","title":"Refactor handlers to use EngineOrchestrator consistently","description":"IPC handlers use inconsistent patterns for accessing engines.\n\nPattern A - Direct vault access (read-only):\n```typescript\nipcMain.handle('notes:list', async () =\u003e {\n  const vault = requireVault(deps);\n  return vault.list();\n});\n```\n\nPattern B - Using withEngines helper (write operations):\n```typescript\nipcMain.handle('notes:save', withEngines(deps, async (engines, note) =\u003e {...}));\n```\n\nThe EngineOrchestrator (apps/desktop/electron/main/src/EngineOrchestrator.ts) exists but isn't used consistently in all handlers.\n\nSolution:\n1. Document the intentional difference between patterns in code comments\n2. Refactor write operations to use EngineOrchestrator consistently\n3. Add CONTRIBUTING.md documentation for when to use each pattern\n\nFiles: apps/desktop/electron/main/src/handlers/notesHandlers.ts, apps/desktop/electron/main/src/EngineOrchestrator.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:32.38807-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.34","title":"Convert remaining Promise .then()/.catch() to async/await","description":"Legacy Promise .then()/.catch() patterns should be converted to async/await.\n\nLocations:\n1. packages/engine-core/src/task-index.ts line 206:\n   this.persist().catch((err) =\u003e {...})\n\n2. packages/test-utils/src/vault-factory.ts lines 98, 179:\n   .catch(() =\u003e {}) for cleanup\n\n3. apps/cli/src/index.ts line 16:\n   cli.parseAsync(process.argv).catch(...)\n\n4. apps/desktop/electron/main/src/main.ts line 194:\n   app.whenReady().then(async () =\u003e {...})\n\nThe app.whenReady().then() is borderline acceptable for entry point code, but the others should use try/catch with async/await for consistency.\n\nFiles: packages/engine-core/src/task-index.ts, apps/desktop/electron/main/src/main.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:32.461623-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.4","title":"Extract autocomplete hooks into separate files","description":"useTriggerableAutocomplete.ts is 498 lines with three hooks in one file:\n1. useTriggerableAutocomplete - Main hook for wiki-links [[  and mentions @\n2. useAutocompleteKeyboardNavigation - Keyboard navigation\n3. useClickOutside - Generic click outside detection\n\nProposed split:\n- useTriggerableAutocomplete.ts - Main hook only\n- useAutocompleteKeyboard.ts - Keyboard navigation hook\n- useClickOutside.ts - Generic reusable click outside hook\n\nThe useClickOutside hook is generic and could be reused elsewhere in the codebase.\n\nFiles: apps/desktop/renderer/src/components/Editor/hooks/useTriggerableAutocomplete.ts","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T13:26:30.000154-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.5","title":"Merge CLI ErrorCode enum into shared package","description":"Merge CLI ErrorCode enum into shared package.\n\nTwo separate ErrorCode enums exist with overlapping codes:\n\n**CLI (apps/cli/src/errors.ts) - 7 codes:**\n- INTERNAL_ERROR, VAULT_NOT_FOUND, NOTE_NOT_FOUND\n- INVALID_INPUT, WRITE_FAILED, PERMISSION_DENIED, HAS_BACKLINKS\n\n**Shared (packages/shared/src/errors.ts) - 20+ codes:**\n- FILE_NOT_FOUND, FILE_READ_ERROR, FILE_WRITE_ERROR...\n- NOTE_NOT_FOUND (duplicate!), INVALID_NOTE_FORMAT, NOTE_CORRUPT\n- VAULT_NOT_INITIALIZED, VALIDATION_ERROR, etc.\n\n**Implementation Steps:**\n1. Add CLI-specific codes to shared ErrorCode enum:\n   - INTERNAL_ERROR (if not present)\n   - HAS_BACKLINKS\n   - VAULT_NOT_FOUND (map to VAULT_NOT_INITIALIZED or add)\n2. Update CLI to import ErrorCode from @scribe/shared\n3. CLIError can extend ScribeError or use shared codes\n4. Update EXIT_CODES mapping in CLI to use shared codes\n5. Remove duplicate enum from apps/cli/src/errors.ts\n6. Run `bun test apps/cli` to verify\n\n**Parallel safe:** No dependencies on other tasks.\n\nFiles: apps/cli/src/errors.ts, packages/shared/src/errors.ts","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T13:26:30.076838-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.6","title":"Consolidate wrapError function into shared handler utilities","description":"Consolidate wrapError function into shared handler utilities.\n\nIdentical wrapError function duplicated in two handler files:\n\n**notesHandlers.ts (lines 52-59):**\n```typescript\nfunction wrapError(error: unknown): never {\n  if (error instanceof ScribeError) {\n    const userError = new Error(error.getUserMessage());\n    userError.name = error.code;\n    throw userError;\n  }\n  throw error;\n}\n```\n\n**peopleHandlers.ts (lines 43-50):** Identical implementation\n\n**Implementation Steps:**\n1. Add wrapError to `apps/desktop/electron/main/src/handlers/types.ts`\n2. Export from types.ts alongside requireVault, withEngines, etc.\n3. Update notesHandlers.ts to import wrapError from './types'\n4. Update peopleHandlers.ts to import wrapError from './types'\n5. Remove local wrapError definitions\n6. Search for other handlers that might benefit (meetingHandlers, dailyHandlers)\n7. Run `bun test apps/desktop` to verify\n\n**Parallel safe:** No dependencies on other tasks.\n\nFiles: apps/desktop/electron/main/src/handlers/notesHandlers.ts, apps/desktop/electron/main/src/handlers/peopleHandlers.ts, apps/desktop/electron/main/src/handlers/types.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:30.15794-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.7","title":"Consolidate createDailyContent into single source of truth","description":"Consolidate createDailyContent into single source of truth.\n\ncreateDailyContent function is duplicated in 6+ locations with identical logic:\n\n1. `apps/desktop/renderer/src/templates/daily.ts` (lines 10-40) - **Canonical source (already exists!)**\n2. `apps/desktop/electron/main/src/handlers/dailyHandlers.ts` (lines 51-81) - DUPLICATE\n3. `apps/desktop/daily-handlers.integration.test.ts` (lines 31-68) - DUPLICATE\n4. `apps/desktop/meeting-handlers.integration.test.ts` (lines 34-67) - DUPLICATE\n5. `apps/desktop/date-based-meeting.integration.test.ts` (lines 30-63) - DUPLICATE\n6. `apps/desktop/templates.integration.test.ts` (lines 37-72) - DUPLICATE\n\n**Key insight:** The canonical source already exists at `apps/desktop/renderer/src/templates/daily.ts` and is exported!\n\n**Implementation Steps:**\n1. Update `dailyHandlers.ts` to import createDailyContent from `../../renderer/src/templates/daily.ts`\n2. Remove local createDailyContent definition from dailyHandlers.ts (keep the export)\n3. Update integration tests to import from canonical source OR use test-helpers\n4. Add re-export to test-helpers.ts: `export { createDailyContent } from './renderer/src/templates/daily';`\n5. Update test imports to use test-helpers\n6. Run `bun test apps/desktop` to verify all tests pass\n\n**Parallel safe:** Runs in parallel with g6j.8 and g6j.9.\n\n**UNBLOCKS:** scribe-g6j.12 (test helpers migration)\n\nFiles: apps/desktop/renderer/src/templates/daily.ts, apps/desktop/electron/main/src/handlers/dailyHandlers.ts","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T13:26:30.239801-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.8","title":"Consolidate createMeetingContent into single source of truth","description":"Consolidate createMeetingContent into single source of truth.\n\ncreateMeetingContent function duplicated in 5+ locations:\n\n1. `apps/desktop/renderer/src/templates/meeting.ts` (lines 52-70) - **Canonical source (already exists!)**\n2. `apps/desktop/electron/main/src/handlers/meetingHandlers.ts` (lines 54-104) - DUPLICATE\n3. `apps/desktop/meeting-handlers.integration.test.ts` (lines 69-103) - DUPLICATE\n4. `apps/desktop/date-based-meeting.integration.test.ts` (lines 65-100) - DUPLICATE\n5. `apps/desktop/templates.integration.test.ts` (lines 73-108) - DUPLICATE\n\n**Key insight:** The canonical source already exists at `apps/desktop/renderer/src/templates/meeting.ts`!\n\n**Implementation Steps:**\n1. Update `meetingHandlers.ts` to import createMeetingContent from `../../renderer/src/templates/meeting.ts`\n2. Remove local createMeetingContent definition from meetingHandlers.ts\n3. Add re-export to test-helpers.ts: `export { createMeetingContent } from './renderer/src/templates/meeting';`\n4. Update test imports to use test-helpers\n5. Run `bun test apps/desktop` to verify all tests pass\n\n**Parallel safe:** Runs in parallel with g6j.7 and g6j.9.\n\n**UNBLOCKS:** scribe-g6j.12 (test helpers migration)\n\nFiles: apps/desktop/renderer/src/templates/meeting.ts, apps/desktop/electron/main/src/handlers/meetingHandlers.ts","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T13:26:30.325653-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-g6j.9","title":"Consolidate createPersonContent into single source of truth","description":"Consolidate createPersonContent into single source of truth.\n\n**IMPORTANT:** No person template file exists yet! This task should CREATE the canonical source.\n\nCurrent locations:\n1. apps/desktop/test-helpers.ts (lines 237-255) - Used by tests\n2. apps/desktop/electron/main/src/handlers/peopleHandlers.ts (lines 63-92) - Used at runtime\n3. apps/desktop/people-handlers.integration.test.ts (as createPersonContentInternal, lines 34-56)\n\n**Implementation Steps:**\n1. Create `apps/desktop/renderer/src/templates/person.ts` (canonical source like daily.ts/meeting.ts)\n2. Export `createPersonContent(name: string): EditorContent \u0026 { type: 'person' }`\n3. Add to `apps/desktop/renderer/src/templates/index.ts` exports\n4. Update `peopleHandlers.ts` to import from templates/person.ts\n5. Update `test-helpers.ts` to re-export from templates/person.ts\n6. Remove createPersonContentInternal from integration tests, use canonical import\n7. Run `bun test apps/desktop` to verify all tests pass\n\n**Parallel safe:** Runs in parallel with g6j.7 and g6j.8.\n\n**UNBLOCKS:** scribe-g6j.12 (test helpers migration)\n\nFiles: apps/desktop/renderer/src/templates/person.ts (NEW), apps/desktop/electron/main/src/handlers/peopleHandlers.ts, apps/desktop/test-helpers.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T13:26:30.409757-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-hao","title":"Sync Engine: Multi-Device Synchronization with Offline-First Support","description":"# Sync Engine Epic (GitHub Issue #54)\n\n## Executive Summary\n\nDesign and implement a sync engine for Scribe, enabling multi-device synchronization with offline-first support. This lays the groundwork for a future mobile client.\n\n---\n\n## Strategic Goals\n\n### Primary Goals\n1. **Offline-first**: Users can edit notes without connectivity; changes sync when back online\n2. **Multi-device**: Same vault accessible from desktop (now) and mobile (future)\n3. **Real-time**: Changes propagate quickly when online (polling every 30s for v1)\n4. **Conflict handling**: Concurrent edits to the same note don't lose data\n5. **Opt-in \u0026 disableable**: Sync MUST be disabled by default and easily toggled off\n6. **Data ownership**: Architecture should support future self-hosting option\n\n### Why This Matters for Scribe\n- Users expect their notes to be available everywhere\n- Mobile is the most requested feature - sync is the foundation\n- Offline-first respects user autonomy and works in any network condition\n- Enterprise/corporate users need explicit opt-in for data governance\n\n---\n\n## Architectural Decisions (Pre-Made)\n\n### 1. Sync Model\n- **Client-server** topology with central server as source of truth\n- **Document-level sync** (v1): Each note syncs as a whole JSON blob\n- **Optimistic concurrency**: baseVersion comparison for conflict detection\n\n### 2. Versioning Scheme\nTwo-tier versioning:\n- `note.sync.version`: Per-note monotonic counter for conflict detection\n- `serverSequence`: Global server sequence for efficient pull (\"give me changes since X\")\n\n### 3. Storage Locations\n- **Sync Database**: `{vault}/derived/sync.sqlite3` (follows derived data pattern)\n- **Sync Config**: `{vault}/.scribe/sync.json` (vault-level, not app-level)\n- **Package**: `packages/engine-sync/` (follows engine-* naming convention)\n\n### 4. Authentication (v1)\n- Simple API key with PBKDF2 hash\n- Workers-compatible (no bcrypt native bindings)\n- OAuth can be added later as alternative login method\n\n### 5. Infrastructure\n- Cloudflare Workers + D1 (SQLite at edge) + KV (session cache)\n- R2 for future blob storage (attachments/images)\n\n### 6. Tasks Handling\n- Tasks (`vault/derived/tasks.jsonl`) are NOT synced\n- Re-derived on each device from synced notes via TaskIndex\n- Avoids data duplication and consistency issues\n\n### 7. Conflict Resolution\n- Store conflicts for user resolution (no auto-merge in v1)\n- Three options: Keep Mine, Keep Theirs, Keep Both\n- Side-by-side comparison view (read-only)\n- Delete vs Edit conflicts handled specially\n\n### 8. Tombstone TTL\n- 90 days for deleted notes\n- Notes deleted while a device is offline \u003e90 days will reappear as \"restored\"\n- Acceptable tradeoff, documented in UI\n\n---\n\n## Integration Points\n\n### Existing Systems to Extend\n1. **BaseNote interface**: Add `sync?: SyncMetadata` field\n2. **EngineOrchestrator**: Add syncEngine integration, queue changes after save\n3. **HandlerDependencies**: Add `syncEngine: SyncEngine | null`\n4. **IPC Contract**: Add sync channels and SyncAPI interface\n5. **EngineName type**: Add 'sync' to the union\n6. **ErrorCode enum**: Add sync-specific error codes\n\n### New Systems to Create\n1. **packages/engine-sync/**: Client-side sync engine\n2. **apps/sync-server/**: Cloudflare Workers server\n3. **Sync UI components**: Status indicator, conflict modal, settings panel\n\n---\n\n## v1 Scope\n\n### INCLUDED\n- Document-level sync (whole note as unit)\n- HTTP polling (30s interval when online)\n- Push/pull REST endpoints\n- Cloudflare Workers + D1 + KV infrastructure\n- API key authentication (PBKDF2)\n- Offline queue with exponential backoff retry\n- Conflict detection \u0026 storage\n- Basic resolution UI (keep mine/theirs/both)\n- Side-by-side comparison (read-only)\n- Delete vs edit conflict handling\n- Type-specific sync (DailyNote, MeetingNote reference validation)\n- Migration strategy for existing vaults\n- Network detection and reconnect sync\n- IPC contract extension\n- Progress UI for initial sync\n\n### DEFERRED (Post-v1)\n- Attachment/image sync (requires R2 integration)\n- WebSocket real-time push (reduces polling)\n- Block-level CRDT merge (complex, different architecture)\n- Auto-merge for DailyNotes (requires semantic understanding)\n- Inline diff highlighting (nice-to-have)\n- Manual merge editor (complex UI)\n- OAuth authentication (Google, GitHub, etc.)\n- End-to-end encryption (requires key management)\n- Self-hosting option (config + docs)\n- Shared/collaborative vaults (different sync model)\n- Real-time collaboration (OT/CRDT, different problem)\n\n---\n\n## Phase Overview\n\n### Phase 0: Opt-in Guards (CRITICAL - First)\nEnsure sync is disabled by default and no network calls occur when disabled.\nThis protects enterprise/corporate users with data governance requirements.\n\n### Phase 1: Core Infrastructure\nCreate the `packages/engine-sync/` package with core types, database, and engine interface.\nThis is the foundation that everything else builds on.\n\n### Phase 2: Client Integration\nIntegrate SyncEngine with EngineOrchestrator, IPC handlers, and main process.\nConnect the sync engine to the existing Scribe architecture.\n\n### Phase 3: Server\nCreate `apps/sync-server/` with Cloudflare Workers, D1 database, and push/pull endpoints.\nBuild the cloud infrastructure that handles synchronization.\n\n### Phase 4: UI\nBuild the user-facing sync components: status indicator, conflict resolution, settings.\nMake sync visible and controllable for users.\n\n### Phase 5: Testing \u0026 Polish\nComprehensive testing of sync flows, conflict resolution, and edge cases.\nEnsure the feature is production-ready.\n\n---\n\n## Dependency Graph Summary\n\n```\nPhase 0 (Opt-in Guards)\n    └── Phase 1 (Core Infrastructure)\n            ├── Phase 2 (Client Integration)\n            │       └── Phase 4 (UI)\n            │               └── Phase 5 (Testing)\n            └── Phase 3 (Server)\n                    └── Phase 5 (Testing)\n```\n\nPhase 1 subtasks have internal dependencies (types before implementations).\nPhases 2 and 3 can be developed in parallel after Phase 1.\nPhase 4 and 5 require both client and server work to be complete.\n\n---\n\n## Success Criteria\n\n1. **Opt-in works**: Fresh install has sync disabled, no network calls occur\n2. **Enable flow works**: User can enable sync, create account, initial sync completes\n3. **Edit flow works**: Changes sync within 30s, visible on second device\n4. **Conflict handling works**: Concurrent edits detected, user can resolve\n5. **Offline works**: Changes queue locally, sync when back online\n6. **Type-specific works**: DailyNotes, MeetingNotes sync with reference validation\n7. **Migration works**: Existing vaults can enable sync, all notes upload\n8. **Disable works**: User can disable sync, no more network calls, data stays local\n\n---\n\n## Related Future Work\n\n- Mobile client (iOS/Android) - shares engine-sync package\n- Web client - shares engine-sync package (uses sql.js instead of better-sqlite3)\n- End-to-end encryption - separate feature flag\n- Shared vaults / collaboration - different sync model required","status":"open","priority":1,"issue_type":"epic","created_at":"2025-12-27T21:28:16.861102-06:00","updated_at":"2025-12-27T21:28:16.861102-06:00"}
{"id":"scribe-hao.1","title":"[Phase 0.1] Verify SyncEngine is not initialized unless explicitly enabled","description":"# [Phase 0.1] Add conditional sync initialization skeleton in main.ts\n\n## Problem Statement\nSync MUST be disabled by default. This task adds the **skeleton code pattern** that checks for sync config before initializing any sync components. This is a prerequisite pattern that Phase 1 will build upon.\n\n## Why This is Critical (P0)\n- **Corporate/enterprise environments** have data governance policies prohibiting external sync\n- **Regulated industries** (healthcare, finance, legal) have strict data residency requirements\n- **Privacy-conscious users** want all data to remain local\n- **Zero network calls when disabled** - no sync-related network traffic whatsoever\n\n## Implementation Steps\n\n### 1. Add sync config check pattern in main.ts\n```typescript\n// apps/desktop/electron/main/src/main.ts\n\nasync function initializeEngines(vaultPath: string): Promise\u003cvoid\u003e {\n  // ... existing engine initialization ...\n  \n  // SYNC: Disabled by default - only initialize if explicitly enabled\n  // The actual loadSyncConfig and createSyncEngine will be implemented in Phase 1\n  // For now, this ensures the pattern exists and syncEngine is always null\n  const syncEnabled = await checkSyncEnabled(vaultPath);\n  if (syncEnabled) {\n    // Phase 1 will implement: deps.syncEngine = await createSyncEngine(...)\n    deps.syncEngine = null; // Placeholder until Phase 1\n    logger.info('Sync enabled but engine not yet implemented');\n  } else {\n    deps.syncEngine = null;\n    logger.info('Sync disabled - no sync engine initialized');\n  }\n}\n\n// Temporary implementation - will be replaced by engine-sync package\nasync function checkSyncEnabled(vaultPath: string): Promise\u003cboolean\u003e {\n  const configPath = path.join(vaultPath, '.scribe', 'sync.json');\n  try {\n    const content = await fs.readFile(configPath, 'utf-8');\n    const config = JSON.parse(content);\n    return config.enabled === true;\n  } catch {\n    return false; // Config doesn't exist = sync disabled (default)\n  }\n}\n```\n\n### 2. Update HandlerDependencies type\n```typescript\n// apps/desktop/electron/main/src/handlers/types.ts\nexport interface HandlerDependencies {\n  // ... existing deps ...\n  syncEngine: SyncEngine | null;  // Explicitly nullable - null when sync disabled\n}\n```\n\n## Verification Criteria\n- [ ] Fresh install has no `.scribe/sync.json` file\n- [ ] `checkSyncEnabled()` returns false when config missing\n- [ ] `deps.syncEngine` is null on app start\n- [ ] No sync-related imports are loaded (verify bundle)\n\n## Files to Modify\n- `apps/desktop/electron/main/src/main.ts`\n- `apps/desktop/electron/main/src/handlers/types.ts`\n\n## Dependencies\n- None (this is truly the first task - just adds the pattern)\n\n## UNBLOCKS\n- scribe-hao.2 (Verify no network calls)\n- scribe-hao.5 (Create engine-sync package - will replace checkSyncEnabled)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-27T21:28:17.046836-06:00","updated_at":"2025-12-29T12:54:48.035525-06:00","closed_at":"2025-12-29T12:54:48.035525-06:00","close_reason":"Implemented sync initialization skeleton in main.ts with checkSyncEnabled function and updated HandlerDependencies","dependencies":[{"issue_id":"scribe-hao.1","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:17.047207-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.10","title":"[Phase 1.6] Implement SyncDatabase SQLite wrapper","description":"# [Phase 1.6] Implement SyncDatabase SQLite wrapper\n\n## Problem Statement\nImplement a SQLite database for tracking sync state, queued changes, conflicts, and tombstones. Located at `{vault}/derived/sync.sqlite3`.\n\n## Why SQLite\n- **Transactional**: ACID guarantees for queue operations\n- **Reliable**: Survives app crashes\n- **Fast**: Indexed queries for status checks\n- **Existing pattern**: Same as Electron's storage approach\n\n## Schema (from GH Issue #54)\n\n```sql\n-- Device identity (survives reinstalls via this DB)\nCREATE TABLE device (\n  id TEXT PRIMARY KEY,\n  name TEXT,\n  created_at INTEGER NOT NULL\n);\n\n-- Track sync state per note\nCREATE TABLE sync_state (\n  note_id TEXT PRIMARY KEY,\n  local_version INTEGER NOT NULL,\n  server_version INTEGER,\n  content_hash TEXT NOT NULL,\n  last_synced_at INTEGER,\n  status TEXT DEFAULT 'synced'  -- 'synced' | 'pending' | 'conflict'\n);\n\n-- Queue of pending operations (FIFO)\nCREATE TABLE sync_queue (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  note_id TEXT NOT NULL,\n  operation TEXT NOT NULL,        -- 'create' | 'update' | 'delete'\n  version INTEGER NOT NULL,\n  base_version INTEGER,           -- Server version at time of local change\n  queued_at INTEGER NOT NULL,\n  payload TEXT,                   -- Full note JSON for create/update\n  status TEXT DEFAULT 'pending',  -- 'pending' | 'in_flight' | 'failed'\n  retries INTEGER DEFAULT 0,\n  last_error TEXT,\n  next_retry_at INTEGER           -- For exponential backoff\n);\nCREATE INDEX idx_sync_queue_status ON sync_queue(status, queued_at);\n\n-- Conflicts stored for user resolution\nCREATE TABLE conflicts (\n  note_id TEXT PRIMARY KEY,\n  local_note TEXT NOT NULL,       -- Full JSON\n  remote_note TEXT NOT NULL,      -- Full JSON\n  local_version INTEGER NOT NULL,\n  remote_version INTEGER NOT NULL,\n  detected_at INTEGER NOT NULL,\n  type TEXT NOT NULL              -- 'edit' | 'delete-edit' | 'edit-delete'\n);\n\n-- Tombstones for tracking deletes\nCREATE TABLE tombstones (\n  note_id TEXT PRIMARY KEY,\n  deleted_at INTEGER NOT NULL,\n  synced INTEGER DEFAULT 0,\n  expires_at INTEGER GENERATED ALWAYS AS (deleted_at + 7776000000) STORED\n);\n```\n\n## Implementation\n\n```typescript\n// packages/engine-sync/src/sync-database.ts\n\nimport Database from 'better-sqlite3';\nimport type { Note } from '@scribe/shared';\n\nexport interface QueuedChange {\n  id: number;\n  noteId: string;\n  operation: 'create' | 'update' | 'delete';\n  version: number;\n  baseVersion?: number;\n  queuedAt: number;\n  payload?: string;\n  status: 'pending' | 'in_flight' | 'failed';\n  retries: number;\n  lastError?: string;\n  nextRetryAt?: number;\n}\n\nexport class SyncDatabase {\n  private db: Database.Database;\n  \n  constructor(dbPath: string) {\n    this.db = new Database(dbPath);\n    this.db.pragma('journal_mode = WAL');\n    this.initialize();\n  }\n  \n  private initialize(): void {\n    this.db.exec(SCHEMA_SQL);\n    this.ensureDeviceId();\n  }\n  \n  // Device identity\n  async getDeviceId(): Promise\u003cstring\u003e {\n    const row = this.db.prepare('SELECT id FROM device LIMIT 1').get();\n    return row?.id;\n  }\n  \n  private ensureDeviceId(): void {\n    const existing = this.db.prepare('SELECT id FROM device LIMIT 1').get();\n    if (!existing) {\n      const id = crypto.randomUUID();\n      this.db.prepare(\n        'INSERT INTO device (id, name, created_at) VALUES (?, ?, ?)'\n      ).run(id, 'Desktop', Date.now());\n    }\n  }\n  \n  // Queue operations\n  queueChange(noteId: string, operation: string, version: number, payload?: Note): void {\n    this.db.prepare(`\n      INSERT INTO sync_queue (note_id, operation, version, queued_at, payload)\n      VALUES (?, ?, ?, ?, ?)\n    `).run(noteId, operation, version, Date.now(), JSON.stringify(payload));\n  }\n  \n  getPendingChanges(limit = 100): QueuedChange[] {\n    return this.db.prepare(`\n      SELECT * FROM sync_queue \n      WHERE status = 'pending' OR (status = 'failed' AND next_retry_at \u003c= ?)\n      ORDER BY queued_at ASC\n      LIMIT ?\n    `).all(Date.now(), limit);\n  }\n  \n  markInFlight(ids: number[]): void {\n    const stmt = this.db.prepare('UPDATE sync_queue SET status = ? WHERE id = ?');\n    const tx = this.db.transaction(() =\u003e {\n      for (const id of ids) {\n        stmt.run('in_flight', id);\n      }\n    });\n    tx();\n  }\n  \n  markCompleted(ids: number[]): void {\n    const stmt = this.db.prepare('DELETE FROM sync_queue WHERE id = ?');\n    const tx = this.db.transaction(() =\u003e {\n      for (const id of ids) {\n        stmt.run(id);\n      }\n    });\n    tx();\n  }\n  \n  markFailed(id: number, error: string, nextRetryAt: number): void {\n    this.db.prepare(`\n      UPDATE sync_queue \n      SET status = 'failed', retries = retries + 1, last_error = ?, next_retry_at = ?\n      WHERE id = ?\n    `).run(error, nextRetryAt, id);\n  }\n  \n  // Conflict storage\n  storeConflict(noteId: string, local: Note, remote: Note, type: string): void {\n    this.db.prepare(`\n      INSERT OR REPLACE INTO conflicts \n      (note_id, local_note, remote_note, local_version, remote_version, detected_at, type)\n      VALUES (?, ?, ?, ?, ?, ?, ?)\n    `).run(\n      noteId,\n      JSON.stringify(local),\n      JSON.stringify(remote),\n      local.sync?.version ?? 0,\n      remote.sync?.version ?? 0,\n      Date.now(),\n      type\n    );\n  }\n  \n  getConflicts(): Conflict[] {\n    return this.db.prepare('SELECT * FROM conflicts').all().map(row =\u003e ({\n      noteId: row.note_id,\n      localNote: JSON.parse(row.local_note),\n      remoteNote: JSON.parse(row.remote_note),\n      localVersion: row.local_version,\n      remoteVersion: row.remote_version,\n      detectedAt: row.detected_at,\n      type: row.type,\n    }));\n  }\n  \n  removeConflict(noteId: string): void {\n    this.db.prepare('DELETE FROM conflicts WHERE note_id = ?').run(noteId);\n  }\n  \n  // Tombstones\n  addTombstone(noteId: string): void {\n    this.db.prepare(\n      'INSERT OR REPLACE INTO tombstones (note_id, deleted_at) VALUES (?, ?)'\n    ).run(noteId, Date.now());\n  }\n  \n  // Stats\n  getPendingCount(): number {\n    return this.db.prepare(\n      'SELECT COUNT(*) as count FROM sync_queue WHERE status = ?'\n    ).get('pending')?.count ?? 0;\n  }\n  \n  getConflictCount(): number {\n    return this.db.prepare('SELECT COUNT(*) as count FROM conflicts').get()?.count ?? 0;\n  }\n  \n  close(): void {\n    this.db.close();\n  }\n}\n```\n\n## Files to Create\n- `packages/engine-sync/src/sync-database.ts`\n- `packages/engine-sync/src/sync-database.test.ts`\n\n## Dependencies\n- scribe-hao.5 (Create engine-sync package)\n- scribe-hao.9 (Content hash - stored in sync_state)\n\n## UNBLOCKS\n- scribe-hao.13 (ChangeTracker - uses queue)\n- scribe-hao.14 (ConflictResolver - uses conflicts table)\n- scribe-hao.15 (SyncCoordinator - uses queue)\n- scribe-hao.16 (SyncEngine - uses database)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:18.674927-06:00","updated_at":"2025-12-29T13:24:48.343828-06:00","closed_at":"2025-12-29T13:24:48.343828-06:00","close_reason":"Implemented SyncDatabase SQLite wrapper with 39 passing tests. Tables for sync_state, change_queue, conflicts, metadata.","dependencies":[{"issue_id":"scribe-hao.10","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:18.675267-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.10","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:02.490643-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.10","depends_on_id":"scribe-hao.6","type":"blocks","created_at":"2025-12-27T22:03:28.858659-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.11","title":"[Phase 1.7] Implement NetworkMonitor","description":"# [Phase 1.7] Define NetworkMonitor interface and implement adapter pattern\n\n## Problem Statement\nThe sync engine needs network status monitoring, but `packages/engine-sync/` must remain platform-agnostic. Electron-specific code (`electron.net`) cannot live in a shared package.\n\n## Architecture Decision\nUse **dependency injection** with an interface:\n- `packages/engine-sync/` defines `INetworkMonitor` interface\n- `apps/desktop/` provides Electron-specific implementation\n- This allows future web/mobile clients to provide their own implementations\n\n## Implementation\n\n### 1. Define interface in engine-sync package\n```typescript\n// packages/engine-sync/src/network-monitor.ts\n\n/**\n * Platform-agnostic network status monitor interface.\n * \n * Implementations are provided by the host application:\n * - Desktop: Uses Electron's net module\n * - Web: Uses navigator.onLine + online/offline events\n * - Mobile: Uses platform-specific APIs\n */\nexport interface INetworkMonitor {\n  /** Check if currently online */\n  isOnline(): boolean;\n  \n  /** Subscribe to network status changes */\n  onStatusChange(callback: (online: boolean) =\u003e void): () =\u003e void;\n  \n  /** Clean up resources */\n  destroy(): void;\n}\n\n/**\n * Null implementation for when sync is disabled.\n * Always reports offline, never fires events.\n */\nexport class DisabledNetworkMonitor implements INetworkMonitor {\n  isOnline(): boolean {\n    return false;\n  }\n  \n  onStatusChange(_callback: (online: boolean) =\u003e void): () =\u003e void {\n    return () =\u003e {}; // No-op unsubscribe\n  }\n  \n  destroy(): void {\n    // Nothing to clean up\n  }\n}\n```\n\n### 2. Implement Electron adapter in desktop app\n```typescript\n// apps/desktop/electron/main/src/sync/electron-network-monitor.ts\n\nimport { net } from 'electron';\nimport type { INetworkMonitor } from '@scribe/engine-sync';\n\n/**\n * Electron-specific network monitor using the net module.\n * Works on macOS, Windows, and Linux.\n */\nexport class ElectronNetworkMonitor implements INetworkMonitor {\n  private online: boolean;\n  private listeners: Set\u003c(online: boolean) =\u003e void\u003e = new Set();\n  private onlineHandler: () =\u003e void;\n  private offlineHandler: () =\u003e void;\n  \n  constructor() {\n    this.online = net.online;\n    \n    this.onlineHandler = () =\u003e this.setOnline(true);\n    this.offlineHandler = () =\u003e this.setOnline(false);\n    \n    net.on('online', this.onlineHandler);\n    net.on('offline', this.offlineHandler);\n  }\n  \n  private setOnline(online: boolean): void {\n    if (this.online !== online) {\n      this.online = online;\n      for (const listener of this.listeners) {\n        listener(online);\n      }\n    }\n  }\n  \n  isOnline(): boolean {\n    return this.online;\n  }\n  \n  onStatusChange(callback: (online: boolean) =\u003e void): () =\u003e void {\n    this.listeners.add(callback);\n    return () =\u003e this.listeners.delete(callback);\n  }\n  \n  destroy(): void {\n    this.listeners.clear();\n    // Note: Electron's net module events are cleaned up on module unload\n  }\n}\n```\n\n### 3. Update SyncEngine to accept injected monitor\n```typescript\n// packages/engine-sync/src/sync-engine.ts\n\nexport interface SyncEngineConfig {\n  // ... other config ...\n  networkMonitor: INetworkMonitor;\n}\n\nexport class SyncEngine {\n  private readonly networkMonitor: INetworkMonitor;\n  \n  constructor(config: SyncEngineConfig) {\n    this.networkMonitor = config.networkMonitor;\n    // ...\n  }\n}\n```\n\n### 4. Wire up in main.ts\n```typescript\n// apps/desktop/electron/main/src/main.ts\n\nimport { ElectronNetworkMonitor } from './sync/electron-network-monitor';\nimport { DisabledNetworkMonitor } from '@scribe/engine-sync';\n\n// When creating SyncEngine:\nconst networkMonitor = syncConfig?.enabled \n  ? new ElectronNetworkMonitor()\n  : new DisabledNetworkMonitor();\n\ndeps.syncEngine = await createSyncEngine({\n  // ...\n  networkMonitor,\n});\n```\n\n## Files to Create/Modify\n- `packages/engine-sync/src/network-monitor.ts` (interface + DisabledNetworkMonitor)\n- `apps/desktop/electron/main/src/sync/electron-network-monitor.ts` (NEW)\n\n## Why This Matters\n- **Testability**: Can mock INetworkMonitor in tests\n- **Portability**: Web client can use `navigator.onLine`, mobile can use native APIs\n- **Separation of concerns**: Platform code stays in apps/, shared code in packages/\n\n## Dependencies\n- scribe-hao.5 (Create engine-sync package)\n\n## UNBLOCKS\n- scribe-hao.2 (Verify no network calls when disabled - uses DisabledNetworkMonitor)\n- scribe-hao.16 (SyncEngine uses INetworkMonitor)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:18.851595-06:00","updated_at":"2025-12-29T13:34:15.945086-06:00","closed_at":"2025-12-29T13:34:15.945086-06:00","close_reason":"Implemented INetworkMonitor interface, DisabledNetworkMonitor (null pattern), and SimpleNetworkMonitor with 17 tests passing.","dependencies":[{"issue_id":"scribe-hao.11","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:18.85195-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.11","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:02.689821-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.11","depends_on_id":"scribe-hao.6","type":"blocks","created_at":"2025-12-27T22:03:29.076113-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.12","title":"[Phase 1.8] Implement SyncTransport HTTP client","description":"# [Phase 1.8] Implement SyncTransport HTTP client\n\n## Problem Statement\nImplement an HTTP client for sync server communication with retry logic, error handling, and authentication.\n\n## API Endpoints (from GH Issue #54)\n\n| Method | Endpoint | Purpose |\n|--------|----------|---------|\n| `POST` | `/v1/sync/push` | Send local changes to server |\n| `POST` | `/v1/sync/pull` | Fetch changes from server |\n| `GET` | `/v1/sync/status` | Health check / auth verification |\n| `POST` | `/v1/auth/register` | Create account |\n| `POST` | `/v1/auth/login` | Get API key |\n| `POST` | `/v1/auth/refresh` | Refresh API key |\n\n## Implementation\n\n```typescript\n// packages/engine-sync/src/sync-transport.ts\n\nimport type { \n  SyncPushRequest, SyncPushResponse,\n  SyncPullRequest, SyncPullResponse \n} from '@scribe/shared';\nimport { SyncError, ErrorCode } from '@scribe/shared';\n\nconst RETRYABLE_ERRORS = [\n  'ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND',\n  'ERR_NETWORK', 'ERR_CONNECTION_REFUSED',\n];\n\nconst RETRYABLE_STATUS_CODES = [429, 500, 502, 503, 504];\n\nexport interface RetryConfig {\n  maxRetries: number;\n  baseDelayMs: number;\n  maxDelayMs: number;\n  backoffMultiplier: number;\n}\n\nconst DEFAULT_RETRY_CONFIG: RetryConfig = {\n  maxRetries: 5,\n  baseDelayMs: 1000,\n  maxDelayMs: 60000,\n  backoffMultiplier: 2,\n};\n\nexport class SyncTransport {\n  private readonly serverUrl: string;\n  private readonly apiKey: string;\n  private readonly retryConfig: RetryConfig;\n  \n  constructor(\n    serverUrl: string, \n    apiKey: string,\n    retryConfig: RetryConfig = DEFAULT_RETRY_CONFIG\n  ) {\n    this.serverUrl = serverUrl.replace(/\\/$/, ''); // Remove trailing slash\n    this.apiKey = apiKey;\n    this.retryConfig = retryConfig;\n  }\n  \n  async push(request: SyncPushRequest): Promise\u003cSyncPushResponse\u003e {\n    return this.fetchWithRetry('/v1/sync/push', {\n      method: 'POST',\n      body: JSON.stringify(request),\n    });\n  }\n  \n  async pull(request: SyncPullRequest): Promise\u003cSyncPullResponse\u003e {\n    return this.fetchWithRetry('/v1/sync/pull', {\n      method: 'POST',\n      body: JSON.stringify(request),\n    });\n  }\n  \n  async checkStatus(): Promise\u003c{ ok: boolean; serverTime: string }\u003e {\n    return this.fetchWithRetry('/v1/sync/status', { method: 'GET' });\n  }\n  \n  private async fetchWithRetry\u003cT\u003e(\n    path: string, \n    options: RequestInit,\n    retryCount = 0\n  ): Promise\u003cT\u003e {\n    const url = `${this.serverUrl}${path}`;\n    \n    try {\n      const response = await fetch(url, {\n        ...options,\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${this.apiKey}`,\n          ...options.headers,\n        },\n      });\n      \n      // Handle specific error codes\n      if (response.status === 401) {\n        throw new SyncError(ErrorCode.SYNC_AUTH_FAILED, 'Invalid API key');\n      }\n      \n      if (response.status === 429) {\n        const retryAfter = response.headers.get('Retry-After');\n        const delay = retryAfter ? parseInt(retryAfter) * 1000 : this.computeDelay(retryCount);\n        \n        if (retryCount \u003c this.retryConfig.maxRetries) {\n          await this.sleep(delay);\n          return this.fetchWithRetry(path, options, retryCount + 1);\n        }\n        throw new SyncError(ErrorCode.SYNC_RATE_LIMITED, 'Rate limit exceeded');\n      }\n      \n      if (RETRYABLE_STATUS_CODES.includes(response.status)) {\n        if (retryCount \u003c this.retryConfig.maxRetries) {\n          await this.sleep(this.computeDelay(retryCount));\n          return this.fetchWithRetry(path, options, retryCount + 1);\n        }\n        throw new SyncError(ErrorCode.SYNC_SERVER_ERROR, `Server error: ${response.status}`);\n      }\n      \n      if (!response.ok) {\n        const body = await response.text();\n        throw new SyncError(\n          ErrorCode.SYNC_FAILED, \n          `Request failed: ${response.status} - ${body}`\n        );\n      }\n      \n      return response.json();\n    } catch (error) {\n      if (error instanceof SyncError) throw error;\n      \n      const err = error as Error \u0026 { code?: string };\n      \n      // Check for retryable network errors\n      if (RETRYABLE_ERRORS.includes(err.code ?? '') || err.name === 'TypeError') {\n        if (retryCount \u003c this.retryConfig.maxRetries) {\n          await this.sleep(this.computeDelay(retryCount));\n          return this.fetchWithRetry(path, options, retryCount + 1);\n        }\n      }\n      \n      throw new SyncError(\n        ErrorCode.SYNC_NETWORK_ERROR, \n        `Network error: ${err.message}`,\n        undefined,\n        err\n      );\n    }\n  }\n  \n  private computeDelay(retryCount: number): number {\n    const delay = this.retryConfig.baseDelayMs * \n      Math.pow(this.retryConfig.backoffMultiplier, retryCount);\n    return Math.min(delay, this.retryConfig.maxDelayMs);\n  }\n  \n  private sleep(ms: number): Promise\u003cvoid\u003e {\n    return new Promise(resolve =\u003e setTimeout(resolve, ms));\n  }\n}\n```\n\n## Files to Create\n- `packages/engine-sync/src/sync-transport.ts`\n- `packages/engine-sync/src/sync-transport.test.ts`\n\n## Dependencies\n- scribe-hao.5 (Create engine-sync package)\n- scribe-hao.6 (Sync types)\n- scribe-hao.8 (Error codes)\n\n## UNBLOCKS\n- scribe-hao.15 (SyncCoordinator uses transport)\n- scribe-hao.16 (SyncEngine uses transport)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:19.032679-06:00","updated_at":"2025-12-29T13:34:16.153039-06:00","closed_at":"2025-12-29T13:34:16.153039-06:00","close_reason":"Implemented SyncTransport HTTP client with push/pull/status methods, exponential backoff retry, rate limiting, and 27 tests passing.","dependencies":[{"issue_id":"scribe-hao.12","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:19.033037-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.12","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:02.912481-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.12","depends_on_id":"scribe-hao.6","type":"blocks","created_at":"2025-12-27T22:03:29.287491-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.13","title":"[Phase 1.9] Implement ChangeTracker observer","description":"# [Phase 1.9] Implement ChangeTracker observer\n\n## Problem Statement\nThe sync engine needs to detect local changes to notes as they happen. The ChangeTracker observes note CRUD operations and queues them for the sync coordinator.\n\n## Why This Architecture\n- **Event-driven**: Reacts to changes rather than polling\n- **Decoupled**: Works independently of EngineOrchestrator\n- **Batching**: Collects changes for efficient sync cycles\n\n## Implementation\n\n### File: `packages/engine-sync/src/change-tracker.ts`\n\n```typescript\nimport type { Note, NoteId } from '@scribe/shared';\nimport type { SyncDatabase } from './sync-database';\nimport type { ContentHasher } from './content-hash';\n\nexport type ChangeType = 'create' | 'update' | 'delete';\n\nexport interface LocalChange {\n  noteId: NoteId;\n  changeType: ChangeType;\n  contentHash: string | null; // null for deletes\n  timestamp: number;\n}\n\nexport interface ChangeTrackerConfig {\n  database: SyncDatabase;\n  contentHasher: ContentHasher;\n}\n\n/**\n * Observes local note changes and records them for sync.\n * \n * ## Tracking Strategy\n * \n * - CREATE: Record new note with content hash\n * - UPDATE: Compute new hash, compare to stored, record if different\n * - DELETE: Record tombstone with null hash\n * \n * ## Deduplication\n * \n * Multiple rapid saves to the same note are coalesced:\n * - Only the latest state matters for sync\n * - Earlier pending changes for same noteId are overwritten\n * \n * ## Usage\n * \n * ```typescript\n * // After saving a note via EngineOrchestrator\n * changeTracker.trackChange(note, 'update');\n * \n * // After deleting\n * changeTracker.trackDelete(noteId);\n * ```\n */\nexport class ChangeTracker {\n  private readonly database: SyncDatabase;\n  private readonly contentHasher: ContentHasher;\n\n  constructor(config: ChangeTrackerConfig) {\n    this.database = config.database;\n    this.contentHasher = config.contentHasher;\n  }\n\n  /**\n   * Track a note create or update.\n   * Computes content hash and records in pending_changes table.\n   */\n  async trackChange(note: Note, changeType: 'create' | 'update'): Promise\u003cvoid\u003e {\n    const contentHash = this.contentHasher.computeHash(note);\n    const existingHash = this.database.getNoteHash(note.id);\n\n    // Skip if content hasn't actually changed (for updates)\n    if (changeType === 'update' \u0026\u0026 existingHash === contentHash) {\n      return;\n    }\n\n    this.database.recordPendingChange({\n      noteId: note.id,\n      changeType,\n      contentHash,\n      timestamp: Date.now(),\n    });\n\n    // Update stored hash\n    this.database.updateNoteHash(note.id, contentHash);\n  }\n\n  /**\n   * Track a note deletion.\n   * Records tombstone in pending_changes.\n   */\n  trackDelete(noteId: NoteId): void {\n    this.database.recordPendingChange({\n      noteId,\n      changeType: 'delete',\n      contentHash: null,\n      timestamp: Date.now(),\n    });\n\n    this.database.removeNoteHash(noteId);\n  }\n\n  /**\n   * Get all pending changes for the next sync cycle.\n   * Returns changes in chronological order.\n   */\n  getPendingChanges(): LocalChange[] {\n    return this.database.getPendingChanges();\n  }\n\n  /**\n   * Clear pending changes after successful sync.\n   * @param changeIds - IDs of changes to clear (from sync response)\n   */\n  clearPendingChanges(changeIds: number[]): void {\n    this.database.clearPendingChanges(changeIds);\n  }\n\n  /**\n   * Check if there are any pending changes.\n   */\n  hasPendingChanges(): boolean {\n    return this.database.getPendingChangeCount() \u003e 0;\n  }\n}\n```\n\n## Database Schema Requirements (from scribe-hao.10)\n\n```sql\n-- Content hashes for change detection\nCREATE TABLE note_hashes (\n  note_id TEXT PRIMARY KEY,\n  content_hash TEXT NOT NULL,\n  updated_at INTEGER NOT NULL\n);\n\n-- Pending local changes queue\nCREATE TABLE pending_changes (\n  id INTEGER PRIMARY KEY AUTOINCREMENT,\n  note_id TEXT NOT NULL,\n  change_type TEXT NOT NULL CHECK (change_type IN ('create', 'update', 'delete')),\n  content_hash TEXT, -- NULL for deletes\n  timestamp INTEGER NOT NULL,\n  UNIQUE(note_id) -- Coalesce multiple changes to same note\n);\n```\n\n## Integration with EngineOrchestrator\n\nAfter this task, the ChangeTracker will be wired into save/delete flows:\n\n```typescript\n// In EngineOrchestrator.saveNote()\nawait this.vault.save(note);\n// ... other engine updates ...\nif (this.syncEnabled) {\n  await this.changeTracker.trackChange(note, isNew ? 'create' : 'update');\n}\n```\n\n## Verification Criteria\n- [ ] `trackChange()` correctly identifies create vs update\n- [ ] Content hash comparison prevents redundant tracking\n- [ ] Delete tombstones are properly recorded\n- [ ] `getPendingChanges()` returns chronological order\n- [ ] Coalescing works (multiple saves → single pending change)\n\n## Files to Create\n- `packages/engine-sync/src/change-tracker.ts`\n\n## Dependencies\n- scribe-hao.9 (content-hash.ts - for ContentHasher)\n- scribe-hao.10 (sync-database.ts - for SyncDatabase)\n\n## UNBLOCKS\n- scribe-hao.15 (SyncCoordinator)\n- scribe-hao.16 (SyncEngine main class)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:19.208465-06:00","updated_at":"2025-12-29T13:34:16.344366-06:00","closed_at":"2025-12-29T13:34:16.344366-06:00","close_reason":"Implemented ChangeTracker with trackChange, trackDelete, deduplication, and 23 tests passing.","dependencies":[{"issue_id":"scribe-hao.13","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:19.208789-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.13","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:03.139678-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.13","depends_on_id":"scribe-hao.10","type":"blocks","created_at":"2025-12-27T22:03:29.499304-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.13","depends_on_id":"scribe-hao.9","type":"blocks","created_at":"2025-12-27T22:03:29.697422-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.14","title":"[Phase 1.10] Implement ConflictResolver","description":"# [Phase 1.10] Implement ConflictResolver\n\n## Problem Statement\nWhen the server has a different version of a note than the client, we have a conflict. The ConflictResolver detects conflicts and provides resolution strategies.\n\n## Why This Architecture\n- **Last-write-wins default**: Simple, predictable behavior for most cases\n- **Manual resolution available**: User can choose when edits diverge\n- **Keep both option**: Never lose data - can create copy\n\n## Conflict Detection\n\nA conflict occurs when:\n1. Client has pending changes for a note\n2. Server returns that note in a pull with a different `server_version` than our last known\n\n```\nClient state: version=5, pending changes (local edit)\nServer state: version=6 (someone else edited)\n→ CONFLICT: Both sides modified since last sync\n```\n\n## Implementation\n\n### File: `packages/engine-sync/src/conflict-resolver.ts`\n\n```typescript\nimport type { Note, NoteId } from '@scribe/shared';\n\nexport type ConflictResolution = \n  | 'local'      // Keep local version, overwrite server\n  | 'remote'     // Accept server version, discard local changes\n  | 'keepBoth'   // Create a copy with local changes\n  | 'manual';    // User will resolve in UI\n\nexport interface SyncConflict {\n  noteId: NoteId;\n  localNote: Note;\n  remoteNote: Note;\n  localVersion: number;\n  remoteVersion: number;\n  localModifiedAt: number;\n  remoteModifiedAt: number;\n}\n\nexport interface ConflictResult {\n  resolution: ConflictResolution;\n  resolvedNote?: Note;        // For 'local' or 'remote'\n  copyNote?: Note;            // For 'keepBoth' - the copy to save\n  requiresUserInput: boolean; // For 'manual'\n}\n\nexport interface ConflictResolverConfig {\n  /** Default resolution strategy when auto-resolving */\n  defaultStrategy: ConflictResolution;\n  /** Auto-resolve if changes are within this many ms */\n  autoResolveThresholdMs: number;\n}\n\n/**\n * Detects and resolves sync conflicts between local and remote notes.\n * \n * ## Resolution Strategies\n * \n * - **local**: Push local version to server, bump version\n * - **remote**: Accept server version, discard pending local changes\n * - **keepBoth**: Save server version AND create \"[title] (conflict copy)\"\n * - **manual**: Store conflict for user resolution via UI\n * \n * ## Auto-Resolution Heuristics\n * \n * 1. If only metadata changed (not content), take newer timestamp\n * 2. If edits are in different sections, attempt merge (future)\n * 3. If one side is trivial (whitespace only), take the other\n */\nexport class ConflictResolver {\n  private readonly config: ConflictResolverConfig;\n  private pendingConflicts: Map\u003cNoteId, SyncConflict\u003e = new Map();\n\n  constructor(config: ConflictResolverConfig) {\n    this.config = config;\n  }\n\n  /**\n   * Check if two versions of a note represent a conflict.\n   */\n  isConflict(\n    localNote: Note,\n    remoteNote: Note,\n    localVersion: number,\n    remoteVersion: number\n  ): boolean {\n    // No conflict if versions match\n    if (localVersion === remoteVersion) {\n      return false;\n    }\n\n    // No conflict if local is behind and has no pending changes\n    // (this case is handled by normal pull - just update local)\n    \n    // Conflict: local has changes AND server has newer version\n    return localVersion \u003c remoteVersion;\n  }\n\n  /**\n   * Attempt to auto-resolve a conflict based on heuristics.\n   * Returns 'manual' if auto-resolution is not possible.\n   */\n  autoResolve(conflict: SyncConflict): ConflictResult {\n    const { localNote, remoteNote, localModifiedAt, remoteModifiedAt } = conflict;\n\n    // Heuristic 1: Same content hash → no real conflict\n    // (handled upstream, but defensive check)\n    if (this.contentEquals(localNote, remoteNote)) {\n      return {\n        resolution: 'remote',\n        resolvedNote: remoteNote,\n        requiresUserInput: false,\n      };\n    }\n\n    // Heuristic 2: Timestamps within threshold → take newer\n    const timeDiff = Math.abs(localModifiedAt - remoteModifiedAt);\n    if (timeDiff \u003c this.config.autoResolveThresholdMs) {\n      const useLocal = localModifiedAt \u003e remoteModifiedAt;\n      return {\n        resolution: useLocal ? 'local' : 'remote',\n        resolvedNote: useLocal ? localNote : remoteNote,\n        requiresUserInput: false,\n      };\n    }\n\n    // Heuristic 3: One side is whitespace-only change → take the other\n    // (implement if needed)\n\n    // Default: require manual resolution\n    this.pendingConflicts.set(conflict.noteId, conflict);\n    return {\n      resolution: 'manual',\n      requiresUserInput: true,\n    };\n  }\n\n  /**\n   * Resolve a conflict with user-provided strategy.\n   */\n  resolveManually(\n    noteId: NoteId,\n    resolution: Exclude\u003cConflictResolution, 'manual'\u003e\n  ): ConflictResult {\n    const conflict = this.pendingConflicts.get(noteId);\n    if (!conflict) {\n      throw new Error(`No pending conflict for note ${noteId}`);\n    }\n\n    this.pendingConflicts.delete(noteId);\n\n    switch (resolution) {\n      case 'local':\n        return {\n          resolution: 'local',\n          resolvedNote: conflict.localNote,\n          requiresUserInput: false,\n        };\n\n      case 'remote':\n        return {\n          resolution: 'remote',\n          resolvedNote: conflict.remoteNote,\n          requiresUserInput: false,\n        };\n\n      case 'keepBoth':\n        const copyNote = this.createConflictCopy(conflict.localNote);\n        return {\n          resolution: 'keepBoth',\n          resolvedNote: conflict.remoteNote, // Accept remote as primary\n          copyNote,                           // Save local as copy\n          requiresUserInput: false,\n        };\n    }\n  }\n\n  /**\n   * Get all pending conflicts requiring user resolution.\n   */\n  getPendingConflicts(): SyncConflict[] {\n    return Array.from(this.pendingConflicts.values());\n  }\n\n  /**\n   * Check if a specific note has a pending conflict.\n   */\n  hasConflict(noteId: NoteId): boolean {\n    return this.pendingConflicts.has(noteId);\n  }\n\n  /**\n   * Clear a conflict (e.g., if note was deleted).\n   */\n  clearConflict(noteId: NoteId): void {\n    this.pendingConflicts.delete(noteId);\n  }\n\n  private contentEquals(a: Note, b: Note): boolean {\n    // Compare serialized content (excluding metadata like sync versions)\n    return JSON.stringify(a.content) === JSON.stringify(b.content);\n  }\n\n  private createConflictCopy(note: Note): Note {\n    const timestamp = new Date().toISOString().slice(0, 19).replace('T', ' ');\n    return {\n      ...note,\n      id: crypto.randomUUID() as NoteId,\n      metadata: {\n        ...note.metadata,\n        title: `${note.metadata.title} (conflict copy ${timestamp})`,\n        createdAt: new Date().toISOString(),\n        updatedAt: new Date().toISOString(),\n      },\n    };\n  }\n}\n```\n\n## Verification Criteria\n- [ ] `isConflict()` correctly identifies divergent versions\n- [ ] Auto-resolve works for trivial conflicts\n- [ ] Manual resolution stores and retrieves conflicts\n- [ ] `keepBoth` creates valid copy with unique ID\n- [ ] Conflict copies have clear naming\n\n## Files to Create\n- `packages/engine-sync/src/conflict-resolver.ts`\n\n## Dependencies\n- scribe-hao.6 (sync types for Note with sync metadata)\n\n## UNBLOCKS\n- scribe-hao.15 (SyncCoordinator)\n- scribe-hao.46 (conflict resolution integration tests)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:19.383527-06:00","updated_at":"2025-12-29T13:34:16.515166-06:00","closed_at":"2025-12-29T13:34:16.515166-06:00","close_reason":"Implemented ConflictResolver with hasConflict, detectConflict, resolve (keep_local/remote/both), auto-resolve heuristics, and 23 tests passing.","dependencies":[{"issue_id":"scribe-hao.14","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:19.383869-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.14","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:03.342744-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.14","depends_on_id":"scribe-hao.6","type":"blocks","created_at":"2025-12-27T22:03:29.887863-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.14","depends_on_id":"scribe-hao.9","type":"blocks","created_at":"2025-12-27T22:03:30.077678-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.15","title":"[Phase 1.11] Implement SyncCoordinator","description":"# [Phase 1.11] Implement SyncCoordinator\n\n## Problem Statement\nThe SyncCoordinator orchestrates full sync cycles: gathering local changes, pushing to server, pulling remote changes, detecting conflicts, and applying updates. It ties together all sync components.\n\n## Why This Architecture\n- **Single sync loop**: One place for the push/pull/resolve cycle\n- **Batched operations**: Efficient network usage\n- **Conflict handling**: Integrated with ConflictResolver\n- **Progress reporting**: Enables UI feedback\n\n## Sync Cycle Flow\n\n```\n┌────────────────────────────────────────────────────────────┐\n│                     SYNC CYCLE                              │\n├────────────────────────────────────────────────────────────┤\n│  1. Gather pending local changes (ChangeTracker)           │\n│  2. PUSH: Send local changes to server                     │\n│     → Server returns accepted versions                      │\n│  3. PULL: Request changes since last sync token            │\n│     → Server returns remote changes + new token            │\n│  4. DETECT: Compare pulled notes with local state          │\n│     → Identify conflicts using ConflictResolver            │\n│  5. APPLY: Update local vault with non-conflicting notes   │\n│  6. RESOLVE: Handle conflicts (auto or queue for manual)   │\n│  7. Update sync token and clear processed changes          │\n└────────────────────────────────────────────────────────────┘\n```\n\n## Implementation\n\n### File: `packages/engine-sync/src/sync-coordinator.ts`\n\n```typescript\nimport type { Note, NoteId } from '@scribe/shared';\nimport type { SyncTransport, PushRequest, PullResponse } from './sync-transport';\nimport type { SyncDatabase } from './sync-database';\nimport type { ChangeTracker, LocalChange } from './change-tracker';\nimport type { ConflictResolver, SyncConflict } from './conflict-resolver';\nimport type { ContentHasher } from './content-hash';\n\nexport type SyncPhase = \n  | 'idle'\n  | 'gathering'\n  | 'pushing'\n  | 'pulling'\n  | 'applying'\n  | 'resolving';\n\nexport interface SyncProgress {\n  phase: SyncPhase;\n  totalItems: number;\n  processedItems: number;\n  conflicts: number;\n}\n\nexport interface SyncCycleResult {\n  success: boolean;\n  pushed: number;\n  pulled: number;\n  conflicts: SyncConflict[];\n  error?: string;\n}\n\nexport interface SyncCoordinatorConfig {\n  transport: SyncTransport;\n  database: SyncDatabase;\n  changeTracker: ChangeTracker;\n  conflictResolver: ConflictResolver;\n  contentHasher: ContentHasher;\n  \n  /** Callback to save a note locally (via EngineOrchestrator) */\n  onSaveNote: (note: Note) =\u003e Promise\u003cvoid\u003e;\n  /** Callback to delete a note locally */\n  onDeleteNote: (noteId: NoteId) =\u003e Promise\u003cvoid\u003e;\n  /** Callback for progress updates */\n  onProgress?: (progress: SyncProgress) =\u003e void;\n}\n\n/**\n * Coordinates complete sync cycles between local and remote.\n * \n * ## Thread Safety\n * \n * Only one sync cycle can run at a time. Concurrent calls to\n * `runSyncCycle()` are queued.\n * \n * ## Error Handling\n * \n * - Network errors: Retry with exponential backoff\n * - Conflict errors: Queue for resolution, continue with others\n * - Server errors: Abort cycle, preserve local state\n */\nexport class SyncCoordinator {\n  private readonly config: SyncCoordinatorConfig;\n  private currentPhase: SyncPhase = 'idle';\n  private syncInProgress = false;\n\n  constructor(config: SyncCoordinatorConfig) {\n    this.config = config;\n  }\n\n  /**\n   * Run a complete sync cycle.\n   * \n   * @returns Result with counts and any conflicts\n   * @throws SyncError if cycle fails unrecoverably\n   */\n  async runSyncCycle(): Promise\u003cSyncCycleResult\u003e {\n    if (this.syncInProgress) {\n      // Queue or reject concurrent sync\n      throw new Error('Sync already in progress');\n    }\n\n    this.syncInProgress = true;\n    const conflicts: SyncConflict[] = [];\n    let pushed = 0;\n    let pulled = 0;\n\n    try {\n      // Phase 1: Gather local changes\n      this.setPhase('gathering');\n      const pendingChanges = this.config.changeTracker.getPendingChanges();\n\n      // Phase 2: Push local changes\n      if (pendingChanges.length \u003e 0) {\n        this.setPhase('pushing');\n        pushed = await this.pushChanges(pendingChanges);\n      }\n\n      // Phase 3: Pull remote changes\n      this.setPhase('pulling');\n      const lastSyncToken = this.config.database.getLastSyncToken();\n      const pullResponse = await this.config.transport.pull(lastSyncToken);\n\n      // Phase 4 \u0026 5: Apply pulled changes, detect conflicts\n      if (pullResponse.changes.length \u003e 0) {\n        this.setPhase('applying');\n        const { applied, conflictsDetected } = await this.applyPulledChanges(\n          pullResponse\n        );\n        pulled = applied;\n        conflicts.push(...conflictsDetected);\n      }\n\n      // Phase 6: Handle conflicts\n      if (conflicts.length \u003e 0) {\n        this.setPhase('resolving');\n        await this.handleConflicts(conflicts);\n      }\n\n      // Update sync token\n      this.config.database.setLastSyncToken(pullResponse.syncToken);\n\n      this.setPhase('idle');\n      return { success: true, pushed, pulled, conflicts };\n\n    } catch (error) {\n      this.setPhase('idle');\n      return {\n        success: false,\n        pushed,\n        pulled,\n        conflicts,\n        error: error instanceof Error ? error.message : 'Unknown error',\n      };\n    } finally {\n      this.syncInProgress = false;\n    }\n  }\n\n  /**\n   * Push local changes to server.\n   */\n  private async pushChanges(changes: LocalChange[]): Promise\u003cnumber\u003e {\n    const pushRequest: PushRequest = {\n      changes: await Promise.all(\n        changes.map(async (change) =\u003e {\n          if (change.changeType === 'delete') {\n            return {\n              noteId: change.noteId,\n              changeType: 'delete' as const,\n              contentHash: null,\n              note: null,\n            };\n          }\n\n          // Get full note for create/update\n          const note = this.config.database.getLocalNote(change.noteId);\n          return {\n            noteId: change.noteId,\n            changeType: change.changeType,\n            contentHash: change.contentHash,\n            note,\n          };\n        })\n      ),\n    };\n\n    const response = await this.config.transport.push(pushRequest);\n\n    // Clear successfully pushed changes\n    const successIds = response.results\n      .filter((r) =\u003e r.success)\n      .map((r) =\u003e r.changeId);\n    this.config.changeTracker.clearPendingChanges(successIds);\n\n    return successIds.length;\n  }\n\n  /**\n   * Apply pulled changes to local vault.\n   */\n  private async applyPulledChanges(\n    pullResponse: PullResponse\n  ): Promise\u003c{ applied: number; conflictsDetected: SyncConflict[] }\u003e {\n    const conflictsDetected: SyncConflict[] = [];\n    let applied = 0;\n\n    for (const change of pullResponse.changes) {\n      // Check for conflict with local pending changes\n      const hasPendingChange = this.config.changeTracker\n        .getPendingChanges()\n        .some((c) =\u003e c.noteId === change.noteId);\n\n      if (hasPendingChange) {\n        // Potential conflict - check versions\n        const localNote = this.config.database.getLocalNote(change.noteId);\n        const localVersion = this.config.database.getNoteVersion(change.noteId);\n\n        if (\n          localNote \u0026\u0026\n          this.config.conflictResolver.isConflict(\n            localNote,\n            change.note!,\n            localVersion,\n            change.serverVersion\n          )\n        ) {\n          conflictsDetected.push({\n            noteId: change.noteId,\n            localNote,\n            remoteNote: change.note!,\n            localVersion,\n            remoteVersion: change.serverVersion,\n            localModifiedAt: new Date(localNote.metadata.updatedAt).getTime(),\n            remoteModifiedAt: change.timestamp,\n          });\n          continue; // Skip applying - will handle in conflict resolution\n        }\n      }\n\n      // No conflict - apply change\n      if (change.changeType === 'delete') {\n        await this.config.onDeleteNote(change.noteId);\n      } else if (change.note) {\n        await this.config.onSaveNote(change.note);\n      }\n\n      // Update local version tracking\n      this.config.database.setNoteVersion(change.noteId, change.serverVersion);\n      applied++;\n    }\n\n    return { applied, conflictsDetected };\n  }\n\n  /**\n   * Handle detected conflicts.\n   */\n  private async handleConflicts(conflicts: SyncConflict[]): Promise\u003cvoid\u003e {\n    for (const conflict of conflicts) {\n      const result = this.config.conflictResolver.autoResolve(conflict);\n\n      if (!result.requiresUserInput) {\n        // Auto-resolved - apply resolution\n        if (result.resolvedNote) {\n          await this.config.onSaveNote(result.resolvedNote);\n        }\n        if (result.copyNote) {\n          await this.config.onSaveNote(result.copyNote);\n        }\n      }\n      // Manual resolution: conflict stays in ConflictResolver.pendingConflicts\n    }\n  }\n\n  private setPhase(phase: SyncPhase): void {\n    this.currentPhase = phase;\n    this.config.onProgress?.({\n      phase,\n      totalItems: 0,\n      processedItems: 0,\n      conflicts: this.config.conflictResolver.getPendingConflicts().length,\n    });\n  }\n\n  /**\n   * Get current sync status.\n   */\n  getStatus(): { phase: SyncPhase; inProgress: boolean } {\n    return {\n      phase: this.currentPhase,\n      inProgress: this.syncInProgress,\n    };\n  }\n\n  /**\n   * Check if there are pending changes that need syncing.\n   */\n  hasPendingChanges(): boolean {\n    return this.config.changeTracker.hasPendingChanges();\n  }\n}\n```\n\n## Verification Criteria\n- [ ] Complete sync cycle works: push → pull → apply\n- [ ] Conflicts are detected when local and remote diverge\n- [ ] Auto-resolution handles trivial conflicts\n- [ ] Manual conflicts are queued for UI resolution\n- [ ] Sync token is updated after successful cycle\n- [ ] Concurrent sync attempts are rejected/queued\n\n## Files to Create\n- `packages/engine-sync/src/sync-coordinator.ts`\n\n## Dependencies\n- scribe-hao.9 (content-hash.ts)\n- scribe-hao.10 (sync-database.ts)\n- scribe-hao.12 (sync-transport.ts)\n- scribe-hao.13 (change-tracker.ts)\n- scribe-hao.14 (conflict-resolver.ts)\n\n## UNBLOCKS\n- scribe-hao.16 (SyncEngine main class)\n- scribe-hao.45 (integration tests for sync flow)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:19.567057-06:00","updated_at":"2025-12-29T13:39:31.55693-06:00","closed_at":"2025-12-29T13:39:31.55693-06:00","close_reason":"Implemented SyncCoordinator with runSyncCycle, pushChanges, pullChanges methods and 21 tests passing. Orchestrates full sync cycle with conflict detection.","dependencies":[{"issue_id":"scribe-hao.15","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:19.567443-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.15","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:03.555648-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.15","depends_on_id":"scribe-hao.11","type":"blocks","created_at":"2025-12-27T22:03:30.268433-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.15","depends_on_id":"scribe-hao.12","type":"blocks","created_at":"2025-12-27T22:03:30.459236-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.15","depends_on_id":"scribe-hao.13","type":"blocks","created_at":"2025-12-27T22:03:30.649408-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.15","depends_on_id":"scribe-hao.14","type":"blocks","created_at":"2025-12-27T22:03:30.838211-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.16","title":"[Phase 1.12] Implement main SyncEngine class","description":"# [Phase 1.12] Implement main SyncEngine class\n\n## Problem Statement\nImplement the main SyncEngine class that coordinates all sync components and provides the public API.\n\n## SyncEngine Interface (from GH Issue #54)\n\n```typescript\ninterface SyncEngine {\n  // Lifecycle\n  initialize(): Promise\u003cvoid\u003e;\n  shutdown(): Promise\u003cvoid\u003e;\n  \n  // Sync metadata\n  addSyncMetadata(note: Note): Note;\n  \n  // Change tracking\n  queueChange(note: Note | { id: NoteId }, operation: 'create' | 'update' | 'delete'): Promise\u003cvoid\u003e;\n  \n  // Manual sync triggers\n  triggerSync(): Promise\u003cSyncResult\u003e;\n  triggerPush(): Promise\u003cPushResult\u003e;\n  triggerPull(): Promise\u003cPullResult\u003e;\n  \n  // Conflict management\n  getConflicts(): Promise\u003cConflict[]\u003e;\n  resolveConflict(noteId: NoteId, resolution: ConflictResolution): Promise\u003cvoid\u003e;\n  \n  // Status\n  getStatus(): SyncStatus;\n  onStatusChange(callback: (status: SyncStatus) =\u003e void): () =\u003e void;\n  \n  // Device identity\n  getDeviceId(): Promise\u003cstring\u003e;\n}\n```\n\n## Implementation\n\n```typescript\n// packages/engine-sync/src/sync-engine.ts\n\nimport type { Note, NoteId, SyncStatus, SyncResult, Conflict, ConflictResolution } from '@scribe/shared';\nimport { SyncDatabase } from './sync-database';\nimport { SyncCoordinator } from './sync-coordinator';\nimport { SyncTransport } from './sync-transport';\nimport { NetworkMonitor } from './network-monitor';\nimport { ConflictResolver } from './conflict-resolver';\nimport { computeContentHash } from './content-hash';\nimport { loadSyncConfig, type SyncConfig } from './sync-config';\n\nexport interface SyncEngineConfig {\n  vaultPath: string;\n  serverUrl?: string;\n  apiKey?: string;\n  pollIntervalMs?: number;\n}\n\nexport class SyncEngine {\n  private db: SyncDatabase;\n  private coordinator: SyncCoordinator;\n  private transport: SyncTransport | null = null;\n  private networkMonitor: NetworkMonitor;\n  private conflictResolver: ConflictResolver;\n  private config: SyncConfig | null = null;\n  private statusListeners: Set\u003c(status: SyncStatus) =\u003e void\u003e = new Set();\n  private pollTimer: NodeJS.Timeout | null = null;\n  \n  private readonly vaultPath: string;\n  private readonly pollIntervalMs: number;\n  \n  constructor(config: SyncEngineConfig) {\n    this.vaultPath = config.vaultPath;\n    this.pollIntervalMs = config.pollIntervalMs ?? 30000;\n    \n    // Initialize database\n    const dbPath = `${config.vaultPath}/derived/sync.sqlite3`;\n    this.db = new SyncDatabase(dbPath);\n    \n    // Initialize components\n    this.networkMonitor = new NetworkMonitor();\n    this.conflictResolver = new ConflictResolver(this.db);\n  }\n  \n  async initialize(): Promise\u003cvoid\u003e {\n    // Load config\n    this.config = await loadSyncConfig(this.vaultPath);\n    \n    if (!this.config?.enabled) {\n      return; // Sync disabled - don't initialize transport\n    }\n    \n    // Initialize transport\n    this.transport = new SyncTransport(\n      this.config.serverUrl,\n      this.config.apiKeyHash\n    );\n    \n    // Initialize coordinator\n    this.coordinator = new SyncCoordinator({\n      db: this.db,\n      transport: this.transport,\n      conflictResolver: this.conflictResolver,\n      onStatusChange: (status) =\u003e this.notifyStatusChange(status),\n    });\n    \n    // Start polling if online\n    if (this.networkMonitor.isOnline()) {\n      this.startPolling();\n    }\n    \n    // React to network changes\n    this.networkMonitor.onStatusChange((online) =\u003e {\n      if (online) {\n        this.triggerSync();\n        this.startPolling();\n      } else {\n        this.stopPolling();\n        this.notifyStatusChange({ ...this.getStatus(), state: 'offline' });\n      }\n    });\n  }\n  \n  async shutdown(): Promise\u003cvoid\u003e {\n    this.stopPolling();\n    this.db.close();\n  }\n  \n  // Add sync metadata to a note\n  addSyncMetadata(note: Note): Note {\n    const version = (note.sync?.version ?? 0) + 1;\n    const contentHash = computeContentHash(note);\n    \n    return {\n      ...note,\n      sync: {\n        ...note.sync,\n        version,\n        contentHash,\n        deviceId: await this.db.getDeviceId(),\n      },\n    };\n  }\n  \n  // Queue a change for sync\n  async queueChange(\n    note: Note | { id: NoteId },\n    operation: 'create' | 'update' | 'delete'\n  ): Promise\u003cvoid\u003e {\n    if (!this.config?.enabled) return;\n    \n    const noteId = 'id' in note ? note.id : (note as Note).id;\n    const fullNote = operation === 'delete' ? undefined : note as Note;\n    const version = fullNote?.sync?.version ?? 1;\n    \n    this.db.queueChange(noteId, operation, version, fullNote);\n    \n    // Update status\n    this.notifyStatusChange(this.getStatus());\n    \n    // Trigger immediate sync attempt if online\n    if (this.networkMonitor.isOnline()) {\n      // Debounce to batch rapid changes\n      setTimeout(() =\u003e this.triggerPush(), 1000);\n    }\n  }\n  \n  // Manual sync triggers\n  async triggerSync(): Promise\u003cSyncResult\u003e {\n    if (!this.transport) {\n      return { pushed: 0, pulled: 0, conflicts: 0, errors: ['Sync disabled'] };\n    }\n    return this.coordinator.sync();\n  }\n  \n  async triggerPush(): Promise\u003cSyncResult\u003e {\n    if (!this.transport) {\n      return { pushed: 0, pulled: 0, conflicts: 0, errors: ['Sync disabled'] };\n    }\n    return this.coordinator.push();\n  }\n  \n  async triggerPull(): Promise\u003cSyncResult\u003e {\n    if (!this.transport) {\n      return { pushed: 0, pulled: 0, conflicts: 0, errors: ['Sync disabled'] };\n    }\n    return this.coordinator.pull();\n  }\n  \n  // Conflict management\n  async getConflicts(): Promise\u003cConflict[]\u003e {\n    return this.db.getConflicts();\n  }\n  \n  async resolveConflict(noteId: NoteId, resolution: ConflictResolution): Promise\u003cvoid\u003e {\n    await this.conflictResolver.resolve(noteId, resolution);\n    this.notifyStatusChange(this.getStatus());\n  }\n  \n  // Status\n  getStatus(): SyncStatus {\n    if (!this.config?.enabled) {\n      return { state: 'disabled', pendingChanges: 0, conflictCount: 0 };\n    }\n    \n    if (!this.networkMonitor.isOnline()) {\n      return {\n        state: 'offline',\n        pendingChanges: this.db.getPendingCount(),\n        conflictCount: this.db.getConflictCount(),\n      };\n    }\n    \n    // TODO: Track syncing state in coordinator\n    return {\n      state: 'idle',\n      pendingChanges: this.db.getPendingCount(),\n      conflictCount: this.db.getConflictCount(),\n      lastSyncAt: this.config.lastSyncSequence, // TODO: Store actual timestamp\n    };\n  }\n  \n  onStatusChange(callback: (status: SyncStatus) =\u003e void): () =\u003e void {\n    this.statusListeners.add(callback);\n    return () =\u003e this.statusListeners.delete(callback);\n  }\n  \n  async getDeviceId(): Promise\u003cstring\u003e {\n    return this.db.getDeviceId();\n  }\n  \n  // Private methods\n  private startPolling(): void {\n    if (this.pollTimer) return;\n    this.pollTimer = setInterval(() =\u003e this.triggerSync(), this.pollIntervalMs);\n  }\n  \n  private stopPolling(): void {\n    if (this.pollTimer) {\n      clearInterval(this.pollTimer);\n      this.pollTimer = null;\n    }\n  }\n  \n  private notifyStatusChange(status: SyncStatus): void {\n    for (const listener of this.statusListeners) {\n      listener(status);\n    }\n  }\n}\n\n// Factory function\nexport async function createSyncEngine(config: SyncEngineConfig): Promise\u003cSyncEngine\u003e {\n  const engine = new SyncEngine(config);\n  await engine.initialize();\n  return engine;\n}\n```\n\n## Files to Create\n- `packages/engine-sync/src/sync-engine.ts`\n\n## Dependencies\n- scribe-hao.5 (Package structure)\n- scribe-hao.6 (Sync types)\n- scribe-hao.7 (SyncMetadata on Note)\n- scribe-hao.8 (Error codes)\n- scribe-hao.9 (Content hash)\n- scribe-hao.10 (SyncDatabase)\n- scribe-hao.11 (NetworkMonitor)\n- scribe-hao.12 (SyncTransport)\n- scribe-hao.13 (ChangeTracker)\n- scribe-hao.14 (ConflictResolver)\n- scribe-hao.15 (SyncCoordinator)\n\n## UNBLOCKS\n- Phase 2 tasks (Client Integration)\n- scribe-hao.42 (Unit tests for SyncEngine)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:19.748043-06:00","updated_at":"2025-12-29T13:47:04.994806-06:00","closed_at":"2025-12-29T13:47:04.994806-06:00","close_reason":"Implemented main SyncEngine class with full API: initialize, shutdown, addSyncMetadata, queueChange/Delete, triggerSync, getConflicts, resolveConflict, getStatus, onStatusChange, getDeviceId. 28 tests passing.","dependencies":[{"issue_id":"scribe-hao.16","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:19.748408-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.16","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:03.758818-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.16","depends_on_id":"scribe-hao.15","type":"blocks","created_at":"2025-12-27T22:03:31.026703-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.17","title":"[Phase 2.1] Extend IPC contract with sync channels and SyncAPI","description":"# [Phase 2.1] Extend IPC contract with sync channels and SyncAPI\n\n## Problem Statement\nAdd sync-related IPC channels and typed API interface to the shared IPC contract, enabling communication between renderer and main process for sync operations.\n\n## New IPC Channels\n\n```typescript\n// packages/shared/src/ipc-contract.ts\n\nexport const IPC_CHANNELS = {\n  // ... existing channels ...\n  \n  // Sync\n  SYNC_GET_STATUS: 'sync:getStatus',\n  SYNC_TRIGGER: 'sync:trigger',\n  SYNC_GET_CONFLICTS: 'sync:getConflicts',\n  SYNC_RESOLVE_CONFLICT: 'sync:resolveConflict',\n  SYNC_ENABLE: 'sync:enable',\n  SYNC_DISABLE: 'sync:disable',\n  SYNC_STATUS_CHANGED: 'sync:statusChanged',  // Event channel\n} as const;\n```\n\n## SyncAPI Interface\n\n```typescript\n/**\n * Sync API for multi-device synchronization\n */\nexport interface SyncAPI {\n  /** Get current sync status */\n  getStatus(): Promise\u003cSyncStatus\u003e;\n  \n  /** Manually trigger a sync cycle */\n  trigger(): Promise\u003cSyncResult\u003e;\n  \n  /** Get list of unresolved conflicts */\n  getConflicts(): Promise\u003cConflict[]\u003e;\n  \n  /** Resolve a conflict */\n  resolveConflict(\n    noteId: NoteId, \n    resolution: ConflictResolution\n  ): Promise\u003c{ success: boolean }\u003e;\n  \n  /** Enable sync for this vault */\n  enable(options: SyncEnableOptions): Promise\u003c{ success: boolean; error?: string }\u003e;\n  \n  /** Disable sync for this vault */\n  disable(): Promise\u003c{ success: boolean }\u003e;\n  \n  /** Subscribe to status changes (uses event pattern like tasks:changed) */\n  onStatusChange(callback: (status: SyncStatus) =\u003e void): () =\u003e void;\n}\n```\n\n## Add to ScribeAPI\n\n```typescript\nexport interface ScribeAPI {\n  // ... existing APIs ...\n  \n  /** Sync API for multi-device synchronization */\n  sync: SyncAPI;\n}\n```\n\n## Import Types\n\n```typescript\n// At top of ipc-contract.ts\nimport type {\n  Note,\n  NoteId,\n  SearchResult,\n  GraphNode,\n  Task,\n  TaskFilter,\n  TaskChangeEvent,\n  SyncStatus,\n  SyncResult,\n  Conflict,\n  ConflictResolution,\n  SyncEnableOptions,\n} from './types.js';\n```\n\n## Event Pattern (like tasks:changed)\n\nThe `onStatusChange` method uses the same event pattern as `tasks.onChange`:\n\n```typescript\n// Preload implementation pattern:\nonStatusChange(callback: (status: SyncStatus) =\u003e void): () =\u003e void {\n  const handler = (_event: IpcRendererEvent, status: SyncStatus) =\u003e {\n    callback(status);\n  };\n  ipcRenderer.on(IPC_CHANNELS.SYNC_STATUS_CHANGED, handler);\n  return () =\u003e {\n    ipcRenderer.removeListener(IPC_CHANNELS.SYNC_STATUS_CHANGED, handler);\n  };\n}\n```\n\n## Files to Modify\n- `packages/shared/src/ipc-contract.ts`\n\n## Dependencies\n- scribe-hao.6 (Sync types in shared)\n\n## UNBLOCKS\n- scribe-hao.3 (Settings UI uses SyncAPI)\n- scribe-hao.18 (HandlerDependencies)\n- scribe-hao.20 (Sync IPC handlers)\n- scribe-hao.22 (Preload bridge)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:19.929737-06:00","updated_at":"2025-12-29T13:54:46.433913-06:00","closed_at":"2025-12-29T13:54:46.433913-06:00","close_reason":"Extended IPC contract with 7 sync channels (SYNC_GET_STATUS, SYNC_TRIGGER, etc.), SyncAPI interface with 7 methods, added sync to ScribeAPI. Typecheck passes.","dependencies":[{"issue_id":"scribe-hao.17","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:19.93014-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.17","depends_on_id":"scribe-hao.16","type":"blocks","created_at":"2025-12-27T22:03:45.372397-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.18","title":"[Phase 2.2] Extend HandlerDependencies with syncEngine","description":"# [Phase 2.2] Extend HandlerDependencies with syncEngine\n\n## Problem Statement\nIPC handlers need access to the SyncEngine to trigger sync operations and report sync status. The HandlerDependencies interface must be extended to include the optional SyncEngine.\n\n## Why This Architecture\n- **Optional dependency**: SyncEngine is null when sync is disabled (Phase 0 opt-in)\n- **Consistent pattern**: Follows existing vault/graphEngine/searchEngine pattern\n- **Type-safe access**: Helper function ensures sync is enabled before use\n\n## Implementation\n\n### File: `apps/desktop/electron/main/src/handlers/types.ts`\n\n```typescript\nimport type { BrowserWindow } from 'electron';\nimport type { FileSystemVault } from '@scribe/storage-fs';\nimport type { GraphEngine } from '@scribe/engine-graph';\nimport type { SearchEngine } from '@scribe/engine-search';\nimport type { TaskIndex } from '@scribe/engine-core/node';\nimport type { SyncEngine } from '@scribe/engine-sync'; // NEW\nimport { ScribeError } from '@scribe/shared';\n\n/**\n * Dependencies injected into each handler module.\n * All properties may be null during early startup.\n */\nexport interface HandlerDependencies {\n  vault: FileSystemVault | null;\n  graphEngine: GraphEngine | null;\n  searchEngine: SearchEngine | null;\n  taskIndex: TaskIndex | null;\n  mainWindow: BrowserWindow | null;\n  syncEngine: SyncEngine | null; // NEW - null when sync disabled\n}\n\n// ... existing helpers (requireVault, requireGraphEngine, etc.) ...\n\n/**\n * Helper to get a guaranteed non-null syncEngine, throwing if not initialized or disabled.\n * \n * Use this in sync-specific handlers. For handlers that should work\n * whether sync is enabled or not, check `deps.syncEngine` directly.\n */\nexport function requireSyncEngine(deps: HandlerDependencies): SyncEngine {\n  if (!deps.syncEngine) {\n    throw new Error('Sync engine not initialized or sync is disabled');\n  }\n  return deps.syncEngine;\n}\n\n/**\n * Check if sync is enabled and ready.\n * Use this for conditional sync operations in non-sync handlers.\n */\nexport function isSyncEnabled(deps: HandlerDependencies): boolean {\n  return deps.syncEngine !== null \u0026\u0026 deps.syncEngine.isEnabled();\n}\n\n/**\n * Extended Engines type including sync.\n */\nexport interface EnginesWithSync extends Engines {\n  syncEngine: SyncEngine;\n}\n\n/**\n * Higher-order function for handlers that require sync.\n */\nexport function withSync\u003cT extends unknown[], R\u003e(\n  deps: HandlerDependencies,\n  handler: (syncEngine: SyncEngine, ...args: T) =\u003e Promise\u003cR\u003e\n): (_event: Electron.IpcMainInvokeEvent, ...args: T) =\u003e Promise\u003cR\u003e {\n  return async (_event: Electron.IpcMainInvokeEvent, ...args: T): Promise\u003cR\u003e =\u003e {\n    if (!deps.syncEngine) {\n      throw new Error('Sync not enabled');\n    }\n    return handler(deps.syncEngine, ...args);\n  };\n}\n```\n\n### Updating Existing Engines Interface\n\n```typescript\n/**\n * Type-safe bundle of all initialized engines.\n * Used by {@link withEngines} to provide pre-validated engine references.\n */\nexport interface Engines {\n  vault: FileSystemVault;\n  graphEngine: GraphEngine;\n  searchEngine: SearchEngine;\n  taskIndex: TaskIndex;\n  // Note: syncEngine intentionally NOT here - it's optional\n}\n```\n\n## Integration Pattern\n\nHandlers that need sync will use one of two patterns:\n\n```typescript\n// Pattern 1: Sync-specific handler (requires sync)\nipcMain.handle(IPC_CHANNELS.SYNC_NOW, withSync(deps, async (syncEngine) =\u003e {\n  return await syncEngine.syncNow();\n}));\n\n// Pattern 2: Handler with optional sync (e.g., notes:save with sync trigger)\nipcMain.handle(IPC_CHANNELS.NOTES_SAVE, withEngines(deps, async (engines, note: Note) =\u003e {\n  await engines.vault.save(note);\n  // ... other engine updates ...\n  \n  // Optional sync trigger\n  if (isSyncEnabled(deps)) {\n    deps.syncEngine!.notifyChange(note.id, 'update');\n  }\n  \n  return { success: true };\n}));\n```\n\n## Verification Criteria\n- [ ] `HandlerDependencies` includes `syncEngine: SyncEngine | null`\n- [ ] `requireSyncEngine()` throws when sync is disabled\n- [ ] `isSyncEnabled()` returns false when syncEngine is null\n- [ ] `withSync()` wrapper works for sync-specific handlers\n- [ ] Existing handlers compile without changes\n\n## Files to Modify\n- `apps/desktop/electron/main/src/handlers/types.ts`\n\n## Dependencies\n- scribe-hao.16 (SyncEngine main class must exist)\n- scribe-hao.17 (IPC contract with SyncAPI)\n\n## UNBLOCKS\n- scribe-hao.20 (sync IPC handlers)\n- scribe-hao.21 (main.ts integration)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:20.109741-06:00","updated_at":"2025-12-29T13:58:18.549025-06:00","closed_at":"2025-12-29T13:58:18.549025-06:00","close_reason":"Added SyncEngine import from engine-sync, verified syncEngine in HandlerDependencies, added requireSyncEngine and isSyncAvailable helpers.","dependencies":[{"issue_id":"scribe-hao.18","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:20.110067-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.18","depends_on_id":"scribe-hao.17","type":"blocks","created_at":"2025-12-27T22:03:45.58896-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.19","title":"[Phase 2.3] Extend EngineOrchestrator for sync integration","description":"# [Phase 2.3] Extend EngineOrchestrator for sync integration\n\n## Problem Statement\nExtend the existing EngineOrchestrator to integrate with SyncEngine, queuing changes after successful saves.\n\n## Current EngineOrchestrator (simplified)\n```typescript\nclass EngineOrchestrator {\n  async saveNote(note: Note): Promise\u003cSaveResult\u003e {\n    // 1. Save to vault\n    await this.vault.save(note);\n    // 2. Update graph\n    this.graphEngine.addNote(note);\n    // 3. Update search\n    this.searchEngine.indexNote(note);\n    // 4. Update tasks\n    const taskChanges = this.taskIndex.indexNote(note);\n    // 5. Emit task changes\n    if (taskChanges.length \u003e 0 \u0026\u0026 this.onTasksChanged) {\n      this.onTasksChanged(taskChanges);\n    }\n    return { success: true, taskChanges };\n  }\n}\n```\n\n## Target EngineOrchestrator (with sync)\n```typescript\nclass EngineOrchestrator {\n  private syncEngine?: SyncEngine;\n  private onSyncStatusChanged?: (status: SyncStatus) =\u003e void;\n  \n  constructor(config: EngineOrchestratorConfig) {\n    // ... existing initialization ...\n    this.syncEngine = config.syncEngine;\n    this.onSyncStatusChanged = config.onSyncStatusChanged;\n    \n    // Subscribe to sync status changes\n    if (this.syncEngine) {\n      this.syncEngine.onStatusChange((status) =\u003e {\n        if (this.onSyncStatusChanged) {\n          this.onSyncStatusChanged(status);\n        }\n      });\n    }\n  }\n  \n  async saveNote(note: Note): Promise\u003cSaveResult\u003e {\n    // 1. Add sync metadata if sync is enabled\n    const noteToSave = this.syncEngine\n      ? this.syncEngine.addSyncMetadata(note)\n      : note;\n    \n    // 2. Save to vault (source of truth)\n    await this.vault.save(noteToSave);\n    \n    // 3. Update graph\n    this.graphEngine.addNote(noteToSave);\n    \n    // 4. Update search\n    this.searchEngine.indexNote(noteToSave);\n    \n    // 5. Update tasks\n    const taskChanges = this.taskIndex.indexNote(noteToSave);\n    \n    // 6. Queue for sync (non-blocking)\n    if (this.syncEngine) {\n      await this.syncEngine.queueChange(noteToSave, 'update');\n    }\n    \n    // 7. Emit task changes\n    if (taskChanges.length \u003e 0 \u0026\u0026 this.onTasksChanged) {\n      this.onTasksChanged(taskChanges);\n    }\n    \n    return { success: true, taskChanges };\n  }\n  \n  async deleteNote(noteId: NoteId): Promise\u003cDeleteResult\u003e {\n    // 1. Delete from vault\n    await this.vault.delete(noteId);\n    \n    // 2. Remove from graph\n    this.graphEngine.removeNote(noteId);\n    \n    // 3. Remove from search\n    this.searchEngine.removeNote(noteId);\n    \n    // 4. Remove tasks\n    const taskChanges = this.taskIndex.removeNote(noteId);\n    \n    // 5. Queue delete for sync\n    if (this.syncEngine) {\n      await this.syncEngine.queueChange({ id: noteId }, 'delete');\n    }\n    \n    // 6. Emit task changes\n    if (taskChanges.length \u003e 0 \u0026\u0026 this.onTasksChanged) {\n      this.onTasksChanged(taskChanges);\n    }\n    \n    return { success: true, taskChanges };\n  }\n}\n```\n\n## Config Interface Update\n```typescript\ninterface EngineOrchestratorConfig {\n  vault: FileSystemVault;\n  graphEngine: GraphEngine;\n  searchEngine: SearchEngine;\n  taskIndex: TaskIndex;\n  syncEngine?: SyncEngine;                // NEW: Optional sync engine\n  onTasksChanged?: (changes: TaskChangeEvent[]) =\u003e void;\n  onSyncStatusChanged?: (status: SyncStatus) =\u003e void;  // NEW\n}\n```\n\n## Files to Modify\n- `apps/desktop/electron/main/src/EngineOrchestrator.ts`\n\n## Dependencies\n- scribe-hao.16 (SyncEngine implementation)\n- scribe-hao.18 (HandlerDependencies)\n\n## UNBLOCKS\n- scribe-hao.21 (SyncEngine initialization in main.ts)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:20.288456-06:00","updated_at":"2025-12-29T14:03:05.234105-06:00","closed_at":"2025-12-29T14:03:05.234105-06:00","close_reason":"Created EngineOrchestrator with SyncEngine integration in saveNote/deleteNote flows. Added setSyncEngine, getSyncEngine, isSyncEnabled methods. All typechecks pass.","dependencies":[{"issue_id":"scribe-hao.19","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:20.288831-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.19","depends_on_id":"scribe-hao.18","type":"blocks","created_at":"2025-12-27T22:03:45.785156-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.2","title":"[Phase 0.2] Verify no network calls occur when sync is disabled","description":"# [Phase 0.2] Verify no network calls occur when sync is disabled\n\n## Problem Statement\nWhen sync is disabled, there must be ZERO network traffic related to sync. This is not just about skipping sync operations - it's about ensuring no telemetry, no health checks, no anything that phones home.\n\n## Why This is Critical (P0)\n- Enterprise security teams audit network traffic\n- Some corporate environments block unknown endpoints\n- Users should have full confidence that \"disabled\" means \"disabled\"\n- GDPR and other regulations may require this guarantee\n\n## Implementation Approach\n\n### 1. Conditional import of sync transport\n```typescript\n// packages/engine-sync/src/sync-engine.ts\n\nexport class SyncEngine {\n  private transport: SyncTransport | null = null;\n  \n  constructor(config: SyncEngineConfig) {\n    if (!config.enabled) {\n      // Don't even create the transport - no HTTP client instantiated\n      this.transport = null;\n      return;\n    }\n    this.transport = new SyncTransport(config.serverUrl);\n  }\n}\n```\n\n### 2. Guard all network operations\n```typescript\n// Every method that might make network calls:\nasync triggerSync(): Promise\u003cSyncResult\u003e {\n  if (!this.transport) {\n    return { pushed: 0, pulled: 0, conflicts: 0, errors: ['Sync disabled'] };\n  }\n  // ... actual sync logic\n}\n```\n\n### 3. NetworkMonitor should not ping when disabled\n```typescript\n// packages/engine-sync/src/network-monitor.ts\n\nexport class NetworkMonitor {\n  constructor(private enabled: boolean) {\n    if (!enabled) {\n      // Don't set up any listeners or polling\n      return;\n    }\n    // Set up Electron net listeners only if enabled\n    net.on('online', () =\u003e this.setOnline(true));\n    net.on('offline', () =\u003e this.setOnline(false));\n  }\n}\n```\n\n## Verification Criteria\n- [ ] With sync disabled, no HTTP requests are made (verify with network inspector)\n- [ ] With sync disabled, no DNS lookups for sync server\n- [ ] SyncTransport is not instantiated when sync is disabled\n- [ ] NetworkMonitor doesn't set up listeners when sync is disabled\n\n## Testing Approach\n```typescript\ndescribe('Sync disabled mode', () =\u003e {\n  it('makes no network calls on app start', async () =\u003e {\n    const networkSpy = vi.spyOn(global, 'fetch');\n    await initializeAppWithSyncDisabled();\n    expect(networkSpy).not.toHaveBeenCalled();\n  });\n  \n  it('triggerSync returns early without network call', async () =\u003e {\n    const engine = createSyncEngine({ enabled: false });\n    const result = await engine.triggerSync();\n    expect(result.errors).toContain('Sync disabled');\n    expect(fetchSpy).not.toHaveBeenCalled();\n  });\n});\n```\n\n## Files to Modify\n- `packages/engine-sync/src/sync-engine.ts`\n- `packages/engine-sync/src/network-monitor.ts`\n- `packages/engine-sync/src/sync-transport.ts`\n\n## Dependencies\n- scribe-hao.1 (Verify SyncEngine not initialized)\n- scribe-hao.5 (Create engine-sync package)\n\n## UNBLOCKS\n- scribe-hao.4 (Verify no account prompts)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-27T21:28:17.226018-06:00","updated_at":"2025-12-29T13:01:20.687697-06:00","closed_at":"2025-12-29T13:01:20.687697-06:00","close_reason":"Created integration test file with 14 tests verifying no network calls when sync disabled. All tests pass.","dependencies":[{"issue_id":"scribe-hao.2","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:17.226372-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.2","depends_on_id":"scribe-hao.1","type":"blocks","created_at":"2025-12-27T22:03:08.028397-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.20","title":"[Phase 2.4] Implement sync IPC handlers","description":"# [Phase 2.4] Implement sync IPC handlers\n\n## Problem Statement\nCreate IPC handlers that expose sync functionality to the renderer process. These handlers wrap SyncEngine methods and translate between IPC and sync operations.\n\n## Why This Architecture\n- **Thin wrapper**: Handlers just delegate to SyncEngine\n- **Error translation**: Convert sync errors to IPC-safe format\n- **Event forwarding**: Push sync status updates to renderer\n\n## Implementation\n\n### File: `apps/desktop/electron/main/src/handlers/syncHandlers.ts`\n\n```typescript\nimport { ipcMain, type BrowserWindow } from 'electron';\nimport { IPC_CHANNELS, type SyncStatus, type SyncConflict } from '@scribe/shared';\nimport type { HandlerDependencies } from './types';\nimport { requireSyncEngine, isSyncEnabled, wrapError } from './types';\n\n/**\n * Register sync-related IPC handlers.\n * \n * These handlers are registered unconditionally, but will throw\n * if called when sync is disabled. The renderer should check\n * sync:isEnabled before calling sync operations.\n */\nexport function registerSyncHandlers(deps: HandlerDependencies): void {\n  // Check if sync is enabled\n  ipcMain.handle(IPC_CHANNELS.SYNC_IS_ENABLED, async () =\u003e {\n    return isSyncEnabled(deps);\n  });\n\n  // Get current sync status\n  ipcMain.handle(IPC_CHANNELS.SYNC_GET_STATUS, async () =\u003e {\n    if (!isSyncEnabled(deps)) {\n      return { enabled: false, status: 'disabled' as const };\n    }\n    try {\n      const syncEngine = requireSyncEngine(deps);\n      return {\n        enabled: true,\n        status: syncEngine.getStatus(),\n      };\n    } catch (error) {\n      wrapError(error);\n    }\n  });\n\n  // Trigger immediate sync\n  ipcMain.handle(IPC_CHANNELS.SYNC_NOW, async () =\u003e {\n    try {\n      const syncEngine = requireSyncEngine(deps);\n      const result = await syncEngine.syncNow();\n      return result;\n    } catch (error) {\n      wrapError(error);\n    }\n  });\n\n  // Get pending conflicts\n  ipcMain.handle(IPC_CHANNELS.SYNC_GET_CONFLICTS, async () =\u003e {\n    try {\n      const syncEngine = requireSyncEngine(deps);\n      return syncEngine.getPendingConflicts();\n    } catch (error) {\n      wrapError(error);\n    }\n  });\n\n  // Resolve a conflict\n  ipcMain.handle(\n    IPC_CHANNELS.SYNC_RESOLVE_CONFLICT,\n    async (_event, noteId: string, resolution: 'local' | 'remote' | 'keepBoth') =\u003e {\n      try {\n        const syncEngine = requireSyncEngine(deps);\n        await syncEngine.resolveConflict(noteId, resolution);\n        return { success: true };\n      } catch (error) {\n        wrapError(error);\n      }\n    }\n  );\n\n  // Enable sync (requires account)\n  ipcMain.handle(\n    IPC_CHANNELS.SYNC_ENABLE,\n    async (_event, credentials: { email: string; token: string }) =\u003e {\n      try {\n        const syncEngine = requireSyncEngine(deps);\n        await syncEngine.enable(credentials);\n        return { success: true };\n      } catch (error) {\n        wrapError(error);\n      }\n    }\n  );\n\n  // Disable sync\n  ipcMain.handle(IPC_CHANNELS.SYNC_DISABLE, async () =\u003e {\n    try {\n      const syncEngine = requireSyncEngine(deps);\n      await syncEngine.disable();\n      return { success: true };\n    } catch (error) {\n      wrapError(error);\n    }\n  });\n\n  // Get sync configuration\n  ipcMain.handle(IPC_CHANNELS.SYNC_GET_CONFIG, async () =\u003e {\n    if (!deps.syncEngine) {\n      return null;\n    }\n    try {\n      return deps.syncEngine.getConfig();\n    } catch (error) {\n      wrapError(error);\n    }\n  });\n\n  // Update sync configuration\n  ipcMain.handle(\n    IPC_CHANNELS.SYNC_SET_CONFIG,\n    async (_event, config: Partial\u003c{ syncIntervalMs: number; autoSync: boolean }\u003e) =\u003e {\n      try {\n        const syncEngine = requireSyncEngine(deps);\n        await syncEngine.updateConfig(config);\n        return { success: true };\n      } catch (error) {\n        wrapError(error);\n      }\n    }\n  );\n}\n\n/**\n * Set up sync status change listener.\n * Called after mainWindow is created.\n */\nexport function setupSyncStatusListener(\n  deps: HandlerDependencies,\n  mainWindow: BrowserWindow\n): void {\n  if (!deps.syncEngine) {\n    return;\n  }\n\n  deps.syncEngine.onStatusChange((status: SyncStatus) =\u003e {\n    if (!mainWindow.isDestroyed()) {\n      mainWindow.webContents.send(IPC_CHANNELS.SYNC_STATUS_CHANGED, status);\n    }\n  });\n\n  deps.syncEngine.onConflict((conflict: SyncConflict) =\u003e {\n    if (!mainWindow.isDestroyed()) {\n      mainWindow.webContents.send(IPC_CHANNELS.SYNC_CONFLICT_DETECTED, conflict);\n    }\n  });\n}\n```\n\n### Handler Registration in main.ts\n\n```typescript\n// In registerIpcHandlers() or similar\nimport { registerSyncHandlers, setupSyncStatusListener } from './handlers/syncHandlers';\n\n// Register handlers\nregisterSyncHandlers(deps);\n\n// After window creation\nmainWindow.once('ready-to-show', () =\u003e {\n  setupSyncStatusListener(deps, mainWindow);\n});\n```\n\n## Verification Criteria\n- [ ] `sync:isEnabled` returns correct state\n- [ ] `sync:getStatus` works when enabled, returns disabled otherwise\n- [ ] `sync:now` triggers immediate sync cycle\n- [ ] `sync:getConflicts` returns pending conflicts\n- [ ] `sync:resolveConflict` applies user choice\n- [ ] `sync:enable` and `sync:disable` work correctly\n- [ ] Status change events are forwarded to renderer\n- [ ] Conflict events are forwarded to renderer\n\n## Files to Create\n- `apps/desktop/electron/main/src/handlers/syncHandlers.ts`\n\n## Files to Modify\n- `apps/desktop/electron/main/src/handlers/index.ts` (add export)\n\n## Dependencies\n- scribe-hao.17 (IPC channels defined)\n- scribe-hao.18 (HandlerDependencies with syncEngine)\n- scribe-hao.16 (SyncEngine class)\n\n## UNBLOCKS\n- scribe-hao.22 (preload bridge)\n- scribe-hao.33 (SyncStatusIndicator component)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:20.468261-06:00","updated_at":"2025-12-29T14:08:18.540382-06:00","closed_at":"2025-12-29T14:08:18.540382-06:00","close_reason":"Created syncHandlers.ts with 6 IPC handlers (getStatus, trigger, getConflicts, resolveConflict, enable, disable). Added setupSyncStatusForwarding. Integrated into main.ts.","dependencies":[{"issue_id":"scribe-hao.20","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:20.468625-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.20","depends_on_id":"scribe-hao.19","type":"blocks","created_at":"2025-12-27T22:03:45.982877-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.21","title":"[Phase 2.5] Integrate SyncEngine initialization in main.ts","description":"# [Phase 2.5] Integrate SyncEngine initialization in main.ts\n\n## Problem Statement\nThe main process must conditionally initialize SyncEngine based on user settings. This includes loading sync config, creating the sync database, and wiring up the sync engine to the EngineOrchestrator.\n\n## Why This Architecture\n- **Lazy initialization**: Only create SyncEngine if sync is enabled\n- **Lifecycle management**: Proper startup/shutdown sequencing\n- **EngineOrchestrator integration**: Sync observes note changes\n\n## Implementation\n\n### File: `apps/desktop/electron/main/src/main.ts` (additions)\n\n```typescript\nimport { createSyncEngine, type SyncEngine } from '@scribe/engine-sync';\nimport { loadSyncConfig, type SyncConfig } from './config/sync-config';\n\n// Add to deps\nconst deps: HandlerDependencies = {\n  vault: null,\n  graphEngine: null,\n  searchEngine: null,\n  taskIndex: null,\n  mainWindow: null,\n  syncEngine: null, // NEW\n};\n\n/**\n * Initialize sync engine if enabled in config.\n * Call after vault is loaded.\n */\nasync function initializeSyncEngine(vaultPath: string): Promise\u003cvoid\u003e {\n  // Load sync configuration\n  const syncConfig = await loadSyncConfig(vaultPath);\n  \n  if (!syncConfig.enabled) {\n    console.log('Sync is disabled, skipping SyncEngine initialization');\n    return;\n  }\n\n  // Create sync database path\n  const syncDbPath = path.join(vaultPath, 'derived', 'sync.sqlite3');\n\n  // Create sync engine\n  deps.syncEngine = createSyncEngine({\n    vaultPath,\n    databasePath: syncDbPath,\n    serverUrl: syncConfig.serverUrl,\n    credentials: syncConfig.credentials, // May be null if not logged in\n    config: {\n      syncIntervalMs: syncConfig.syncIntervalMs ?? 30000,\n      autoSync: syncConfig.autoSync ?? true,\n      conflictStrategy: syncConfig.conflictStrategy ?? 'manual',\n    },\n    // Wire up to EngineOrchestrator for saving pulled notes\n    onSaveNote: async (note) =\u003e {\n      if (deps.vault) {\n        // Save directly to vault (skip sync tracking to avoid loop)\n        await deps.vault.save(note);\n        deps.graphEngine?.addNote(note);\n        deps.searchEngine?.indexNote(note);\n        deps.taskIndex?.indexNote(note);\n      }\n    },\n    onDeleteNote: async (noteId) =\u003e {\n      if (deps.vault) {\n        await deps.vault.delete(noteId);\n        deps.graphEngine?.removeNote(noteId);\n        deps.searchEngine?.removeNote(noteId);\n        deps.taskIndex?.removeNote(noteId);\n      }\n    },\n    onStatusChange: (status) =\u003e {\n      // Forward to renderer\n      deps.mainWindow?.webContents.send(IPC_CHANNELS.SYNC_STATUS_CHANGED, status);\n    },\n  });\n\n  // Initialize sync engine (loads local state, starts auto-sync if enabled)\n  await deps.syncEngine.initialize();\n\n  console.log('SyncEngine initialized');\n}\n\n/**\n * Hook into EngineOrchestrator to track changes for sync.\n * Call after both orchestrator and sync engine are initialized.\n */\nfunction wireOrchestratorToSync(orchestrator: EngineOrchestrator): void {\n  if (!deps.syncEngine) {\n    return;\n  }\n\n  // Override orchestrator save to notify sync\n  const originalSave = orchestrator.saveNote.bind(orchestrator);\n  orchestrator.saveNote = async (note) =\u003e {\n    const result = await originalSave(note);\n    \n    // Notify sync engine of change (it will decide whether to track)\n    if (deps.syncEngine?.isEnabled()) {\n      await deps.syncEngine.trackChange(note, 'update');\n    }\n    \n    return result;\n  };\n\n  // Override orchestrator delete to notify sync\n  const originalDelete = orchestrator.deleteNote.bind(orchestrator);\n  orchestrator.deleteNote = async (noteId) =\u003e {\n    const result = await originalDelete(noteId);\n    \n    if (deps.syncEngine?.isEnabled()) {\n      deps.syncEngine.trackDelete(noteId);\n    }\n    \n    return result;\n  };\n}\n\n// In app ready handler, after vault initialization:\napp.whenReady().then(async () =\u003e {\n  // ... existing vault/engine initialization ...\n\n  // Initialize sync engine (after vault)\n  if (vaultPath) {\n    await initializeSyncEngine(vaultPath);\n    \n    // Wire orchestrator to sync\n    if (orchestrator) {\n      wireOrchestratorToSync(orchestrator);\n    }\n  }\n\n  // ... rest of initialization ...\n});\n\n// In app quit handler:\napp.on('before-quit', async () =\u003e {\n  // Shutdown sync engine gracefully\n  if (deps.syncEngine) {\n    await deps.syncEngine.shutdown();\n  }\n  \n  // ... existing shutdown ...\n});\n```\n\n### Sync Config File: `apps/desktop/electron/main/src/config/sync-config.ts`\n\n```typescript\nimport { readFile, writeFile } from 'fs/promises';\nimport { join } from 'path';\n\nexport interface SyncConfig {\n  enabled: boolean;\n  serverUrl: string;\n  syncIntervalMs: number;\n  autoSync: boolean;\n  conflictStrategy: 'auto' | 'manual';\n  credentials?: {\n    email: string;\n    refreshToken: string;\n  };\n}\n\nconst DEFAULT_CONFIG: SyncConfig = {\n  enabled: false, // Opt-in: disabled by default\n  serverUrl: 'https://sync.scribe.app',\n  syncIntervalMs: 30000,\n  autoSync: true,\n  conflictStrategy: 'manual',\n};\n\nexport async function loadSyncConfig(vaultPath: string): Promise\u003cSyncConfig\u003e {\n  const configPath = join(vaultPath, '.scribe', 'sync.json');\n  \n  try {\n    const content = await readFile(configPath, 'utf-8');\n    return { ...DEFAULT_CONFIG, ...JSON.parse(content) };\n  } catch {\n    // No config file = sync disabled\n    return DEFAULT_CONFIG;\n  }\n}\n\nexport async function saveSyncConfig(\n  vaultPath: string,\n  config: Partial\u003cSyncConfig\u003e\n): Promise\u003cvoid\u003e {\n  const configPath = join(vaultPath, '.scribe', 'sync.json');\n  const current = await loadSyncConfig(vaultPath);\n  const updated = { ...current, ...config };\n  \n  await writeFile(configPath, JSON.stringify(updated, null, 2));\n}\n```\n\n## Verification Criteria\n- [ ] SyncEngine is NOT created when sync is disabled (Phase 0 guard)\n- [ ] SyncEngine initializes correctly when enabled\n- [ ] EngineOrchestrator save/delete notify SyncEngine\n- [ ] Sync config is loaded from `{vault}/.scribe/sync.json`\n- [ ] Shutdown properly cleans up sync resources\n- [ ] Status changes are forwarded to renderer\n\n## Files to Modify\n- `apps/desktop/electron/main/src/main.ts`\n\n## Files to Create\n- `apps/desktop/electron/main/src/config/sync-config.ts`\n\n## Dependencies\n- scribe-hao.16 (SyncEngine main class)\n- scribe-hao.18 (HandlerDependencies with syncEngine)\n- scribe-hao.1 (Phase 0 opt-in guard respected)\n\n## UNBLOCKS\n- scribe-hao.22 (preload bridge)\n- scribe-hao.48 (integration tests for vault migration)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:20.652628-06:00","updated_at":"2025-12-29T14:11:43.000695-06:00","closed_at":"2025-12-29T14:11:43.000695-06:00","close_reason":"Integrated SyncEngine initialization in main.ts with createCredentialManager, proper vault callbacks using createNoteId, and error handling.","dependencies":[{"issue_id":"scribe-hao.21","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:20.653014-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.21","depends_on_id":"scribe-hao.20","type":"blocks","created_at":"2025-12-27T22:03:46.179852-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.22","title":"[Phase 2.6] Implement sync preload bridge","description":"# [Phase 2.6] Implement sync preload bridge\n\n## Problem Statement\nThe preload script must expose sync API to the renderer process. This is the secure bridge that allows React components to call sync operations.\n\n## Why This Architecture\n- **Security**: Only expose intended methods via contextBridge\n- **Type safety**: Match SyncAPI interface from ipc-contract\n- **Event handling**: Support status change listeners\n\n## Implementation\n\n### File: `apps/desktop/electron/preload/src/sync.ts`\n\n```typescript\nimport { ipcRenderer } from 'electron';\nimport { IPC_CHANNELS, type SyncAPI, type SyncStatus, type SyncConflict } from '@scribe/shared';\n\n/**\n * Sync API exposed to renderer via preload bridge.\n * \n * This matches the SyncAPI interface in @scribe/shared/ipc-contract.\n */\nexport const syncApi: SyncAPI = {\n  /**\n   * Check if sync feature is enabled.\n   */\n  isEnabled: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.SYNC_IS_ENABLED),\n\n  /**\n   * Get current sync status.\n   */\n  getStatus: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.SYNC_GET_STATUS),\n\n  /**\n   * Trigger immediate sync cycle.\n   */\n  syncNow: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.SYNC_NOW),\n\n  /**\n   * Get pending conflicts requiring resolution.\n   */\n  getConflicts: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.SYNC_GET_CONFLICTS),\n\n  /**\n   * Resolve a specific conflict.\n   */\n  resolveConflict: (noteId: string, resolution: 'local' | 'remote' | 'keepBoth') =\u003e\n    ipcRenderer.invoke(IPC_CHANNELS.SYNC_RESOLVE_CONFLICT, noteId, resolution),\n\n  /**\n   * Enable sync with credentials.\n   */\n  enable: (credentials: { email: string; token: string }) =\u003e\n    ipcRenderer.invoke(IPC_CHANNELS.SYNC_ENABLE, credentials),\n\n  /**\n   * Disable sync.\n   */\n  disable: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.SYNC_DISABLE),\n\n  /**\n   * Get sync configuration.\n   */\n  getConfig: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.SYNC_GET_CONFIG),\n\n  /**\n   * Update sync configuration.\n   */\n  setConfig: (config: Partial\u003c{ syncIntervalMs: number; autoSync: boolean }\u003e) =\u003e\n    ipcRenderer.invoke(IPC_CHANNELS.SYNC_SET_CONFIG, config),\n\n  /**\n   * Subscribe to sync status changes.\n   * Returns unsubscribe function.\n   */\n  onStatusChange: (callback: (status: SyncStatus) =\u003e void) =\u003e {\n    const handler = (_event: Electron.IpcRendererEvent, status: SyncStatus) =\u003e {\n      callback(status);\n    };\n    ipcRenderer.on(IPC_CHANNELS.SYNC_STATUS_CHANGED, handler);\n    return () =\u003e {\n      ipcRenderer.removeListener(IPC_CHANNELS.SYNC_STATUS_CHANGED, handler);\n    };\n  },\n\n  /**\n   * Subscribe to conflict detection events.\n   * Returns unsubscribe function.\n   */\n  onConflict: (callback: (conflict: SyncConflict) =\u003e void) =\u003e {\n    const handler = (_event: Electron.IpcRendererEvent, conflict: SyncConflict) =\u003e {\n      callback(conflict);\n    };\n    ipcRenderer.on(IPC_CHANNELS.SYNC_CONFLICT_DETECTED, handler);\n    return () =\u003e {\n      ipcRenderer.removeListener(IPC_CHANNELS.SYNC_CONFLICT_DETECTED, handler);\n    };\n  },\n};\n```\n\n### Integrate into Main Preload: `apps/desktop/electron/preload/src/index.ts`\n\n```typescript\nimport { contextBridge } from 'electron';\nimport { syncApi } from './sync';\n\n// ... existing API setup ...\n\nconst api = {\n  // ... existing APIs (notes, search, graph, etc.) ...\n  sync: syncApi,\n};\n\ncontextBridge.exposeInMainWorld('scribe', api);\n```\n\n### Type Declaration: `apps/desktop/renderer/src/types/electron.d.ts`\n\n```typescript\nimport type { ScribeAPI, SyncAPI } from '@scribe/shared';\n\ndeclare global {\n  interface Window {\n    scribe: ScribeAPI \u0026 {\n      sync: SyncAPI;\n    };\n  }\n}\n\nexport {};\n```\n\n## Usage in React\n\n```typescript\n// Check if sync is enabled\nconst enabled = await window.scribe.sync.isEnabled();\n\n// Subscribe to status changes\nuseEffect(() =\u003e {\n  const unsubscribe = window.scribe.sync.onStatusChange((status) =\u003e {\n    console.log('Sync status:', status);\n  });\n  return unsubscribe;\n}, []);\n\n// Trigger sync\nawait window.scribe.sync.syncNow();\n```\n\n## Verification Criteria\n- [ ] `window.scribe.sync` is available in renderer\n- [ ] All SyncAPI methods work correctly\n- [ ] Event subscriptions work and can be unsubscribed\n- [ ] TypeScript types are correct in renderer\n- [ ] No IPC channel leaks (all channels properly scoped)\n\n## Files to Create\n- `apps/desktop/electron/preload/src/sync.ts`\n\n## Files to Modify\n- `apps/desktop/electron/preload/src/index.ts`\n- `apps/desktop/renderer/src/types/electron.d.ts`\n\n## Dependencies\n- scribe-hao.17 (SyncAPI interface in ipc-contract)\n- scribe-hao.20 (sync IPC handlers registered)\n\n## UNBLOCKS\n- scribe-hao.33 (SyncStatusIndicator component)\n- scribe-hao.38 (SyncSettingsPanel component)\n- scribe-hao.40 (useSyncStatus hook)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:20.826239-06:00","updated_at":"2025-12-29T13:58:18.713859-06:00","closed_at":"2025-12-29T13:58:18.713859-06:00","close_reason":"Added sync API to preload with 7 methods (getStatus, trigger, getConflicts, resolveConflict, enable, disable, onStatusChange). Typecheck passes.","dependencies":[{"issue_id":"scribe-hao.22","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:20.826607-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.22","depends_on_id":"scribe-hao.17","type":"blocks","created_at":"2025-12-27T22:03:46.368395-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.23","title":"[Phase 3.1] Create apps/sync-server/ package structure","description":"# [Phase 3.1] Create apps/sync-server/ package structure\n\n## Problem Statement\nCreate the Cloudflare Workers application for the sync server. This includes package configuration, Wrangler setup, and the basic project structure.\n\n## Why This Architecture\n- **Cloudflare Workers**: Edge deployment, global distribution, low latency\n- **D1 Database**: SQLite-compatible, serverless, integrated with Workers\n- **Hono framework**: Lightweight, fast, TypeScript-native routing\n\n## Package Structure\n\n```\napps/\n  sync-server/\n    src/\n      index.ts              # Worker entry point\n      routes/\n        index.ts            # Route aggregator\n        push.ts             # POST /api/push\n        pull.ts             # GET /api/pull\n        auth.ts             # POST /api/auth/*\n        status.ts           # GET /api/status\n      middleware/\n        auth.ts             # JWT/token validation\n        rate-limit.ts       # Request rate limiting\n        error.ts            # Error handling\n      db/\n        migrations/\n          001_initial.sql   # Initial schema\n        queries.ts          # Prepared statements\n        schema.ts           # TypeScript types\n      services/\n        sync.ts             # Sync business logic\n        auth.ts             # Auth business logic\n      types.ts              # Shared types\n    wrangler.toml           # Cloudflare config\n    package.json\n    tsconfig.json\n    vitest.config.ts\n    README.md\n```\n\n## Implementation\n\n### package.json\n\n```json\n{\n  \"name\": \"@scribe/sync-server\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"type\": \"module\",\n  \"scripts\": {\n    \"dev\": \"wrangler dev\",\n    \"deploy\": \"wrangler deploy\",\n    \"deploy:staging\": \"wrangler deploy --env staging\",\n    \"db:migrate\": \"wrangler d1 migrations apply scribe-sync-db\",\n    \"db:migrate:local\": \"wrangler d1 migrations apply scribe-sync-db --local\",\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\",\n    \"lint\": \"eslint .\",\n    \"typecheck\": \"tsc --noEmit\"\n  },\n  \"dependencies\": {\n    \"hono\": \"^4.0.0\"\n  },\n  \"devDependencies\": {\n    \"@cloudflare/workers-types\": \"^4.20240117.0\",\n    \"wrangler\": \"^3.22.0\",\n    \"typescript\": \"^5.7.0\",\n    \"vitest\": \"^2.1.0\"\n  }\n}\n```\n\n### wrangler.toml\n\n```toml\nname = \"scribe-sync-server\"\nmain = \"src/index.ts\"\ncompatibility_date = \"2024-01-01\"\n\n# Development\n[env.development]\nvars = { ENVIRONMENT = \"development\" }\n\n# Staging\n[env.staging]\nvars = { ENVIRONMENT = \"staging\" }\nroute = { pattern = \"sync-staging.scribe.app/*\", zone_name = \"scribe.app\" }\n\n# Production\n[env.production]\nvars = { ENVIRONMENT = \"production\" }\nroute = { pattern = \"sync.scribe.app/*\", zone_name = \"scribe.app\" }\n\n# D1 Database binding\n[[d1_databases]]\nbinding = \"DB\"\ndatabase_name = \"scribe-sync-db\"\ndatabase_id = \"REPLACE_WITH_DATABASE_ID\"\n\n# Rate limiting\n[[kv_namespaces]]\nbinding = \"RATE_LIMIT\"\nid = \"REPLACE_WITH_KV_ID\"\n```\n\n### src/index.ts\n\n```typescript\nimport { Hono } from 'hono';\nimport { cors } from 'hono/cors';\nimport { logger } from 'hono/logger';\nimport { authRoutes } from './routes/auth';\nimport { pushRoute } from './routes/push';\nimport { pullRoute } from './routes/pull';\nimport { statusRoute } from './routes/status';\nimport { authMiddleware } from './middleware/auth';\nimport { rateLimitMiddleware } from './middleware/rate-limit';\nimport { errorMiddleware } from './middleware/error';\nimport type { Env } from './types';\n\nconst app = new Hono\u003c{ Bindings: Env }\u003e();\n\n// Global middleware\napp.use('*', logger());\napp.use('*', cors({\n  origin: ['https://scribe.app', 'http://localhost:3000'],\n  allowMethods: ['GET', 'POST', 'OPTIONS'],\n  allowHeaders: ['Content-Type', 'Authorization'],\n}));\napp.use('*', errorMiddleware());\napp.use('/api/*', rateLimitMiddleware());\n\n// Public routes\napp.get('/health', (c) =\u003e c.json({ status: 'ok', timestamp: Date.now() }));\n\n// Auth routes (some public, some protected)\napp.route('/api/auth', authRoutes);\n\n// Protected routes (require authentication)\napp.use('/api/sync/*', authMiddleware());\napp.route('/api/sync', pushRoute);\napp.route('/api/sync', pullRoute);\napp.route('/api/sync', statusRoute);\n\n// 404 handler\napp.notFound((c) =\u003e c.json({ error: 'Not found' }, 404));\n\nexport default app;\n```\n\n### src/types.ts\n\n```typescript\nexport interface Env {\n  DB: D1Database;\n  RATE_LIMIT: KVNamespace;\n  ENVIRONMENT: 'development' | 'staging' | 'production';\n  JWT_SECRET: string;\n}\n\nexport interface AuthContext {\n  userId: string;\n  email: string;\n}\n```\n\n### tsconfig.json\n\n```json\n{\n  \"extends\": \"../../config/tsconfig/node.json\",\n  \"compilerOptions\": {\n    \"target\": \"ES2022\",\n    \"module\": \"ES2022\",\n    \"moduleResolution\": \"bundler\",\n    \"types\": [\"@cloudflare/workers-types\"]\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n## Verification Criteria\n- [ ] Package structure matches spec\n- [ ] `bun run dev` starts local worker\n- [ ] `/health` endpoint returns OK\n- [ ] TypeScript types work with Workers types\n- [ ] Wrangler config is valid\n\n## Files to Create\n- `apps/sync-server/package.json`\n- `apps/sync-server/wrangler.toml`\n- `apps/sync-server/tsconfig.json`\n- `apps/sync-server/vitest.config.ts`\n- `apps/sync-server/src/index.ts`\n- `apps/sync-server/src/types.ts`\n- `apps/sync-server/README.md`\n\n## Dependencies\n- None (first Phase 3 task)\n\n## UNBLOCKS\n- All other Phase 3 tasks (scribe-hao.24 through scribe-hao.32)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:21.001126-06:00","updated_at":"2025-12-29T13:54:46.606842-06:00","closed_at":"2025-12-29T13:54:46.606842-06:00","close_reason":"Created apps/sync-server/ with Hono-based Cloudflare Worker, wrangler.toml, tsconfig, eslint config. Health and status endpoints working.","dependencies":[{"issue_id":"scribe-hao.23","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:21.001516-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.23","depends_on_id":"scribe-hao.6","type":"blocks","created_at":"2025-12-27T22:04:02.934065-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.24","title":"[Phase 3.2] Implement D1 database schema and migrations","description":"# [Phase 3.2] Implement D1 database schema and migrations\n\n## Problem Statement\nCreate the D1 database schema for the sync server, including users, devices, notes, and change tracking.\n\n## Schema (from GH Issue #54)\n\n```sql\n-- apps/sync-server/src/db/migrations/001_initial.sql\n\n-- Users table\nCREATE TABLE users (\n  id TEXT PRIMARY KEY,\n  email TEXT UNIQUE NOT NULL,\n  api_key_hash TEXT NOT NULL,       -- PBKDF2 hash (not bcrypt - Workers compatible)\n  created_at INTEGER DEFAULT (unixepoch() * 1000),\n  storage_used_bytes INTEGER DEFAULT 0,\n  note_count INTEGER DEFAULT 0\n);\n\n-- Devices per user\nCREATE TABLE devices (\n  id TEXT PRIMARY KEY,\n  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  name TEXT,\n  created_at INTEGER DEFAULT (unixepoch() * 1000),\n  last_seen_at INTEGER\n);\n\nCREATE INDEX idx_devices_user ON devices(user_id);\n\n-- Notes storage\nCREATE TABLE notes (\n  id TEXT NOT NULL,\n  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  version INTEGER NOT NULL DEFAULT 1,\n  content_hash TEXT NOT NULL,\n  content TEXT NOT NULL,              -- Full JSON including type-specific fields\n  note_type TEXT,                     -- 'person' | 'daily' | 'meeting' | etc.\n  created_at INTEGER DEFAULT (unixepoch() * 1000),\n  updated_at INTEGER DEFAULT (unixepoch() * 1000),\n  deleted_at INTEGER,                 -- Soft delete\n  PRIMARY KEY (id, user_id)\n);\n\nCREATE INDEX idx_notes_user ON notes(user_id);\nCREATE INDEX idx_notes_deleted ON notes(user_id, deleted_at) WHERE deleted_at IS NOT NULL;\n\n-- Change log for efficient pull queries\nCREATE TABLE change_log (\n  sequence INTEGER PRIMARY KEY AUTOINCREMENT,\n  user_id TEXT NOT NULL REFERENCES users(id) ON DELETE CASCADE,\n  note_id TEXT NOT NULL,\n  device_id TEXT REFERENCES devices(id),\n  operation TEXT NOT NULL,            -- 'create' | 'update' | 'delete'\n  version INTEGER NOT NULL,\n  content_hash TEXT,\n  created_at INTEGER DEFAULT (unixepoch() * 1000)\n);\n\nCREATE INDEX idx_change_log_user_seq ON change_log(user_id, sequence);\n```\n\n## Query Helpers\n\n```typescript\n// apps/sync-server/src/db/queries.ts\n\nimport type { D1Database, D1Result } from '@cloudflare/workers-types';\n\nexport interface User {\n  id: string;\n  email: string;\n  api_key_hash: string;\n  created_at: number;\n  storage_used_bytes: number;\n  note_count: number;\n}\n\nexport interface Note {\n  id: string;\n  user_id: string;\n  version: number;\n  content_hash: string;\n  content: string;\n  note_type: string | null;\n  created_at: number;\n  updated_at: number;\n  deleted_at: number | null;\n}\n\nexport interface ChangeLogEntry {\n  sequence: number;\n  user_id: string;\n  note_id: string;\n  device_id: string | null;\n  operation: 'create' | 'update' | 'delete';\n  version: number;\n  content_hash: string | null;\n  created_at: number;\n}\n\nexport class SyncQueries {\n  constructor(private db: D1Database) {}\n  \n  // User queries\n  async getUserByEmail(email: string): Promise\u003cUser | null\u003e {\n    return this.db.prepare('SELECT * FROM users WHERE email = ?').bind(email).first\u003cUser\u003e();\n  }\n  \n  async getUserByApiKeyHash(hash: string): Promise\u003cUser | null\u003e {\n    return this.db.prepare('SELECT * FROM users WHERE api_key_hash = ?').bind(hash).first\u003cUser\u003e();\n  }\n  \n  async createUser(id: string, email: string, apiKeyHash: string): Promise\u003cvoid\u003e {\n    await this.db.prepare(\n      'INSERT INTO users (id, email, api_key_hash) VALUES (?, ?, ?)'\n    ).bind(id, email, apiKeyHash).run();\n  }\n  \n  // Note queries\n  async getNote(userId: string, noteId: string): Promise\u003cNote | null\u003e {\n    return this.db.prepare(\n      'SELECT * FROM notes WHERE user_id = ? AND id = ? AND deleted_at IS NULL'\n    ).bind(userId, noteId).first\u003cNote\u003e();\n  }\n  \n  async upsertNote(\n    userId: string,\n    noteId: string,\n    version: number,\n    contentHash: string,\n    content: string,\n    noteType: string | null\n  ): Promise\u003cvoid\u003e {\n    await this.db.prepare(`\n      INSERT INTO notes (id, user_id, version, content_hash, content, note_type, updated_at)\n      VALUES (?, ?, ?, ?, ?, ?, unixepoch() * 1000)\n      ON CONFLICT(id, user_id) DO UPDATE SET\n        version = excluded.version,\n        content_hash = excluded.content_hash,\n        content = excluded.content,\n        note_type = excluded.note_type,\n        updated_at = unixepoch() * 1000\n    `).bind(noteId, userId, version, contentHash, content, noteType).run();\n  }\n  \n  async softDeleteNote(userId: string, noteId: string): Promise\u003cvoid\u003e {\n    await this.db.prepare(\n      'UPDATE notes SET deleted_at = unixepoch() * 1000 WHERE user_id = ? AND id = ?'\n    ).bind(userId, noteId).run();\n  }\n  \n  // Change log queries\n  async appendChangeLog(\n    userId: string,\n    noteId: string,\n    deviceId: string | null,\n    operation: string,\n    version: number,\n    contentHash: string | null\n  ): Promise\u003cnumber\u003e {\n    const result = await this.db.prepare(`\n      INSERT INTO change_log (user_id, note_id, device_id, operation, version, content_hash)\n      VALUES (?, ?, ?, ?, ?, ?)\n    `).bind(userId, noteId, deviceId, operation, version, contentHash).run();\n    return result.meta.last_row_id;\n  }\n  \n  async getChangesSince(\n    userId: string,\n    sinceSequence: number,\n    limit: number\n  ): Promise\u003cChangeLogEntry[]\u003e {\n    return this.db.prepare(`\n      SELECT * FROM change_log\n      WHERE user_id = ? AND sequence \u003e ?\n      ORDER BY sequence ASC\n      LIMIT ?\n    `).bind(userId, sinceSequence, limit).all\u003cChangeLogEntry\u003e().then(r =\u003e r.results);\n  }\n}\n```\n\n## Files to Create\n- `apps/sync-server/src/db/migrations/001_initial.sql`\n- `apps/sync-server/src/db/queries.ts`\n\n## Dependencies\n- scribe-hao.23 (Create sync-server package)\n\n## UNBLOCKS\n- scribe-hao.25 (Auth middleware)\n- scribe-hao.27 (Push endpoint)\n- scribe-hao.28 (Pull endpoint)\n- scribe-hao.31 (SyncService)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:21.17349-06:00","updated_at":"2025-12-29T13:58:18.877709-06:00","closed_at":"2025-12-29T13:58:18.877709-06:00","close_reason":"Created D1 schema with users, devices, notes, change_log tables. Created SyncQueries class with type-safe query helpers.","dependencies":[{"issue_id":"scribe-hao.24","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:21.173832-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.24","depends_on_id":"scribe-hao.23","type":"blocks","created_at":"2025-12-27T22:04:03.135822-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.25","title":"[Phase 3.3] Implement auth middleware with PBKDF2","description":"# [Phase 3.3] Implement auth middleware with PBKDF2\n\n## Problem Statement\nImplement authentication middleware that validates JWT tokens and authenticates requests. Uses PBKDF2 for password hashing since bcrypt is not available in Workers runtime.\n\n## Why This Architecture\n- **PBKDF2**: Web Crypto API native, works in Workers\n- **JWT tokens**: Stateless authentication with refresh tokens\n- **Middleware pattern**: Clean separation of auth logic\n\n## Implementation\n\n### File: `apps/sync-server/src/middleware/auth.ts`\n\n```typescript\nimport { createMiddleware } from 'hono/factory';\nimport type { Context } from 'hono';\nimport type { Env, AuthContext } from '../types';\n\ninterface TokenPayload {\n  sub: string;      // User ID\n  email: string;\n  exp: number;      // Expiration timestamp\n  iat: number;      // Issued at\n  type: 'access' | 'refresh';\n}\n\n/**\n * Auth middleware that validates JWT tokens.\n * \n * Expects Authorization header: \"Bearer \u003ctoken\u003e\"\n * Sets c.get('auth') with user info on success.\n */\nexport const authMiddleware = () =\u003e {\n  return createMiddleware\u003c{ Bindings: Env; Variables: { auth: AuthContext } }\u003e(\n    async (c, next) =\u003e {\n      const authHeader = c.req.header('Authorization');\n      \n      if (!authHeader?.startsWith('Bearer ')) {\n        return c.json({ error: 'Missing or invalid Authorization header' }, 401);\n      }\n\n      const token = authHeader.slice(7);\n\n      try {\n        const payload = await verifyToken(token, c.env.JWT_SECRET);\n\n        if (payload.type !== 'access') {\n          return c.json({ error: 'Invalid token type' }, 401);\n        }\n\n        if (payload.exp \u003c Date.now() / 1000) {\n          return c.json({ error: 'Token expired' }, 401);\n        }\n\n        c.set('auth', {\n          userId: payload.sub,\n          email: payload.email,\n        });\n\n        await next();\n      } catch (error) {\n        return c.json({ error: 'Invalid token' }, 401);\n      }\n    }\n  );\n};\n\n/**\n * Verify and decode a JWT token.\n */\nasync function verifyToken(token: string, secret: string): Promise\u003cTokenPayload\u003e {\n  const [headerB64, payloadB64, signatureB64] = token.split('.');\n\n  if (!headerB64 || !payloadB64 || !signatureB64) {\n    throw new Error('Invalid token format');\n  }\n\n  // Verify signature\n  const data = `${headerB64}.${payloadB64}`;\n  const signature = base64UrlDecode(signatureB64);\n  \n  const key = await crypto.subtle.importKey(\n    'raw',\n    new TextEncoder().encode(secret),\n    { name: 'HMAC', hash: 'SHA-256' },\n    false,\n    ['verify']\n  );\n\n  const valid = await crypto.subtle.verify(\n    'HMAC',\n    key,\n    signature,\n    new TextEncoder().encode(data)\n  );\n\n  if (!valid) {\n    throw new Error('Invalid signature');\n  }\n\n  // Decode payload\n  const payloadJson = new TextDecoder().decode(base64UrlDecode(payloadB64));\n  return JSON.parse(payloadJson);\n}\n\n/**\n * Create a signed JWT token.\n */\nexport async function createToken(\n  payload: Omit\u003cTokenPayload, 'iat'\u003e,\n  secret: string\n): Promise\u003cstring\u003e {\n  const header = { alg: 'HS256', typ: 'JWT' };\n  const fullPayload = { ...payload, iat: Math.floor(Date.now() / 1000) };\n\n  const headerB64 = base64UrlEncode(JSON.stringify(header));\n  const payloadB64 = base64UrlEncode(JSON.stringify(fullPayload));\n  const data = `${headerB64}.${payloadB64}`;\n\n  const key = await crypto.subtle.importKey(\n    'raw',\n    new TextEncoder().encode(secret),\n    { name: 'HMAC', hash: 'SHA-256' },\n    false,\n    ['sign']\n  );\n\n  const signature = await crypto.subtle.sign(\n    'HMAC',\n    key,\n    new TextEncoder().encode(data)\n  );\n\n  const signatureB64 = base64UrlEncode(new Uint8Array(signature));\n  return `${data}.${signatureB64}`;\n}\n\n/**\n * Hash a password using PBKDF2.\n * Workers-compatible alternative to bcrypt.\n */\nexport async function hashPassword(password: string): Promise\u003cstring\u003e {\n  const salt = crypto.getRandomValues(new Uint8Array(16));\n  const hash = await pbkdf2(password, salt, 100000);\n  \n  // Format: iterations$salt$hash (all base64)\n  return `100000$${base64UrlEncode(salt)}$${base64UrlEncode(hash)}`;\n}\n\n/**\n * Verify a password against a stored hash.\n */\nexport async function verifyPassword(\n  password: string,\n  storedHash: string\n): Promise\u003cboolean\u003e {\n  const [iterationsStr, saltB64, hashB64] = storedHash.split('$');\n  const iterations = parseInt(iterationsStr, 10);\n  const salt = base64UrlDecode(saltB64);\n  const expectedHash = base64UrlDecode(hashB64);\n\n  const actualHash = await pbkdf2(password, salt, iterations);\n\n  // Constant-time comparison\n  if (actualHash.length !== expectedHash.length) {\n    return false;\n  }\n  \n  let diff = 0;\n  for (let i = 0; i \u003c actualHash.length; i++) {\n    diff |= actualHash[i] ^ expectedHash[i];\n  }\n  return diff === 0;\n}\n\nasync function pbkdf2(\n  password: string,\n  salt: Uint8Array,\n  iterations: number\n): Promise\u003cUint8Array\u003e {\n  const key = await crypto.subtle.importKey(\n    'raw',\n    new TextEncoder().encode(password),\n    'PBKDF2',\n    false,\n    ['deriveBits']\n  );\n\n  const bits = await crypto.subtle.deriveBits(\n    { name: 'PBKDF2', salt, iterations, hash: 'SHA-256' },\n    key,\n    256\n  );\n\n  return new Uint8Array(bits);\n}\n\nfunction base64UrlEncode(data: string | Uint8Array): string {\n  const bytes = typeof data === 'string' \n    ? new TextEncoder().encode(data) \n    : data;\n  const base64 = btoa(String.fromCharCode(...bytes));\n  return base64.replace(/\\+/g, '-').replace(/\\//g, '_').replace(/=+$/, '');\n}\n\nfunction base64UrlDecode(str: string): Uint8Array {\n  const base64 = str.replace(/-/g, '+').replace(/_/g, '/');\n  const padded = base64 + '='.repeat((4 - (base64.length % 4)) % 4);\n  const binary = atob(padded);\n  return Uint8Array.from(binary, (c) =\u003e c.charCodeAt(0));\n}\n```\n\n## Verification Criteria\n- [ ] `authMiddleware()` rejects requests without Bearer token\n- [ ] Valid tokens pass through and set `auth` context\n- [ ] Expired tokens are rejected\n- [ ] `hashPassword()` produces verifiable hashes\n- [ ] `verifyPassword()` correctly validates passwords\n- [ ] Token creation and verification work end-to-end\n\n## Files to Create\n- `apps/sync-server/src/middleware/auth.ts`\n\n## Dependencies\n- scribe-hao.23 (package structure)\n\n## UNBLOCKS\n- scribe-hao.30 (auth endpoints)\n- scribe-hao.27 (push endpoint - needs auth)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:21.345823-06:00","updated_at":"2025-12-29T13:58:19.042838-06:00","closed_at":"2025-12-29T13:58:19.042838-06:00","close_reason":"Implemented authMiddleware with Bearer token validation, hashApiKey, hashPassword/verifyPassword using PBKDF2, generateApiKey helper.","dependencies":[{"issue_id":"scribe-hao.25","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:21.346185-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.25","depends_on_id":"scribe-hao.23","type":"blocks","created_at":"2025-12-27T22:04:03.332608-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.26","title":"[Phase 3.4] Implement rate limiting middleware","description":"# [Phase 3.4] Implement rate limiting middleware\n\n## Problem Statement\nImplement rate limiting to prevent abuse and ensure fair usage. Uses Cloudflare KV for distributed rate limit tracking.\n\n## Why This Architecture\n- **KV-based**: Distributed across edge locations\n- **Sliding window**: Smoother than fixed windows\n- **Per-user + global**: Different limits for auth vs anon\n\n## Implementation\n\n### File: `apps/sync-server/src/middleware/rate-limit.ts`\n\n```typescript\nimport { createMiddleware } from 'hono/factory';\nimport type { Env, AuthContext } from '../types';\n\ninterface RateLimitConfig {\n  /** Requests allowed per window */\n  limit: number;\n  /** Window size in seconds */\n  windowSeconds: number;\n  /** Key prefix for KV */\n  prefix: string;\n}\n\nconst LIMITS: Record\u003cstring, RateLimitConfig\u003e = {\n  // Authenticated sync operations\n  sync: { limit: 60, windowSeconds: 60, prefix: 'rl:sync:' },\n  // Authentication endpoints\n  auth: { limit: 10, windowSeconds: 60, prefix: 'rl:auth:' },\n  // Anonymous/health endpoints\n  anon: { limit: 30, windowSeconds: 60, prefix: 'rl:anon:' },\n};\n\n/**\n * Rate limiting middleware using Cloudflare KV.\n * \n * Applies different limits based on path and auth status:\n * - /api/sync/*: 60 req/min per user\n * - /api/auth/*: 10 req/min per IP\n * - Other: 30 req/min per IP\n */\nexport const rateLimitMiddleware = () =\u003e {\n  return createMiddleware\u003c{ Bindings: Env; Variables: { auth?: AuthContext } }\u003e(\n    async (c, next) =\u003e {\n      const path = c.req.path;\n      const auth = c.get('auth');\n      \n      // Determine rate limit config and key\n      let config: RateLimitConfig;\n      let key: string;\n\n      if (path.startsWith('/api/sync/')) {\n        config = LIMITS.sync;\n        key = auth?.userId ?? getClientIP(c);\n      } else if (path.startsWith('/api/auth/')) {\n        config = LIMITS.auth;\n        key = getClientIP(c);\n      } else {\n        config = LIMITS.anon;\n        key = getClientIP(c);\n      }\n\n      const fullKey = `${config.prefix}${key}`;\n      const result = await checkRateLimit(c.env.RATE_LIMIT, fullKey, config);\n\n      // Set rate limit headers\n      c.header('X-RateLimit-Limit', config.limit.toString());\n      c.header('X-RateLimit-Remaining', result.remaining.toString());\n      c.header('X-RateLimit-Reset', result.resetAt.toString());\n\n      if (!result.allowed) {\n        c.header('Retry-After', Math.ceil((result.resetAt - Date.now()) / 1000).toString());\n        return c.json(\n          { \n            error: 'Rate limit exceeded',\n            retryAfter: Math.ceil((result.resetAt - Date.now()) / 1000),\n          },\n          429\n        );\n      }\n\n      await next();\n    }\n  );\n};\n\ninterface RateLimitResult {\n  allowed: boolean;\n  remaining: number;\n  resetAt: number;\n}\n\n/**\n * Check and update rate limit using sliding window.\n */\nasync function checkRateLimit(\n  kv: KVNamespace,\n  key: string,\n  config: RateLimitConfig\n): Promise\u003cRateLimitResult\u003e {\n  const now = Date.now();\n  const windowMs = config.windowSeconds * 1000;\n  const windowStart = now - windowMs;\n\n  // Get current window data\n  const data = await kv.get\u003c{ requests: number[] }\u003e(key, 'json');\n  \n  // Filter to requests within current window\n  const requests = (data?.requests ?? []).filter((t) =\u003e t \u003e windowStart);\n  \n  const remaining = Math.max(0, config.limit - requests.length);\n  const resetAt = requests.length \u003e 0 \n    ? requests[0] + windowMs \n    : now + windowMs;\n\n  if (requests.length \u003e= config.limit) {\n    return { allowed: false, remaining: 0, resetAt };\n  }\n\n  // Add current request\n  requests.push(now);\n\n  // Store updated window (expires after window + buffer)\n  await kv.put(key, JSON.stringify({ requests }), {\n    expirationTtl: config.windowSeconds + 60,\n  });\n\n  return { allowed: true, remaining: remaining - 1, resetAt };\n}\n\n/**\n * Get client IP from Cloudflare headers.\n */\nfunction getClientIP(c: Context): string {\n  return (\n    c.req.header('CF-Connecting-IP') ??\n    c.req.header('X-Forwarded-For')?.split(',')[0]?.trim() ??\n    'unknown'\n  );\n}\n```\n\n## Verification Criteria\n- [ ] Rate limits are applied per configuration\n- [ ] Headers correctly report limit/remaining/reset\n- [ ] 429 response includes Retry-After\n- [ ] Sliding window correctly filters old requests\n- [ ] KV entries expire after window\n\n## Files to Create\n- `apps/sync-server/src/middleware/rate-limit.ts`\n\n## Dependencies\n- scribe-hao.23 (package structure with KV binding)\n\n## UNBLOCKS\n- scribe-hao.27 (push endpoint)\n- scribe-hao.28 (pull endpoint)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:21.527761-06:00","updated_at":"2025-12-29T14:03:05.409446-06:00","closed_at":"2025-12-29T14:03:05.409446-06:00","close_reason":"Implemented rate limiting middleware with KV-based sliding window. Created pushRateLimitMiddleware (60/min), pullRateLimitMiddleware (120/min), authRateLimitMiddleware (10/5min).","dependencies":[{"issue_id":"scribe-hao.26","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:21.528172-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.26","depends_on_id":"scribe-hao.23","type":"blocks","created_at":"2025-12-27T22:04:03.528662-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.27","title":"[Phase 3.5] Implement push endpoint","description":"# [Phase 3.5] Implement push endpoint\n\n## Problem Statement\nImplement the POST /api/sync/push endpoint that receives local changes from clients and applies them to the server database.\n\n## Why This Architecture\n- **Optimistic concurrency**: Version checks prevent overwrites\n- **Batch operations**: Multiple changes in single request\n- **Partial success**: Return per-change results\n\n## Implementation\n\n### File: `apps/sync-server/src/routes/push.ts`\n\n```typescript\nimport { Hono } from 'hono';\nimport type { Env, AuthContext } from '../types';\nimport { SyncService } from '../services/sync';\n\ninterface PushChange {\n  noteId: string;\n  changeType: 'create' | 'update' | 'delete';\n  contentHash: string | null;\n  baseVersion: number;  // Client's known version (for conflict detection)\n  note: NotePayload | null;  // null for deletes\n}\n\ninterface NotePayload {\n  id: string;\n  metadata: {\n    title: string;\n    type: string;\n    createdAt: string;\n    updatedAt: string;\n    tags?: string[];\n  };\n  content: unknown;  // Lexical JSON\n}\n\ninterface PushRequest {\n  changes: PushChange[];\n}\n\ninterface PushResult {\n  noteId: string;\n  success: boolean;\n  newVersion?: number;\n  error?: string;\n  conflict?: boolean;\n}\n\ninterface PushResponse {\n  results: PushResult[];\n  serverTime: number;\n}\n\nexport const pushRoute = new Hono\u003c{ Bindings: Env; Variables: { auth: AuthContext } }\u003e();\n\n/**\n * POST /api/sync/push\n * \n * Receives local changes and applies them to server.\n * Returns per-change success/failure with new versions.\n */\npushRoute.post('/push', async (c) =\u003e {\n  const auth = c.get('auth');\n  const body = await c.req.json\u003cPushRequest\u003e();\n\n  if (!body.changes || !Array.isArray(body.changes)) {\n    return c.json({ error: 'Invalid request: changes array required' }, 400);\n  }\n\n  if (body.changes.length \u003e 100) {\n    return c.json({ error: 'Too many changes (max 100)' }, 400);\n  }\n\n  const syncService = new SyncService(c.env.DB);\n  const results: PushResult[] = [];\n\n  for (const change of body.changes) {\n    try {\n      const result = await processChange(syncService, auth.userId, change);\n      results.push(result);\n    } catch (error) {\n      results.push({\n        noteId: change.noteId,\n        success: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n      });\n    }\n  }\n\n  const response: PushResponse = {\n    results,\n    serverTime: Date.now(),\n  };\n\n  return c.json(response);\n});\n\nasync function processChange(\n  syncService: SyncService,\n  userId: string,\n  change: PushChange\n): Promise\u003cPushResult\u003e {\n  // Validate change\n  if (!change.noteId) {\n    return { noteId: '', success: false, error: 'Missing noteId' };\n  }\n\n  switch (change.changeType) {\n    case 'create':\n      return await handleCreate(syncService, userId, change);\n    case 'update':\n      return await handleUpdate(syncService, userId, change);\n    case 'delete':\n      return await handleDelete(syncService, userId, change);\n    default:\n      return { noteId: change.noteId, success: false, error: 'Invalid changeType' };\n  }\n}\n\nasync function handleCreate(\n  syncService: SyncService,\n  userId: string,\n  change: PushChange\n): Promise\u003cPushResult\u003e {\n  if (!change.note) {\n    return { noteId: change.noteId, success: false, error: 'Note payload required for create' };\n  }\n\n  // Check if note already exists\n  const existing = await syncService.getNote(userId, change.noteId);\n  if (existing) {\n    return { \n      noteId: change.noteId, \n      success: false, \n      error: 'Note already exists',\n      conflict: true,\n    };\n  }\n\n  const version = await syncService.createNote(userId, change.noteId, change.note, change.contentHash);\n  \n  return { noteId: change.noteId, success: true, newVersion: version };\n}\n\nasync function handleUpdate(\n  syncService: SyncService,\n  userId: string,\n  change: PushChange\n): Promise\u003cPushResult\u003e {\n  if (!change.note) {\n    return { noteId: change.noteId, success: false, error: 'Note payload required for update' };\n  }\n\n  // Get current server version\n  const existing = await syncService.getNote(userId, change.noteId);\n  if (!existing) {\n    return { noteId: change.noteId, success: false, error: 'Note not found' };\n  }\n\n  // Optimistic concurrency check\n  if (existing.version !== change.baseVersion) {\n    return {\n      noteId: change.noteId,\n      success: false,\n      error: 'Version conflict',\n      conflict: true,\n    };\n  }\n\n  const newVersion = await syncService.updateNote(\n    userId,\n    change.noteId,\n    change.note,\n    change.contentHash,\n    change.baseVersion\n  );\n\n  return { noteId: change.noteId, success: true, newVersion };\n}\n\nasync function handleDelete(\n  syncService: SyncService,\n  userId: string,\n  change: PushChange\n): Promise\u003cPushResult\u003e {\n  // Version check for deletes too\n  const existing = await syncService.getNote(userId, change.noteId);\n  if (!existing) {\n    // Already deleted - consider success\n    return { noteId: change.noteId, success: true };\n  }\n\n  if (existing.version !== change.baseVersion) {\n    return {\n      noteId: change.noteId,\n      success: false,\n      error: 'Version conflict - note was modified',\n      conflict: true,\n    };\n  }\n\n  await syncService.deleteNote(userId, change.noteId);\n  \n  return { noteId: change.noteId, success: true };\n}\n```\n\n## Verification Criteria\n- [ ] Creates new notes with version 1\n- [ ] Updates increment version on success\n- [ ] Version conflicts are detected and reported\n- [ ] Deletes create tombstones\n- [ ] Batch of 100 changes works within timeout\n- [ ] Invalid requests return 400\n\n## Files to Create\n- `apps/sync-server/src/routes/push.ts`\n\n## Dependencies\n- scribe-hao.24 (D1 schema)\n- scribe-hao.25 (auth middleware)\n- scribe-hao.31 (SyncService)\n\n## UNBLOCKS\n- scribe-hao.45 (integration tests for sync flow)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:21.710336-06:00","updated_at":"2025-12-29T14:08:18.707917-06:00","closed_at":"2025-12-29T14:08:18.707917-06:00","close_reason":"Implemented POST /v1/sync/push endpoint with version conflict detection, per-change processing, change logging. Returns accepted/conflicts/errors arrays.","dependencies":[{"issue_id":"scribe-hao.27","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:21.710671-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.27","depends_on_id":"scribe-hao.25","type":"blocks","created_at":"2025-12-27T22:04:03.724602-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.27","depends_on_id":"scribe-hao.26","type":"blocks","created_at":"2025-12-27T22:04:03.921446-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.28","title":"[Phase 3.6] Implement pull endpoint","description":"# [Phase 3.6] Implement pull endpoint\n\n## Problem Statement\nImplement the GET /api/sync/pull endpoint that returns changes since a given sync token. Clients use this to receive remote changes.\n\n## Why This Architecture\n- **Sync token**: Opaque cursor for incremental sync\n- **Batched response**: Limit changes per request\n- **Tombstones included**: Clients learn about deletes\n\n## Implementation\n\n### File: `apps/sync-server/src/routes/pull.ts`\n\n```typescript\nimport { Hono } from 'hono';\nimport type { Env, AuthContext } from '../types';\nimport { SyncService, type SyncChange } from '../services/sync';\n\ninterface PullResponse {\n  changes: SyncChange[];\n  syncToken: string;\n  hasMore: boolean;\n  serverTime: number;\n}\n\nexport const pullRoute = new Hono\u003c{ Bindings: Env; Variables: { auth: AuthContext } }\u003e();\n\n/**\n * GET /api/sync/pull\n * \n * Returns changes since the provided sync token.\n * \n * Query params:\n * - token: Sync token from previous pull (empty for initial sync)\n * - limit: Max changes to return (default 100, max 500)\n */\npullRoute.get('/pull', async (c) =\u003e {\n  const auth = c.get('auth');\n  const token = c.req.query('token') ?? '';\n  const limitParam = c.req.query('limit');\n  const limit = Math.min(parseInt(limitParam ?? '100', 10) || 100, 500);\n\n  const syncService = new SyncService(c.env.DB);\n\n  // Parse sync token (format: \"timestamp:lastId\" or empty)\n  const { sinceTimestamp, lastId } = parseSyncToken(token);\n\n  // Fetch changes since token\n  const changes = await syncService.getChangesSince(\n    auth.userId,\n    sinceTimestamp,\n    lastId,\n    limit + 1  // Fetch one extra to detect hasMore\n  );\n\n  // Check if there are more changes\n  const hasMore = changes.length \u003e limit;\n  const returnedChanges = hasMore ? changes.slice(0, limit) : changes;\n\n  // Generate new sync token\n  const newToken = generateSyncToken(returnedChanges);\n\n  const response: PullResponse = {\n    changes: returnedChanges,\n    syncToken: newToken,\n    hasMore,\n    serverTime: Date.now(),\n  };\n\n  return c.json(response);\n});\n\n/**\n * Parse sync token into components.\n * Token format: \"timestamp:lastNoteId\" or empty string for initial sync.\n */\nfunction parseSyncToken(token: string): { sinceTimestamp: number; lastId: string } {\n  if (!token) {\n    return { sinceTimestamp: 0, lastId: '' };\n  }\n\n  const [timestampStr, lastId] = token.split(':');\n  const sinceTimestamp = parseInt(timestampStr, 10);\n\n  if (isNaN(sinceTimestamp)) {\n    return { sinceTimestamp: 0, lastId: '' };\n  }\n\n  return { sinceTimestamp, lastId: lastId ?? '' };\n}\n\n/**\n * Generate sync token from changes.\n * Uses the last change's timestamp and ID as cursor.\n */\nfunction generateSyncToken(changes: SyncChange[]): string {\n  if (changes.length === 0) {\n    return '';\n  }\n\n  const lastChange = changes[changes.length - 1];\n  return `${lastChange.timestamp}:${lastChange.noteId}`;\n}\n```\n\n### SyncChange Type (in services/sync.ts)\n\n```typescript\nexport interface SyncChange {\n  noteId: string;\n  changeType: 'create' | 'update' | 'delete';\n  serverVersion: number;\n  contentHash: string | null;\n  timestamp: number;\n  note: NotePayload | null;  // null for deletes, full note for create/update\n}\n```\n\n## Initial Sync Flow\n\nFor initial sync (empty token):\n1. Server returns all non-deleted notes\n2. Client stores each note and version\n3. Client stores sync token for next pull\n\n## Incremental Sync Flow\n\nFor subsequent syncs:\n1. Client sends last sync token\n2. Server returns only changes since that token\n3. Client applies changes and updates local versions\n4. Client stores new sync token\n\n## Verification Criteria\n- [ ] Empty token returns all notes (initial sync)\n- [ ] Token returns only newer changes\n- [ ] Deletes appear as tombstone entries\n- [ ] `hasMore` correctly indicates pagination\n- [ ] Token format is opaque but parseable\n- [ ] Large vaults paginate correctly\n\n## Files to Create\n- `apps/sync-server/src/routes/pull.ts`\n\n## Dependencies\n- scribe-hao.24 (D1 schema)\n- scribe-hao.25 (auth middleware)\n- scribe-hao.31 (SyncService)\n\n## UNBLOCKS\n- scribe-hao.45 (integration tests for sync flow)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:21.915037-06:00","updated_at":"2025-12-29T14:11:43.162992-06:00","closed_at":"2025-12-29T14:11:43.162992-06:00","close_reason":"Implemented POST /v1/sync/pull endpoint with change log queries, pagination (hasMore), note content retrieval. Typecheck passes.","dependencies":[{"issue_id":"scribe-hao.28","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:21.915395-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.28","depends_on_id":"scribe-hao.24","type":"blocks","created_at":"2025-12-27T22:04:04.122873-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.28","depends_on_id":"scribe-hao.27","type":"blocks","created_at":"2025-12-27T22:04:04.322969-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.29","title":"[Phase 3.7] Implement status endpoint","description":"# [Phase 3.7] Implement status endpoint\n\n## Problem Statement\nImplement the GET /api/sync/status endpoint that returns sync health and account info. Used by clients to check connectivity and sync state.\n\n## Implementation\n\n### File: `apps/sync-server/src/routes/status.ts`\n\n```typescript\nimport { Hono } from 'hono';\nimport type { Env, AuthContext } from '../types';\nimport { SyncService } from '../services/sync';\n\ninterface SyncStatus {\n  connected: true;\n  account: {\n    email: string;\n    userId: string;\n  };\n  stats: {\n    noteCount: number;\n    lastSyncAt: number | null;\n    storageUsedBytes: number;\n    storageLimitBytes: number;\n  };\n  serverTime: number;\n}\n\nexport const statusRoute = new Hono\u003c{ Bindings: Env; Variables: { auth: AuthContext } }\u003e();\n\n/**\n * GET /api/sync/status\n * \n * Returns sync status and account info.\n * Useful for checking connectivity and sync health.\n */\nstatusRoute.get('/status', async (c) =\u003e {\n  const auth = c.get('auth');\n  const syncService = new SyncService(c.env.DB);\n\n  const stats = await syncService.getUserStats(auth.userId);\n\n  const response: SyncStatus = {\n    connected: true,\n    account: {\n      email: auth.email,\n      userId: auth.userId,\n    },\n    stats: {\n      noteCount: stats.noteCount,\n      lastSyncAt: stats.lastSyncAt,\n      storageUsedBytes: stats.storageUsedBytes,\n      storageLimitBytes: 100 * 1024 * 1024, // 100MB limit\n    },\n    serverTime: Date.now(),\n  };\n\n  return c.json(response);\n});\n\n/**\n * GET /api/sync/quota\n * \n * Returns detailed storage quota info.\n */\nstatusRoute.get('/quota', async (c) =\u003e {\n  const auth = c.get('auth');\n  const syncService = new SyncService(c.env.DB);\n\n  const quota = await syncService.getQuotaDetails(auth.userId);\n\n  return c.json({\n    used: quota.usedBytes,\n    limit: quota.limitBytes,\n    percentage: Math.round((quota.usedBytes / quota.limitBytes) * 100),\n    noteCount: quota.noteCount,\n    largestNotes: quota.largestNotes, // Top 5 largest notes\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Returns correct note count\n- [ ] Storage calculation is accurate\n- [ ] Last sync timestamp updates on push/pull\n- [ ] Server time helps client detect clock drift\n\n## Files to Create\n- `apps/sync-server/src/routes/status.ts`\n\n## Dependencies\n- scribe-hao.24 (D1 schema)\n- scribe-hao.25 (auth middleware)\n- scribe-hao.31 (SyncService)\n\n## UNBLOCKS\n- scribe-hao.33 (SyncStatusIndicator - uses status endpoint)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:22.096661-06:00","updated_at":"2025-12-29T14:11:43.328832-06:00","closed_at":"2025-12-29T14:11:43.328832-06:00","close_reason":"Implemented GET /v1/sync/status and GET /v1/sync/stats endpoints returning server info, user info, and sync statistics.","dependencies":[{"issue_id":"scribe-hao.29","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:22.099085-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.29","depends_on_id":"scribe-hao.24","type":"blocks","created_at":"2025-12-27T22:04:04.515447-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.29","depends_on_id":"scribe-hao.27","type":"blocks","created_at":"2025-12-27T22:04:04.707921-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.3","title":"[Phase 0.3] Add sync toggle to Settings UI","description":"# [Phase 0.3] Define sync settings schema and config file structure\n\n## Problem Statement\nBefore any UI or sync engine work, we need to define the structure of the sync configuration. This is a **schema definition task**, not a UI task.\n\n## Why Phase 0\n- The config schema is needed by Phase 1 (loadSyncConfig)\n- No UI components required - just TypeScript types and JSON schema\n- Enables Phase 1 to implement config loading\n\n## Sync Configuration Schema\n\n### File Location\n`{vault}/.scribe/sync.json`\n\n**Why vault-level (not app-level)?**\n- Different vaults can have different sync settings\n- Corporate vault might have sync disabled while personal vault has it enabled\n- Follows existing pattern of vault-specific config\n\n### Schema Definition\n```typescript\n// packages/engine-sync/src/sync-config.ts\n\n/**\n * Sync configuration stored at {vault}/.scribe/sync.json\n * \n * This file is created when user enables sync and contains\n * all vault-specific sync settings.\n */\nexport interface SyncConfig {\n  /** Whether sync is enabled for this vault */\n  enabled: boolean;\n  \n  /** Sync server URL (default: production Scribe server) */\n  serverUrl: string;\n  \n  /** Unique device identifier (generated on first enable) */\n  deviceId: string;\n  \n  /** Timestamp when sync was enabled (for migration tracking) */\n  enabledAt: number;\n  \n  /** Last known server sequence number (for pull cursor) */\n  lastSyncSequence: number;\n  \n  /** Sync interval in milliseconds (default: 30000) */\n  syncIntervalMs: number;\n}\n\n/**\n * Default values for new sync configs\n */\nexport const DEFAULT_SYNC_CONFIG: Partial\u003cSyncConfig\u003e = {\n  serverUrl: 'https://sync.scribe.app',\n  syncIntervalMs: 30000,\n  lastSyncSequence: 0,\n};\n\n/**\n * Load sync config from vault.\n * Returns null if sync was never enabled (file doesn't exist).\n */\nexport async function loadSyncConfig(vaultPath: string): Promise\u003cSyncConfig | null\u003e {\n  const configPath = path.join(vaultPath, '.scribe', 'sync.json');\n  try {\n    const content = await fs.readFile(configPath, 'utf-8');\n    return JSON.parse(content) as SyncConfig;\n  } catch {\n    return null;\n  }\n}\n\n/**\n * Save sync config to vault.\n * Creates .scribe directory if needed.\n */\nexport async function saveSyncConfig(\n  vaultPath: string, \n  config: SyncConfig\n): Promise\u003cvoid\u003e {\n  const scribeDir = path.join(vaultPath, '.scribe');\n  await fs.mkdir(scribeDir, { recursive: true });\n  \n  const configPath = path.join(scribeDir, 'sync.json');\n  await fs.writeFile(configPath, JSON.stringify(config, null, 2));\n}\n```\n\n### JSON Schema (for validation)\n```json\n{\n  \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n  \"type\": \"object\",\n  \"required\": [\"enabled\", \"serverUrl\", \"deviceId\", \"enabledAt\"],\n  \"properties\": {\n    \"enabled\": { \"type\": \"boolean\" },\n    \"serverUrl\": { \"type\": \"string\", \"format\": \"uri\" },\n    \"deviceId\": { \"type\": \"string\", \"minLength\": 32 },\n    \"enabledAt\": { \"type\": \"integer\", \"minimum\": 0 },\n    \"lastSyncSequence\": { \"type\": \"integer\", \"minimum\": 0 },\n    \"syncIntervalMs\": { \"type\": \"integer\", \"minimum\": 5000 }\n  }\n}\n```\n\n## Security Note\n**API key is NOT stored in this config file.** It's stored securely using Electron's safeStorage (see scribe-hao.53).\n\n## Verification Criteria\n- [ ] TypeScript interfaces defined\n- [ ] loadSyncConfig returns null when file missing\n- [ ] saveSyncConfig creates .scribe directory if needed\n- [ ] JSON schema matches TypeScript interface\n\n## Files to Create\n- `packages/engine-sync/src/sync-config.ts`\n- `packages/engine-sync/src/sync-config.test.ts`\n\n## Dependencies\n- None (pure schema definition)\n\n## UNBLOCKS\n- scribe-hao.1 (uses loadSyncConfig pattern)\n- scribe-hao.5 (engine-sync package includes this)\n- scribe-hao.38 (SyncSettingsPanel UI - Phase 4)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-27T21:28:17.39825-06:00","updated_at":"2025-12-29T13:04:07.238806-06:00","closed_at":"2025-12-29T13:04:07.238806-06:00","close_reason":"Created SyncConfig interface and DEFAULT_SYNC_CONFIG in @scribe/shared with 11 unit tests. All types exported and tests pass.","dependencies":[{"issue_id":"scribe-hao.3","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:17.398614-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.3","depends_on_id":"scribe-hao.2","type":"blocks","created_at":"2025-12-27T22:03:08.22258-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.30","title":"[Phase 3.8] Implement auth endpoints (register, login, refresh)","description":"# [Phase 3.8] Implement auth endpoints (register, login, refresh)\n\n## Problem Statement\nImplement authentication endpoints for user registration, login, and token refresh. Uses PBKDF2 password hashing for Workers compatibility.\n\n## Implementation\n\n### File: `apps/sync-server/src/routes/auth.ts`\n\n```typescript\nimport { Hono } from 'hono';\nimport type { Env } from '../types';\nimport { hashPassword, verifyPassword, createToken } from '../middleware/auth';\n\nconst ACCESS_TOKEN_EXPIRY = 15 * 60; // 15 minutes\nconst REFRESH_TOKEN_EXPIRY = 30 * 24 * 60 * 60; // 30 days\n\ninterface RegisterRequest {\n  email: string;\n  password: string;\n}\n\ninterface LoginRequest {\n  email: string;\n  password: string;\n}\n\ninterface RefreshRequest {\n  refreshToken: string;\n}\n\ninterface AuthResponse {\n  accessToken: string;\n  refreshToken: string;\n  expiresIn: number;\n  user: {\n    id: string;\n    email: string;\n  };\n}\n\nexport const authRoutes = new Hono\u003c{ Bindings: Env }\u003e();\n\n/**\n * POST /api/auth/register\n * \n * Create a new account.\n */\nauthRoutes.post('/register', async (c) =\u003e {\n  const body = await c.req.json\u003cRegisterRequest\u003e();\n\n  // Validate input\n  if (!body.email || !isValidEmail(body.email)) {\n    return c.json({ error: 'Invalid email' }, 400);\n  }\n\n  if (!body.password || body.password.length \u003c 8) {\n    return c.json({ error: 'Password must be at least 8 characters' }, 400);\n  }\n\n  // Check if email already exists\n  const existing = await c.env.DB.prepare(\n    'SELECT id FROM users WHERE email = ?'\n  ).bind(body.email.toLowerCase()).first();\n\n  if (existing) {\n    return c.json({ error: 'Email already registered' }, 409);\n  }\n\n  // Create user\n  const userId = crypto.randomUUID();\n  const passwordHash = await hashPassword(body.password);\n  const now = Date.now();\n\n  await c.env.DB.prepare(\n    `INSERT INTO users (id, email, password_hash, created_at, updated_at)\n     VALUES (?, ?, ?, ?, ?)`\n  ).bind(userId, body.email.toLowerCase(), passwordHash, now, now).run();\n\n  // Generate tokens\n  const tokens = await generateTokens(userId, body.email, c.env.JWT_SECRET);\n\n  const response: AuthResponse = {\n    ...tokens,\n    user: { id: userId, email: body.email.toLowerCase() },\n  };\n\n  return c.json(response, 201);\n});\n\n/**\n * POST /api/auth/login\n * \n * Authenticate and get tokens.\n */\nauthRoutes.post('/login', async (c) =\u003e {\n  const body = await c.req.json\u003cLoginRequest\u003e();\n\n  if (!body.email || !body.password) {\n    return c.json({ error: 'Email and password required' }, 400);\n  }\n\n  // Find user\n  const user = await c.env.DB.prepare(\n    'SELECT id, email, password_hash FROM users WHERE email = ?'\n  ).bind(body.email.toLowerCase()).first\u003c{ id: string; email: string; password_hash: string }\u003e();\n\n  if (!user) {\n    return c.json({ error: 'Invalid credentials' }, 401);\n  }\n\n  // Verify password\n  const valid = await verifyPassword(body.password, user.password_hash);\n  if (!valid) {\n    return c.json({ error: 'Invalid credentials' }, 401);\n  }\n\n  // Update last login\n  await c.env.DB.prepare(\n    'UPDATE users SET last_login_at = ? WHERE id = ?'\n  ).bind(Date.now(), user.id).run();\n\n  // Generate tokens\n  const tokens = await generateTokens(user.id, user.email, c.env.JWT_SECRET);\n\n  const response: AuthResponse = {\n    ...tokens,\n    user: { id: user.id, email: user.email },\n  };\n\n  return c.json(response);\n});\n\n/**\n * POST /api/auth/refresh\n * \n * Exchange refresh token for new access token.\n */\nauthRoutes.post('/refresh', async (c) =\u003e {\n  const body = await c.req.json\u003cRefreshRequest\u003e();\n\n  if (!body.refreshToken) {\n    return c.json({ error: 'Refresh token required' }, 400);\n  }\n\n  try {\n    // Verify refresh token\n    const payload = await verifyRefreshToken(body.refreshToken, c.env.JWT_SECRET);\n\n    // Check if user still exists\n    const user = await c.env.DB.prepare(\n      'SELECT id, email FROM users WHERE id = ?'\n    ).bind(payload.sub).first\u003c{ id: string; email: string }\u003e();\n\n    if (!user) {\n      return c.json({ error: 'User not found' }, 401);\n    }\n\n    // Generate new tokens\n    const tokens = await generateTokens(user.id, user.email, c.env.JWT_SECRET);\n\n    const response: AuthResponse = {\n      ...tokens,\n      user: { id: user.id, email: user.email },\n    };\n\n    return c.json(response);\n  } catch (error) {\n    return c.json({ error: 'Invalid or expired refresh token' }, 401);\n  }\n});\n\n/**\n * POST /api/auth/logout\n * \n * Invalidate refresh token (optional - for token blacklist).\n */\nauthRoutes.post('/logout', async (c) =\u003e {\n  // For stateless JWT, client just discards tokens\n  // Could add token blacklist in KV for immediate invalidation\n  return c.json({ success: true });\n});\n\nasync function generateTokens(\n  userId: string,\n  email: string,\n  secret: string\n): Promise\u003c{ accessToken: string; refreshToken: string; expiresIn: number }\u003e {\n  const now = Math.floor(Date.now() / 1000);\n\n  const accessToken = await createToken({\n    sub: userId,\n    email,\n    type: 'access',\n    exp: now + ACCESS_TOKEN_EXPIRY,\n  }, secret);\n\n  const refreshToken = await createToken({\n    sub: userId,\n    email,\n    type: 'refresh',\n    exp: now + REFRESH_TOKEN_EXPIRY,\n  }, secret);\n\n  return {\n    accessToken,\n    refreshToken,\n    expiresIn: ACCESS_TOKEN_EXPIRY,\n  };\n}\n\nfunction isValidEmail(email: string): boolean {\n  return /^[^\\s@]+@[^\\s@]+\\.[^\\s@]+$/.test(email);\n}\n```\n\n## Verification Criteria\n- [ ] Registration creates user with hashed password\n- [ ] Duplicate email returns 409\n- [ ] Login with correct password returns tokens\n- [ ] Login with wrong password returns 401\n- [ ] Refresh token generates new access token\n- [ ] Expired refresh token is rejected\n\n## Files to Create\n- `apps/sync-server/src/routes/auth.ts`\n\n## Dependencies\n- scribe-hao.24 (D1 schema with users table)\n- scribe-hao.25 (auth middleware with PBKDF2)\n\n## UNBLOCKS\n- scribe-hao.38 (SyncSettingsPanel - login UI)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:22.284189-06:00","updated_at":"2025-12-29T14:11:43.492253-06:00","closed_at":"2025-12-29T14:11:43.492253-06:00","close_reason":"Implemented auth endpoints: POST /register, POST /login, POST /regenerate. Rate limited, proper validation, API key management.","dependencies":[{"issue_id":"scribe-hao.30","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:22.284501-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.30","depends_on_id":"scribe-hao.24","type":"blocks","created_at":"2025-12-27T22:04:04.902231-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.30","depends_on_id":"scribe-hao.27","type":"blocks","created_at":"2025-12-27T22:04:05.096188-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.31","title":"[Phase 3.9] Implement SyncService with conflict detection","description":"# [Phase 3.9] Implement SyncService with conflict detection\n\n## Problem Statement\nImplement the SyncService class that handles database operations for sync. This is the business logic layer between routes and D1 database.\n\n## Implementation\n\n### File: `apps/sync-server/src/services/sync.ts`\n\n```typescript\nimport type { D1Database } from '@cloudflare/workers-types';\n\nexport interface NotePayload {\n  id: string;\n  metadata: {\n    title: string;\n    type: string;\n    createdAt: string;\n    updatedAt: string;\n    tags?: string[];\n  };\n  content: unknown;\n}\n\nexport interface SyncChange {\n  noteId: string;\n  changeType: 'create' | 'update' | 'delete';\n  serverVersion: number;\n  contentHash: string | null;\n  timestamp: number;\n  note: NotePayload | null;\n}\n\nexport interface StoredNote {\n  id: string;\n  userId: string;\n  version: number;\n  contentHash: string;\n  noteData: string;  // JSON string\n  createdAt: number;\n  updatedAt: number;\n  deletedAt: number | null;\n}\n\nexport interface UserStats {\n  noteCount: number;\n  lastSyncAt: number | null;\n  storageUsedBytes: number;\n}\n\nexport interface QuotaDetails {\n  usedBytes: number;\n  limitBytes: number;\n  noteCount: number;\n  largestNotes: Array\u003c{ noteId: string; title: string; sizeBytes: number }\u003e;\n}\n\n/**\n * SyncService handles all database operations for sync.\n * \n * ## Versioning\n * \n * Each note has a `version` that increments on every change.\n * Clients send `baseVersion` to detect conflicts:\n * - If server version != baseVersion, conflict occurs\n * - Successful updates return new version\n * \n * ## Tombstones\n * \n * Deleted notes are not removed immediately:\n * - `deleted_at` timestamp is set\n * - Note appears in pull with changeType='delete'\n * - Tombstones are purged after 90 days\n */\nexport class SyncService {\n  constructor(private readonly db: D1Database) {}\n\n  /**\n   * Get a single note by ID.\n   */\n  async getNote(userId: string, noteId: string): Promise\u003cStoredNote | null\u003e {\n    const row = await this.db.prepare(\n      `SELECT * FROM notes WHERE user_id = ? AND id = ? AND deleted_at IS NULL`\n    ).bind(userId, noteId).first\u003cStoredNote\u003e();\n\n    return row ?? null;\n  }\n\n  /**\n   * Create a new note.\n   * @returns Version number (always 1 for new notes)\n   */\n  async createNote(\n    userId: string,\n    noteId: string,\n    note: NotePayload,\n    contentHash: string | null\n  ): Promise\u003cnumber\u003e {\n    const now = Date.now();\n    const noteData = JSON.stringify(note);\n\n    await this.db.prepare(\n      `INSERT INTO notes (id, user_id, version, content_hash, note_data, created_at, updated_at)\n       VALUES (?, ?, 1, ?, ?, ?, ?)`\n    ).bind(noteId, userId, contentHash, noteData, now, now).run();\n\n    await this.updateLastSync(userId);\n    return 1;\n  }\n\n  /**\n   * Update an existing note with version check.\n   * @returns New version number\n   * @throws Error if version conflict\n   */\n  async updateNote(\n    userId: string,\n    noteId: string,\n    note: NotePayload,\n    contentHash: string | null,\n    baseVersion: number\n  ): Promise\u003cnumber\u003e {\n    const now = Date.now();\n    const noteData = JSON.stringify(note);\n    const newVersion = baseVersion + 1;\n\n    const result = await this.db.prepare(\n      `UPDATE notes \n       SET version = ?, content_hash = ?, note_data = ?, updated_at = ?\n       WHERE id = ? AND user_id = ? AND version = ? AND deleted_at IS NULL`\n    ).bind(newVersion, contentHash, noteData, now, noteId, userId, baseVersion).run();\n\n    if (result.meta.changes === 0) {\n      throw new Error('Version conflict or note not found');\n    }\n\n    await this.updateLastSync(userId);\n    return newVersion;\n  }\n\n  /**\n   * Delete a note (creates tombstone).\n   */\n  async deleteNote(userId: string, noteId: string): Promise\u003cvoid\u003e {\n    const now = Date.now();\n\n    await this.db.prepare(\n      `UPDATE notes \n       SET deleted_at = ?, updated_at = ?, version = version + 1\n       WHERE id = ? AND user_id = ? AND deleted_at IS NULL`\n    ).bind(now, now, noteId, userId).run();\n\n    await this.updateLastSync(userId);\n  }\n\n  /**\n   * Get changes since a timestamp for incremental sync.\n   */\n  async getChangesSince(\n    userId: string,\n    sinceTimestamp: number,\n    lastId: string,\n    limit: number\n  ): Promise\u003cSyncChange[]\u003e {\n    // Query notes updated since timestamp, handling pagination\n    const rows = await this.db.prepare(\n      `SELECT id, version, content_hash, note_data, updated_at, deleted_at\n       FROM notes\n       WHERE user_id = ?\n         AND (updated_at \u003e ? OR (updated_at = ? AND id \u003e ?))\n       ORDER BY updated_at ASC, id ASC\n       LIMIT ?`\n    ).bind(userId, sinceTimestamp, sinceTimestamp, lastId, limit).all\u003c{\n      id: string;\n      version: number;\n      content_hash: string | null;\n      note_data: string;\n      updated_at: number;\n      deleted_at: number | null;\n    }\u003e();\n\n    return rows.results.map((row) =\u003e {\n      const isDeleted = row.deleted_at !== null;\n      \n      return {\n        noteId: row.id,\n        changeType: isDeleted ? 'delete' : 'update', // Can't distinguish create from update here\n        serverVersion: row.version,\n        contentHash: row.content_hash,\n        timestamp: row.updated_at,\n        note: isDeleted ? null : JSON.parse(row.note_data),\n      };\n    });\n  }\n\n  /**\n   * Get user stats for status endpoint.\n   */\n  async getUserStats(userId: string): Promise\u003cUserStats\u003e {\n    const stats = await this.db.prepare(\n      `SELECT \n         COUNT(*) as note_count,\n         SUM(LENGTH(note_data)) as storage_used\n       FROM notes\n       WHERE user_id = ? AND deleted_at IS NULL`\n    ).bind(userId).first\u003c{ note_count: number; storage_used: number }\u003e();\n\n    const lastSync = await this.db.prepare(\n      `SELECT last_sync_at FROM users WHERE id = ?`\n    ).bind(userId).first\u003c{ last_sync_at: number | null }\u003e();\n\n    return {\n      noteCount: stats?.note_count ?? 0,\n      lastSyncAt: lastSync?.last_sync_at ?? null,\n      storageUsedBytes: stats?.storage_used ?? 0,\n    };\n  }\n\n  /**\n   * Get detailed quota info.\n   */\n  async getQuotaDetails(userId: string): Promise\u003cQuotaDetails\u003e {\n    const stats = await this.getUserStats(userId);\n\n    const largest = await this.db.prepare(\n      `SELECT id, note_data, LENGTH(note_data) as size_bytes\n       FROM notes\n       WHERE user_id = ? AND deleted_at IS NULL\n       ORDER BY size_bytes DESC\n       LIMIT 5`\n    ).bind(userId).all\u003c{ id: string; note_data: string; size_bytes: number }\u003e();\n\n    return {\n      usedBytes: stats.storageUsedBytes,\n      limitBytes: 100 * 1024 * 1024, // 100MB\n      noteCount: stats.noteCount,\n      largestNotes: largest.results.map((row) =\u003e {\n        const note = JSON.parse(row.note_data) as NotePayload;\n        return {\n          noteId: row.id,\n          title: note.metadata.title,\n          sizeBytes: row.size_bytes,\n        };\n      }),\n    };\n  }\n\n  private async updateLastSync(userId: string): Promise\u003cvoid\u003e {\n    await this.db.prepare(\n      `UPDATE users SET last_sync_at = ? WHERE id = ?`\n    ).bind(Date.now(), userId).run();\n  }\n}\n```\n\n## Verification Criteria\n- [ ] `createNote()` creates with version 1\n- [ ] `updateNote()` increments version and checks baseVersion\n- [ ] Version mismatch throws error\n- [ ] `deleteNote()` sets tombstone, doesn't hard delete\n- [ ] `getChangesSince()` returns paginated results\n- [ ] Stats calculation is accurate\n\n## Files to Create\n- `apps/sync-server/src/services/sync.ts`\n\n## Dependencies\n- scribe-hao.24 (D1 schema)\n\n## UNBLOCKS\n- scribe-hao.27 (push endpoint)\n- scribe-hao.28 (pull endpoint)\n- scribe-hao.29 (status endpoint)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:22.465341-06:00","updated_at":"2025-12-29T14:47:07.300239-06:00","closed_at":"2025-12-29T14:47:07.300239-06:00","close_reason":"SyncService fully implemented with conflict detection, push/pull, user stats","dependencies":[{"issue_id":"scribe-hao.31","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:22.465702-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.31","depends_on_id":"scribe-hao.28","type":"blocks","created_at":"2025-12-27T22:04:05.289952-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.31","depends_on_id":"scribe-hao.29","type":"blocks","created_at":"2025-12-27T22:04:05.481813-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.31","depends_on_id":"scribe-hao.30","type":"blocks","created_at":"2025-12-27T22:04:05.698231-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.32","title":"[Phase 3.10] Deploy to Cloudflare Workers","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:22.648855-06:00","updated_at":"2025-12-29T20:31:22.049271-06:00","closed_at":"2025-12-29T20:31:22.049271-06:00","close_reason":"Not needed for tests - blocked tasks use unstable_dev/miniflare for local testing, no real Cloudflare deployment required","dependencies":[{"issue_id":"scribe-hao.32","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:22.649191-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.32","depends_on_id":"scribe-hao.31","type":"blocks","created_at":"2025-12-27T22:04:05.922227-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.33","title":"[Phase 4.1] Implement SyncStatusIndicator component","description":"# [Phase 4.1] Implement SyncStatusIndicator component\n\n## Problem Statement\nCreate a sync status indicator for the header bar showing current sync state, pending changes, and conflicts.\n\n## UI States (from GH Issue #54)\n\n```\nStates:\n  ✓ Synced           - Green checkmark, all changes synced\n  ↻ Syncing...       - Animated spinner, sync in progress  \n  ⬆ 3 pending        - Yellow up arrow, changes queued\n  ⚠ 2 conflicts      - Orange warning, clickable to open modal\n  ✕ Offline          - Gray X, no network connection\n  ⚠ Error            - Red warning, sync error (clickable for details)\n  (hidden)           - When sync is disabled, show nothing\n```\n\n## Implementation\n\n```tsx\n// apps/desktop/renderer/src/components/sync/SyncStatusIndicator.tsx\n\nimport { useSyncStatus } from '../../hooks/useSyncStatus';\nimport * as styles from './SyncStatusIndicator.css';\n\nexport function SyncStatusIndicator() {\n  const { status, openConflicts, openSettings } = useSyncStatus();\n  \n  // Don't show anything if sync is disabled\n  if (status.state === 'disabled') {\n    return null;\n  }\n  \n  const handleClick = () =\u003e {\n    if (status.conflictCount \u003e 0) {\n      openConflicts();\n    } else if (status.error) {\n      openSettings();\n    }\n  };\n  \n  return (\n    \u003cbutton\n      className={styles.indicator}\n      onClick={handleClick}\n      disabled={status.state === 'syncing'}\n      title={getTooltip(status)}\n    \u003e\n      \u003cspan className={styles.icon[status.state]}\u003e\n        {getIcon(status)}\n      \u003c/span\u003e\n      \u003cspan className={styles.label}\u003e\n        {getLabel(status)}\n      \u003c/span\u003e\n    \u003c/button\u003e\n  );\n}\n\nfunction getIcon(status: SyncStatus): string {\n  switch (status.state) {\n    case 'idle':\n      return status.pendingChanges \u003e 0 ? '⬆' : '✓';\n    case 'syncing':\n      return '↻';\n    case 'offline':\n      return '✕';\n    case 'error':\n      return '⚠';\n    default:\n      return '';\n  }\n}\n\nfunction getLabel(status: SyncStatus): string {\n  if (status.conflictCount \u003e 0) {\n    return `${status.conflictCount} conflict${status.conflictCount \u003e 1 ? 's' : ''}`;\n  }\n  \n  switch (status.state) {\n    case 'idle':\n      return status.pendingChanges \u003e 0 \n        ? `${status.pendingChanges} pending` \n        : 'Synced';\n    case 'syncing':\n      return 'Syncing...';\n    case 'offline':\n      return 'Offline';\n    case 'error':\n      return 'Error';\n    default:\n      return '';\n  }\n}\n\nfunction getTooltip(status: SyncStatus): string {\n  if (status.lastSyncAt) {\n    const ago = formatRelativeTime(status.lastSyncAt);\n    return `Last sync: ${ago}`;\n  }\n  return getLabel(status);\n}\n```\n\n## Styles\n\n```typescript\n// apps/desktop/renderer/src/components/sync/SyncStatusIndicator.css.ts\n\nimport { style, styleVariants } from '@vanilla-extract/css';\nimport { vars } from '@scribe/design-system';\n\nexport const indicator = style({\n  display: 'flex',\n  alignItems: 'center',\n  gap: vars.space[1],\n  padding: `${vars.space[1]} ${vars.space[2]}`,\n  borderRadius: vars.radii.sm,\n  border: 'none',\n  background: 'transparent',\n  cursor: 'pointer',\n  fontSize: vars.fontSizes.sm,\n  \n  ':hover': {\n    background: vars.colors.surface.hover,\n  },\n});\n\nconst iconBase = style({\n  fontSize: vars.fontSizes.md,\n});\n\nexport const icon = styleVariants({\n  idle: [iconBase, { color: vars.colors.success }],\n  syncing: [iconBase, { \n    color: vars.colors.primary,\n    animation: 'spin 1s linear infinite',\n  }],\n  offline: [iconBase, { color: vars.colors.textMuted }],\n  error: [iconBase, { color: vars.colors.error }],\n});\n\nexport const label = style({\n  color: vars.colors.text,\n});\n```\n\n## Files to Create\n- `apps/desktop/renderer/src/components/sync/SyncStatusIndicator.tsx`\n- `apps/desktop/renderer/src/components/sync/SyncStatusIndicator.css.ts`\n- `apps/desktop/renderer/src/components/sync/index.ts`\n\n## Dependencies\n- scribe-hao.40 (useSyncStatus hook)\n- scribe-hao.17 (IPC contract)\n\n## UNBLOCKS\n- scribe-hao.39 (Integrate in header bar)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:22.826077-06:00","updated_at":"2025-12-29T14:21:07.60076-06:00","closed_at":"2025-12-29T14:21:07.60076-06:00","close_reason":"Implemented SyncStatusIndicator component with 20 passing tests. Shows sync state (synced, syncing, pending, conflict, offline, error, disabled) with icons, labels, tooltips, and accessibility attributes.","dependencies":[{"issue_id":"scribe-hao.33","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:22.826418-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.33","depends_on_id":"scribe-hao.22","type":"blocks","created_at":"2025-12-27T22:04:22.380314-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.34","title":"[Phase 4.2] Implement ConflictListModal component","description":"# [Phase 4.2] Implement ConflictListModal component\n\n## Problem Statement\nCreate a modal that displays all pending sync conflicts, allowing users to see which notes have conflicts and navigate to resolve them.\n\n## Why This Architecture\n- **Modal pattern**: Consistent with existing Overlay-based modals\n- **List view**: Shows all conflicts at a glance\n- **Action buttons**: Quick resolution options per conflict\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/components/Sync/ConflictListModal.tsx`\n\n```tsx\nimport { useCallback } from 'react';\nimport { Overlay, Button, Text, Surface } from '@scribe/design-system';\nimport { AlertIcon, ChevronRightIcon } from '@scribe/design-system';\nimport type { SyncConflict } from '@scribe/shared';\nimport * as styles from './ConflictListModal.css';\n\nexport interface ConflictListModalProps {\n  /** Whether the modal is open */\n  isOpen: boolean;\n  /** Callback when modal should close */\n  onClose: () =\u003e void;\n  /** List of pending conflicts */\n  conflicts: SyncConflict[];\n  /** Callback when user wants to view a specific conflict */\n  onViewConflict: (conflict: SyncConflict) =\u003e void;\n  /** Callback for quick resolution */\n  onQuickResolve: (noteId: string, resolution: 'local' | 'remote') =\u003e void;\n}\n\n/**\n * Modal displaying all pending sync conflicts.\n * \n * Shows a list of notes with conflicts, with options to:\n * - View detailed comparison (opens ConflictCompareView)\n * - Quick resolve by keeping local or remote version\n */\nexport function ConflictListModal({\n  isOpen,\n  onClose,\n  conflicts,\n  onViewConflict,\n  onQuickResolve,\n}: ConflictListModalProps) {\n  if (!isOpen) return null;\n\n  return (\n    \u003cOverlay open={isOpen} onClose={onClose} backdrop=\"blur\" closeOnEscape\u003e\n      \u003cSurface className={styles.container} elevation=\"modal\"\u003e\n        \u003cheader className={styles.header}\u003e\n          \u003cAlertIcon size={24} className={styles.alertIcon} /\u003e\n          \u003cdiv\u003e\n            \u003cText as=\"h2\" weight=\"semibold\" size=\"lg\"\u003e\n              Sync Conflicts\n            \u003c/Text\u003e\n            \u003cText as=\"p\" color=\"muted\" size=\"sm\"\u003e\n              {conflicts.length} note{conflicts.length !== 1 ? 's' : ''} need attention\n            \u003c/Text\u003e\n          \u003c/div\u003e\n        \u003c/header\u003e\n\n        \u003cdiv className={styles.list}\u003e\n          {conflicts.map((conflict) =\u003e (\n            \u003cConflictItem\n              key={conflict.noteId}\n              conflict={conflict}\n              onView={() =\u003e onViewConflict(conflict)}\n              onKeepLocal={() =\u003e onQuickResolve(conflict.noteId, 'local')}\n              onKeepRemote={() =\u003e onQuickResolve(conflict.noteId, 'remote')}\n            /\u003e\n          ))}\n        \u003c/div\u003e\n\n        \u003cfooter className={styles.footer}\u003e\n          \u003cButton variant=\"ghost\" onClick={onClose}\u003e\n            Dismiss\n          \u003c/Button\u003e\n          \u003cText size=\"sm\" color=\"muted\"\u003e\n            Resolve conflicts to continue syncing\n          \u003c/Text\u003e\n        \u003c/footer\u003e\n      \u003c/Surface\u003e\n    \u003c/Overlay\u003e\n  );\n}\n\ninterface ConflictItemProps {\n  conflict: SyncConflict;\n  onView: () =\u003e void;\n  onKeepLocal: () =\u003e void;\n  onKeepRemote: () =\u003e void;\n}\n\nfunction ConflictItem({ conflict, onView, onKeepLocal, onKeepRemote }: ConflictItemProps) {\n  const localDate = new Date(conflict.localModifiedAt).toLocaleString();\n  const remoteDate = new Date(conflict.remoteModifiedAt).toLocaleString();\n\n  return (\n    \u003cdiv className={styles.item}\u003e\n      \u003cdiv className={styles.itemContent}\u003e\n        \u003cText weight=\"medium\"\u003e{conflict.localNote.metadata.title}\u003c/Text\u003e\n        \u003cText size=\"sm\" color=\"muted\"\u003e\n          Local: {localDate} | Remote: {remoteDate}\n        \u003c/Text\u003e\n      \u003c/div\u003e\n\n      \u003cdiv className={styles.itemActions}\u003e\n        \u003cButton variant=\"ghost\" size=\"sm\" onClick={onKeepLocal}\u003e\n          Keep Local\n        \u003c/Button\u003e\n        \u003cButton variant=\"ghost\" size=\"sm\" onClick={onKeepRemote}\u003e\n          Keep Remote\n        \u003c/Button\u003e\n        \u003cButton\n          variant=\"subtle\"\n          size=\"sm\"\n          iconRight={\u003cChevronRightIcon size={16} /\u003e}\n          onClick={onView}\n        \u003e\n          Compare\n        \u003c/Button\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### File: `apps/desktop/renderer/src/components/Sync/ConflictListModal.css.ts`\n\n```typescript\nimport { style } from '@vanilla-extract/css';\nimport { vars } from '@scribe/design-system';\n\nexport const container = style({\n  width: '600px',\n  maxHeight: '80vh',\n  display: 'flex',\n  flexDirection: 'column',\n});\n\nexport const header = style({\n  display: 'flex',\n  alignItems: 'flex-start',\n  gap: vars.spacing[3],\n  padding: vars.spacing[4],\n  borderBottom: `1px solid ${vars.color.border.subtle}`,\n});\n\nexport const alertIcon = style({\n  color: vars.color.status.warning,\n  flexShrink: 0,\n});\n\nexport const list = style({\n  flex: 1,\n  overflowY: 'auto',\n  padding: vars.spacing[2],\n});\n\nexport const item = style({\n  display: 'flex',\n  alignItems: 'center',\n  justifyContent: 'space-between',\n  padding: vars.spacing[3],\n  borderRadius: vars.radius.md,\n  ':hover': {\n    backgroundColor: vars.color.surface.hover,\n  },\n});\n\nexport const itemContent = style({\n  flex: 1,\n  minWidth: 0,\n});\n\nexport const itemActions = style({\n  display: 'flex',\n  gap: vars.spacing[2],\n  flexShrink: 0,\n});\n\nexport const footer = style({\n  display: 'flex',\n  alignItems: 'center',\n  justifyContent: 'space-between',\n  padding: vars.spacing[4],\n  borderTop: `1px solid ${vars.color.border.subtle}`,\n});\n```\n\n## Verification Criteria\n- [ ] Modal opens with correct conflict list\n- [ ] Each conflict shows note title and timestamps\n- [ ] \"Keep Local\" resolves with local version\n- [ ] \"Keep Remote\" resolves with remote version\n- [ ] \"Compare\" opens ConflictCompareView\n- [ ] Modal closes after all conflicts resolved\n- [ ] Keyboard accessible (Escape to close)\n\n## Files to Create\n- `apps/desktop/renderer/src/components/Sync/ConflictListModal.tsx`\n- `apps/desktop/renderer/src/components/Sync/ConflictListModal.css.ts`\n\n## Dependencies\n- scribe-hao.22 (preload bridge for conflict data)\n- scribe-hao.33 (SyncStatusIndicator - may trigger this modal)\n\n## UNBLOCKS\n- scribe-hao.35 (ConflictCompareView)\n- scribe-hao.46 (conflict resolution integration tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:23.002319-06:00","updated_at":"2025-12-29T14:47:07.730185-06:00","closed_at":"2025-12-29T14:47:07.730185-06:00","close_reason":"ConflictListModal fully implemented with styling and tests","dependencies":[{"issue_id":"scribe-hao.34","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:23.00264-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.34","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:22.585413-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.35","title":"[Phase 4.3] Implement ConflictCompareView component","description":"# [Phase 4.3] Implement ConflictCompareView component\n\n## Problem Statement\nCreate a side-by-side comparison view for sync conflicts, allowing users to see exactly what changed between local and remote versions before deciding which to keep.\n\n## Why This Architecture\n- **Side-by-side diff**: Clear visual comparison\n- **Metadata display**: Shows who/when for each version\n- **Three resolution options**: Local, Remote, or Keep Both\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/components/Sync/ConflictCompareView.tsx`\n\n```tsx\nimport { useMemo } from 'react';\nimport { Overlay, Button, Text, Surface } from '@scribe/design-system';\nimport { ChevronLeftIcon, CheckIcon, CopyIcon } from '@scribe/design-system';\nimport type { SyncConflict } from '@scribe/shared';\nimport * as styles from './ConflictCompareView.css';\n\nexport interface ConflictCompareViewProps {\n  /** Whether the view is open */\n  isOpen: boolean;\n  /** The conflict to compare */\n  conflict: SyncConflict | null;\n  /** Callback when view should close (back to list) */\n  onBack: () =\u003e void;\n  /** Callback when conflict is resolved */\n  onResolve: (noteId: string, resolution: 'local' | 'remote' | 'keepBoth') =\u003e void;\n}\n\n/**\n * Side-by-side comparison view for a sync conflict.\n * \n * Shows:\n * - Local version on the left\n * - Remote version on the right\n * - Metadata (modified time) for each\n * - Action buttons to resolve\n */\nexport function ConflictCompareView({\n  isOpen,\n  conflict,\n  onBack,\n  onResolve,\n}: ConflictCompareViewProps) {\n  if (!isOpen || !conflict) return null;\n\n  const { localNote, remoteNote, localModifiedAt, remoteModifiedAt } = conflict;\n\n  return (\n    \u003cOverlay open={isOpen} onClose={onBack} backdrop=\"blur\" closeOnEscape\u003e\n      \u003cSurface className={styles.container} elevation=\"modal\"\u003e\n        \u003cheader className={styles.header}\u003e\n          \u003cButton variant=\"ghost\" size=\"sm\" iconLeft={\u003cChevronLeftIcon /\u003e} onClick={onBack}\u003e\n            Back to conflicts\n          \u003c/Button\u003e\n          \u003cText as=\"h2\" weight=\"semibold\" size=\"lg\"\u003e\n            {localNote.metadata.title}\n          \u003c/Text\u003e\n        \u003c/header\u003e\n\n        \u003cdiv className={styles.compareContainer}\u003e\n          {/* Local Version */}\n          \u003cdiv className={styles.versionPanel}\u003e\n            \u003cdiv className={styles.versionHeader}\u003e\n              \u003cText weight=\"semibold\" size=\"md\"\u003eThis Device\u003c/Text\u003e\n              \u003cText size=\"sm\" color=\"muted\"\u003e\n                {new Date(localModifiedAt).toLocaleString()}\n              \u003c/Text\u003e\n            \u003c/div\u003e\n            \u003cdiv className={styles.versionContent}\u003e\n              \u003cNotePreview note={localNote} /\u003e\n            \u003c/div\u003e\n            \u003cdiv className={styles.versionActions}\u003e\n              \u003cButton\n                variant=\"solid\"\n                tone=\"accent\"\n                iconLeft={\u003cCheckIcon /\u003e}\n                onClick={() =\u003e onResolve(conflict.noteId, 'local')}\n              \u003e\n                Keep This Version\n              \u003c/Button\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n\n          {/* Divider */}\n          \u003cdiv className={styles.divider}\u003e\n            \u003cText size=\"sm\" color=\"muted\"\u003eVS\u003c/Text\u003e\n          \u003c/div\u003e\n\n          {/* Remote Version */}\n          \u003cdiv className={styles.versionPanel}\u003e\n            \u003cdiv className={styles.versionHeader}\u003e\n              \u003cText weight=\"semibold\" size=\"md\"\u003eOther Device\u003c/Text\u003e\n              \u003cText size=\"sm\" color=\"muted\"\u003e\n                {new Date(remoteModifiedAt).toLocaleString()}\n              \u003c/Text\u003e\n            \u003c/div\u003e\n            \u003cdiv className={styles.versionContent}\u003e\n              \u003cNotePreview note={remoteNote} /\u003e\n            \u003c/div\u003e\n            \u003cdiv className={styles.versionActions}\u003e\n              \u003cButton\n                variant=\"solid\"\n                tone=\"accent\"\n                iconLeft={\u003cCheckIcon /\u003e}\n                onClick={() =\u003e onResolve(conflict.noteId, 'remote')}\n              \u003e\n                Keep This Version\n              \u003c/Button\u003e\n            \u003c/div\u003e\n          \u003c/div\u003e\n        \u003c/div\u003e\n\n        \u003cfooter className={styles.footer}\u003e\n          \u003cButton\n            variant=\"subtle\"\n            iconLeft={\u003cCopyIcon /\u003e}\n            onClick={() =\u003e onResolve(conflict.noteId, 'keepBoth')}\n          \u003e\n            Keep Both (create copy)\n          \u003c/Button\u003e\n          \u003cText size=\"sm\" color=\"muted\"\u003e\n            Creates a copy named \"{localNote.metadata.title} (conflict copy)\"\n          \u003c/Text\u003e\n        \u003c/footer\u003e\n      \u003c/Surface\u003e\n    \u003c/Overlay\u003e\n  );\n}\n\ninterface NotePreviewProps {\n  note: SyncConflict['localNote'];\n}\n\n/**\n * Preview of a note's content for comparison.\n * Shows a simplified text representation of the Lexical content.\n */\nfunction NotePreview({ note }: NotePreviewProps) {\n  const textContent = useMemo(() =\u003e {\n    // Extract plain text from Lexical JSON for preview\n    return extractTextFromLexical(note.content);\n  }, [note.content]);\n\n  return (\n    \u003cdiv className={styles.preview}\u003e\n      \u003cdiv className={styles.previewMeta}\u003e\n        \u003cText size=\"sm\" color=\"muted\"\u003e\n          Type: {note.metadata.type}\n        \u003c/Text\u003e\n        {note.metadata.tags \u0026\u0026 note.metadata.tags.length \u003e 0 \u0026\u0026 (\n          \u003cText size=\"sm\" color=\"muted\"\u003e\n            Tags: {note.metadata.tags.join(', ')}\n          \u003c/Text\u003e\n        )}\n      \u003c/div\u003e\n      \u003cpre className={styles.previewText}\u003e{textContent}\u003c/pre\u003e\n    \u003c/div\u003e\n  );\n}\n\n/**\n * Extract plain text from Lexical JSON for preview.\n * Simplified extraction - just gets text nodes.\n */\nfunction extractTextFromLexical(content: unknown): string {\n  if (!content || typeof content !== 'object') {\n    return '';\n  }\n\n  const root = content as { root?: { children?: unknown[] } };\n  if (!root.root?.children) {\n    return '';\n  }\n\n  const texts: string[] = [];\n  \n  function extract(node: unknown) {\n    if (!node || typeof node !== 'object') return;\n    \n    const n = node as { type?: string; text?: string; children?: unknown[] };\n    \n    if (n.type === 'text' \u0026\u0026 n.text) {\n      texts.push(n.text);\n    }\n    \n    if (n.children) {\n      for (const child of n.children) {\n        extract(child);\n      }\n      texts.push('\\n');\n    }\n  }\n\n  for (const child of root.root.children) {\n    extract(child);\n  }\n\n  return texts.join('').trim().slice(0, 2000); // Limit preview length\n}\n```\n\n### File: `apps/desktop/renderer/src/components/Sync/ConflictCompareView.css.ts`\n\n```typescript\nimport { style } from '@vanilla-extract/css';\nimport { vars } from '@scribe/design-system';\n\nexport const container = style({\n  width: '900px',\n  maxWidth: '95vw',\n  maxHeight: '85vh',\n  display: 'flex',\n  flexDirection: 'column',\n});\n\nexport const header = style({\n  display: 'flex',\n  alignItems: 'center',\n  gap: vars.spacing[3],\n  padding: vars.spacing[4],\n  borderBottom: `1px solid ${vars.color.border.subtle}`,\n});\n\nexport const compareContainer = style({\n  display: 'flex',\n  flex: 1,\n  overflow: 'hidden',\n});\n\nexport const versionPanel = style({\n  flex: 1,\n  display: 'flex',\n  flexDirection: 'column',\n  minWidth: 0,\n});\n\nexport const versionHeader = style({\n  padding: vars.spacing[3],\n  borderBottom: `1px solid ${vars.color.border.subtle}`,\n  backgroundColor: vars.color.surface.subtle,\n});\n\nexport const versionContent = style({\n  flex: 1,\n  overflow: 'auto',\n  padding: vars.spacing[3],\n});\n\nexport const versionActions = style({\n  padding: vars.spacing[3],\n  borderTop: `1px solid ${vars.color.border.subtle}`,\n  display: 'flex',\n  justifyContent: 'center',\n});\n\nexport const divider = style({\n  width: '1px',\n  backgroundColor: vars.color.border.default,\n  display: 'flex',\n  alignItems: 'center',\n  justifyContent: 'center',\n  padding: `0 ${vars.spacing[2]}`,\n});\n\nexport const preview = style({\n  fontSize: vars.typography.size.sm,\n});\n\nexport const previewMeta = style({\n  marginBottom: vars.spacing[2],\n  display: 'flex',\n  gap: vars.spacing[3],\n});\n\nexport const previewText = style({\n  whiteSpace: 'pre-wrap',\n  fontFamily: 'inherit',\n  margin: 0,\n  color: vars.color.text.default,\n  lineHeight: 1.6,\n});\n\nexport const footer = style({\n  display: 'flex',\n  alignItems: 'center',\n  gap: vars.spacing[3],\n  padding: vars.spacing[4],\n  borderTop: `1px solid ${vars.color.border.subtle}`,\n});\n```\n\n## Verification Criteria\n- [ ] Side-by-side view shows both versions\n- [ ] Timestamps displayed correctly\n- [ ] Content preview is readable\n- [ ] \"Keep This Version\" buttons work for both sides\n- [ ] \"Keep Both\" creates a conflict copy\n- [ ] Back button returns to ConflictListModal\n- [ ] Handles long content gracefully\n\n## Files to Create\n- `apps/desktop/renderer/src/components/Sync/ConflictCompareView.tsx`\n- `apps/desktop/renderer/src/components/Sync/ConflictCompareView.css.ts`\n\n## Dependencies\n- scribe-hao.34 (ConflictListModal navigates here)\n- scribe-hao.22 (preload bridge for resolution)\n\n## UNBLOCKS\n- scribe-hao.46 (conflict resolution integration tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:23.22782-06:00","updated_at":"2025-12-29T14:39:49.980649-06:00","closed_at":"2025-12-29T14:39:49.980649-06:00","close_reason":"ConflictCompareView component implemented with CSS","dependencies":[{"issue_id":"scribe-hao.35","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:23.228223-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.35","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:22.778112-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.36","title":"[Phase 4.4] Implement DeleteConflictModal component","description":"# [Phase 4.4] Implement DeleteConflictModal component\n\n## Problem Statement\nHandle the case where a note was deleted locally but modified on another device (or vice versa). This requires a special UI to explain the situation and let the user choose.\n\n## Why This Architecture\n- **Clear explanation**: Delete conflicts are confusing\n- **Explicit choice**: No silent data loss\n- **Recovery option**: Can always restore\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/components/Sync/DeleteConflictModal.tsx`\n\n```tsx\nimport { Overlay, Button, Text, Surface } from '@scribe/design-system';\nimport { TrashIcon, RefreshIcon, AlertIcon } from '@scribe/design-system';\nimport type { SyncConflict } from '@scribe/shared';\nimport * as styles from './DeleteConflictModal.css';\n\nexport type DeleteConflictType = \n  | 'local-deleted-remote-modified'  // You deleted, someone else edited\n  | 'remote-deleted-local-modified'; // Someone else deleted, you edited\n\nexport interface DeleteConflictModalProps {\n  /** Whether the modal is open */\n  isOpen: boolean;\n  /** The conflict data */\n  conflict: SyncConflict | null;\n  /** Type of delete conflict */\n  conflictType: DeleteConflictType;\n  /** Callback when modal should close */\n  onClose: () =\u003e void;\n  /** Keep the note (restore if deleted locally, or keep local edits) */\n  onKeepNote: () =\u003e void;\n  /** Confirm deletion (delete permanently) */\n  onConfirmDelete: () =\u003e void;\n}\n\n/**\n * Modal for handling delete conflicts during sync.\n * \n * Two scenarios:\n * 1. You deleted a note, but it was edited on another device\n * 2. Note was deleted on another device, but you have local edits\n */\nexport function DeleteConflictModal({\n  isOpen,\n  conflict,\n  conflictType,\n  onClose,\n  onKeepNote,\n  onConfirmDelete,\n}: DeleteConflictModalProps) {\n  if (!isOpen || !conflict) return null;\n\n  const isLocalDelete = conflictType === 'local-deleted-remote-modified';\n  const noteTitle = isLocalDelete \n    ? conflict.remoteNote?.metadata.title \n    : conflict.localNote.metadata.title;\n\n  return (\n    \u003cOverlay open={isOpen} onClose={onClose} backdrop=\"blur\" closeOnEscape\u003e\n      \u003cSurface className={styles.container} elevation=\"modal\"\u003e\n        \u003cdiv className={styles.iconContainer}\u003e\n          \u003cAlertIcon size={48} className={styles.alertIcon} /\u003e\n        \u003c/div\u003e\n\n        \u003cText as=\"h2\" weight=\"semibold\" size=\"lg\" align=\"center\"\u003e\n          Delete Conflict\n        \u003c/Text\u003e\n\n        \u003cText as=\"p\" color=\"muted\" align=\"center\" className={styles.description}\u003e\n          {isLocalDelete ? (\n            \u003c\u003e\n              You deleted \u003cstrong\u003e\"{noteTitle}\"\u003c/strong\u003e on this device,\n              but it was edited on another device.\n            \u003c/\u003e\n          ) : (\n            \u003c\u003e\n              \u003cstrong\u003e\"{noteTitle}\"\u003c/strong\u003e was deleted on another device,\n              but you have unsaved edits on this device.\n            \u003c/\u003e\n          )}\n        \u003c/Text\u003e\n\n        \u003cdiv className={styles.actions}\u003e\n          \u003cButton\n            variant=\"solid\"\n            tone=\"accent\"\n            iconLeft={\u003cRefreshIcon /\u003e}\n            onClick={onKeepNote}\n            className={styles.actionButton}\n          \u003e\n            {isLocalDelete ? 'Restore Note' : 'Keep My Edits'}\n          \u003c/Button\u003e\n\n          \u003cButton\n            variant=\"solid\"\n            tone=\"danger\"\n            iconLeft={\u003cTrashIcon /\u003e}\n            onClick={onConfirmDelete}\n            className={styles.actionButton}\n          \u003e\n            Delete Permanently\n          \u003c/Button\u003e\n        \u003c/div\u003e\n\n        \u003cText size=\"sm\" color=\"muted\" align=\"center\"\u003e\n          {isLocalDelete\n            ? 'Restoring will recover the note with the latest edits from your other device.'\n            : 'Deleting will remove the note and discard your local changes.'}\n        \u003c/Text\u003e\n\n        \u003cButton variant=\"ghost\" onClick={onClose} className={styles.cancelButton}\u003e\n          Cancel\n        \u003c/Button\u003e\n      \u003c/Surface\u003e\n    \u003c/Overlay\u003e\n  );\n}\n```\n\n### File: `apps/desktop/renderer/src/components/Sync/DeleteConflictModal.css.ts`\n\n```typescript\nimport { style } from '@vanilla-extract/css';\nimport { vars } from '@scribe/design-system';\n\nexport const container = style({\n  width: '400px',\n  padding: vars.spacing[6],\n  display: 'flex',\n  flexDirection: 'column',\n  alignItems: 'center',\n  gap: vars.spacing[4],\n});\n\nexport const iconContainer = style({\n  marginBottom: vars.spacing[2],\n});\n\nexport const alertIcon = style({\n  color: vars.color.status.warning,\n});\n\nexport const description = style({\n  maxWidth: '320px',\n});\n\nexport const actions = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[2],\n  width: '100%',\n  marginTop: vars.spacing[2],\n});\n\nexport const actionButton = style({\n  width: '100%',\n});\n\nexport const cancelButton = style({\n  marginTop: vars.spacing[2],\n});\n```\n\n## Verification Criteria\n- [ ] Shows correct message for local-delete scenario\n- [ ] Shows correct message for remote-delete scenario\n- [ ] \"Restore Note\" recovers the note\n- [ ] \"Delete Permanently\" removes the note\n- [ ] Cancel closes without action\n- [ ] Note title displayed correctly\n\n## Files to Create\n- `apps/desktop/renderer/src/components/Sync/DeleteConflictModal.tsx`\n- `apps/desktop/renderer/src/components/Sync/DeleteConflictModal.css.ts`\n\n## Dependencies\n- scribe-hao.22 (preload bridge for resolution)\n\n## UNBLOCKS\n- scribe-hao.46 (conflict resolution integration tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:23.443375-06:00","updated_at":"2025-12-29T14:39:50.149566-06:00","closed_at":"2025-12-29T14:39:50.149566-06:00","close_reason":"DeleteConflictModal component implemented with CSS","dependencies":[{"issue_id":"scribe-hao.36","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:23.443721-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.36","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:22.972127-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.37","title":"[Phase 4.5] Implement SyncProgressModal component","description":"# [Phase 4.5] Implement SyncProgressModal component\n\n## Problem Statement\nShow detailed sync progress during long operations like initial sync or syncing many changes. Provides feedback and allows cancellation.\n\n## Why This Architecture\n- **Progress feedback**: Users know sync is working\n- **Phase indication**: Shows what's happening\n- **Cancel option**: Can abort long syncs\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/components/Sync/SyncProgressModal.tsx`\n\n```tsx\nimport { Overlay, Button, Text, Surface } from '@scribe/design-system';\nimport { SyncIcon, CheckIcon, CloseIcon } from '@scribe/design-system';\nimport type { SyncProgress, SyncPhase } from '@scribe/shared';\nimport * as styles from './SyncProgressModal.css';\n\nexport interface SyncProgressModalProps {\n  /** Whether the modal is open */\n  isOpen: boolean;\n  /** Current sync progress */\n  progress: SyncProgress;\n  /** Callback to cancel sync */\n  onCancel: () =\u003e void;\n  /** Callback when sync completes (to close modal) */\n  onComplete: () =\u003e void;\n}\n\nconst PHASE_LABELS: Record\u003cSyncPhase, string\u003e = {\n  idle: 'Ready',\n  gathering: 'Gathering changes...',\n  pushing: 'Uploading changes...',\n  pulling: 'Downloading changes...',\n  applying: 'Applying changes...',\n  resolving: 'Resolving conflicts...',\n};\n\n/**\n * Modal showing sync progress for long operations.\n * \n * Displays:\n * - Current phase\n * - Progress bar\n * - Items processed / total\n * - Cancel button\n */\nexport function SyncProgressModal({\n  isOpen,\n  progress,\n  onCancel,\n  onComplete,\n}: SyncProgressModalProps) {\n  if (!isOpen) return null;\n\n  const isComplete = progress.phase === 'idle' \u0026\u0026 progress.processedItems \u003e 0;\n  const percentage = progress.totalItems \u003e 0 \n    ? Math.round((progress.processedItems / progress.totalItems) * 100)\n    : 0;\n\n  return (\n    \u003cOverlay open={isOpen} backdrop=\"blur\"\u003e\n      \u003cSurface className={styles.container} elevation=\"modal\"\u003e\n        \u003cdiv className={styles.iconContainer}\u003e\n          {isComplete ? (\n            \u003cCheckIcon size={48} className={styles.successIcon} /\u003e\n          ) : (\n            \u003cSyncIcon size={48} className={styles.syncIcon} /\u003e\n          )}\n        \u003c/div\u003e\n\n        \u003cText as=\"h2\" weight=\"semibold\" size=\"lg\" align=\"center\"\u003e\n          {isComplete ? 'Sync Complete' : 'Syncing...'}\n        \u003c/Text\u003e\n\n        \u003cText as=\"p\" color=\"muted\" align=\"center\"\u003e\n          {isComplete \n            ? `${progress.processedItems} items synchronized`\n            : PHASE_LABELS[progress.phase]\n          }\n        \u003c/Text\u003e\n\n        {!isComplete \u0026\u0026 (\n          \u003c\u003e\n            \u003cdiv className={styles.progressContainer}\u003e\n              \u003cdiv className={styles.progressBar}\u003e\n                \u003cdiv \n                  className={styles.progressFill} \n                  style={{ width: `${percentage}%` }}\n                /\u003e\n              \u003c/div\u003e\n              \u003cText size=\"sm\" color=\"muted\"\u003e\n                {progress.processedItems} / {progress.totalItems}\n              \u003c/Text\u003e\n            \u003c/div\u003e\n\n            {progress.conflicts \u003e 0 \u0026\u0026 (\n              \u003cText size=\"sm\" color=\"warning\" align=\"center\"\u003e\n                {progress.conflicts} conflict{progress.conflicts !== 1 ? 's' : ''} detected\n              \u003c/Text\u003e\n            )}\n          \u003c/\u003e\n        )}\n\n        \u003cdiv className={styles.actions}\u003e\n          {isComplete ? (\n            \u003cButton variant=\"solid\" tone=\"accent\" onClick={onComplete}\u003e\n              Done\n            \u003c/Button\u003e\n          ) : (\n            \u003cButton variant=\"ghost\" tone=\"neutral\" onClick={onCancel}\u003e\n              Cancel\n            \u003c/Button\u003e\n          )}\n        \u003c/div\u003e\n      \u003c/Surface\u003e\n    \u003c/Overlay\u003e\n  );\n}\n```\n\n### File: `apps/desktop/renderer/src/components/Sync/SyncProgressModal.css.ts`\n\n```typescript\nimport { style, keyframes } from '@vanilla-extract/css';\nimport { vars } from '@scribe/design-system';\n\nconst spin = keyframes({\n  '0%': { transform: 'rotate(0deg)' },\n  '100%': { transform: 'rotate(360deg)' },\n});\n\nexport const container = style({\n  width: '320px',\n  padding: vars.spacing[6],\n  display: 'flex',\n  flexDirection: 'column',\n  alignItems: 'center',\n  gap: vars.spacing[3],\n});\n\nexport const iconContainer = style({\n  marginBottom: vars.spacing[2],\n});\n\nexport const syncIcon = style({\n  color: vars.color.accent.default,\n  animation: `${spin} 2s linear infinite`,\n});\n\nexport const successIcon = style({\n  color: vars.color.status.success,\n});\n\nexport const progressContainer = style({\n  width: '100%',\n  display: 'flex',\n  flexDirection: 'column',\n  alignItems: 'center',\n  gap: vars.spacing[2],\n});\n\nexport const progressBar = style({\n  width: '100%',\n  height: '4px',\n  backgroundColor: vars.color.surface.subtle,\n  borderRadius: vars.radius.full,\n  overflow: 'hidden',\n});\n\nexport const progressFill = style({\n  height: '100%',\n  backgroundColor: vars.color.accent.default,\n  borderRadius: vars.radius.full,\n  transition: 'width 0.3s ease',\n});\n\nexport const actions = style({\n  marginTop: vars.spacing[2],\n});\n```\n\n## Verification Criteria\n- [ ] Shows spinning icon during sync\n- [ ] Progress bar fills correctly\n- [ ] Phase labels update appropriately\n- [ ] Conflict count shown when \u003e 0\n- [ ] Cancel button works\n- [ ] Completion state shows checkmark\n- [ ] \"Done\" button closes modal\n\n## Files to Create\n- `apps/desktop/renderer/src/components/Sync/SyncProgressModal.tsx`\n- `apps/desktop/renderer/src/components/Sync/SyncProgressModal.css.ts`\n\n## Dependencies\n- scribe-hao.22 (preload bridge for progress events)\n- scribe-hao.40 (useSyncStatus hook)\n\n## UNBLOCKS\n- scribe-hao.45 (integration tests for sync flow)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:23.72884-06:00","updated_at":"2025-12-29T14:39:50.327336-06:00","closed_at":"2025-12-29T14:39:50.327336-06:00","close_reason":"SyncProgressModal component implemented with CSS","dependencies":[{"issue_id":"scribe-hao.37","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:23.729215-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.37","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:23.162063-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.38","title":"[Phase 4.6] Implement SyncSettingsPanel component","description":"# [Phase 4.6] Implement SyncSettingsPanel component\n\n## Problem Statement\nAdd a \"Sync\" section to the Settings page where users can enable/disable sync, manage their account, and configure sync options.\n\n## Why This Architecture\n- **Settings integration**: Follows existing GeneralSettings pattern\n- **Account management**: Login/logout/register\n- **Configuration**: Sync interval, auto-sync toggle\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/components/Settings/SyncSettings.tsx`\n\n```tsx\nimport { useState, useCallback, useEffect } from 'react';\nimport { Button, Text, SegmentedControl } from '@scribe/design-system';\nimport { SyncIcon, UserIcon, LogoutIcon } from '@scribe/design-system';\nimport { useSyncStatus } from '../../hooks/useSyncStatus';\nimport * as styles from './SyncSettings.css';\n\ninterface SyncConfig {\n  enabled: boolean;\n  syncIntervalMs: number;\n  autoSync: boolean;\n}\n\ninterface UserInfo {\n  email: string;\n  userId: string;\n}\n\n/**\n * Sync settings section for the Settings page.\n * \n * When sync is disabled:\n * - Shows enable button and benefits\n * \n * When sync is enabled but not logged in:\n * - Shows login/register forms\n * \n * When sync is enabled and logged in:\n * - Shows account info and sync options\n */\nexport function SyncSettings() {\n  const { isEnabled, status } = useSyncStatus();\n  const [config, setConfig] = useState\u003cSyncConfig | null\u003e(null);\n  const [user, setUser] = useState\u003cUserInfo | null\u003e(null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [showLoginForm, setShowLoginForm] = useState(false);\n\n  useEffect(() =\u003e {\n    loadSyncConfig();\n  }, []);\n\n  const loadSyncConfig = async () =\u003e {\n    setIsLoading(true);\n    try {\n      const cfg = await window.scribe.sync.getConfig();\n      setConfig(cfg);\n      \n      if (cfg?.enabled) {\n        const statusResult = await window.scribe.sync.getStatus();\n        if (statusResult.enabled \u0026\u0026 statusResult.status?.account) {\n          setUser(statusResult.status.account);\n        }\n      }\n    } finally {\n      setIsLoading(false);\n    }\n  };\n\n  const handleEnableSync = useCallback(async () =\u003e {\n    setShowLoginForm(true);\n  }, []);\n\n  const handleDisableSync = useCallback(async () =\u003e {\n    if (confirm('Are you sure you want to disable sync? Your notes will remain on this device.')) {\n      await window.scribe.sync.disable();\n      setConfig((prev) =\u003e prev ? { ...prev, enabled: false } : null);\n      setUser(null);\n    }\n  }, []);\n\n  const handleLogin = useCallback(async (email: string, password: string) =\u003e {\n    try {\n      await window.scribe.sync.enable({ email, token: password });\n      await loadSyncConfig();\n      setShowLoginForm(false);\n    } catch (error) {\n      alert(error instanceof Error ? error.message : 'Login failed');\n    }\n  }, []);\n\n  const handleLogout = useCallback(async () =\u003e {\n    await window.scribe.sync.disable();\n    setUser(null);\n    setConfig((prev) =\u003e prev ? { ...prev, enabled: false } : null);\n  }, []);\n\n  const handleAutoSyncChange = useCallback(async (value: string) =\u003e {\n    const autoSync = value === 'auto';\n    await window.scribe.sync.setConfig({ autoSync });\n    setConfig((prev) =\u003e prev ? { ...prev, autoSync } : null);\n  }, []);\n\n  if (isLoading) {\n    return \u003cdiv className={styles.loading}\u003eLoading sync settings...\u003c/div\u003e;\n  }\n\n  return (\n    \u003cdiv className={styles.container}\u003e\n      \u003ch2 className={styles.sectionHeading}\u003eSync\u003c/h2\u003e\n      \u003cp className={styles.sectionDescription}\u003e\n        Sync your notes across devices with end-to-end encryption.\n      \u003c/p\u003e\n\n      {!config?.enabled ? (\n        \u003cSyncDisabledState onEnable={handleEnableSync} /\u003e\n      ) : !user ? (\n        showLoginForm ? (\n          \u003cLoginForm onLogin={handleLogin} onCancel={() =\u003e setShowLoginForm(false)} /\u003e\n        ) : (\n          \u003cSyncDisabledState onEnable={handleEnableSync} /\u003e\n        )\n      ) : (\n        \u003cSyncEnabledState\n          user={user}\n          config={config}\n          status={status}\n          onAutoSyncChange={handleAutoSyncChange}\n          onLogout={handleLogout}\n          onDisable={handleDisableSync}\n        /\u003e\n      )}\n    \u003c/div\u003e\n  );\n}\n\nfunction SyncDisabledState({ onEnable }: { onEnable: () =\u003e void }) {\n  return (\n    \u003cdiv className={styles.disabledState}\u003e\n      \u003cSyncIcon size={48} className={styles.syncIcon} /\u003e\n      \u003cText as=\"p\" color=\"muted\" align=\"center\"\u003e\n        Sync is currently disabled. Enable sync to access your notes from any device.\n      \u003c/Text\u003e\n      \u003cButton variant=\"solid\" tone=\"accent\" onClick={onEnable}\u003e\n        Enable Sync\n      \u003c/Button\u003e\n    \u003c/div\u003e\n  );\n}\n\ninterface LoginFormProps {\n  onLogin: (email: string, password: string) =\u003e void;\n  onCancel: () =\u003e void;\n}\n\nfunction LoginForm({ onLogin, onCancel }: LoginFormProps) {\n  const [email, setEmail] = useState('');\n  const [password, setPassword] = useState('');\n  const [isSubmitting, setIsSubmitting] = useState(false);\n\n  const handleSubmit = async (e: React.FormEvent) =\u003e {\n    e.preventDefault();\n    setIsSubmitting(true);\n    try {\n      await onLogin(email, password);\n    } finally {\n      setIsSubmitting(false);\n    }\n  };\n\n  return (\n    \u003cform className={styles.loginForm} onSubmit={handleSubmit}\u003e\n      \u003cinput\n        type=\"email\"\n        placeholder=\"Email\"\n        value={email}\n        onChange={(e) =\u003e setEmail(e.target.value)}\n        className={styles.input}\n        required\n      /\u003e\n      \u003cinput\n        type=\"password\"\n        placeholder=\"Password\"\n        value={password}\n        onChange={(e) =\u003e setPassword(e.target.value)}\n        className={styles.input}\n        required\n      /\u003e\n      \u003cdiv className={styles.loginActions}\u003e\n        \u003cButton type=\"button\" variant=\"ghost\" onClick={onCancel}\u003e\n          Cancel\n        \u003c/Button\u003e\n        \u003cButton type=\"submit\" variant=\"solid\" tone=\"accent\" disabled={isSubmitting}\u003e\n          {isSubmitting ? 'Signing in...' : 'Sign In'}\n        \u003c/Button\u003e\n      \u003c/div\u003e\n      \u003cText size=\"sm\" color=\"muted\" align=\"center\"\u003e\n        Don't have an account?{' '}\n        \u003ca href=\"https://sync.scribe.app/register\" target=\"_blank\" rel=\"noopener\"\u003e\n          Create one\n        \u003c/a\u003e\n      \u003c/Text\u003e\n    \u003c/form\u003e\n  );\n}\n\ninterface SyncEnabledStateProps {\n  user: UserInfo;\n  config: SyncConfig;\n  status: unknown;\n  onAutoSyncChange: (value: string) =\u003e void;\n  onLogout: () =\u003e void;\n  onDisable: () =\u003e void;\n}\n\nfunction SyncEnabledState({\n  user,\n  config,\n  onAutoSyncChange,\n  onLogout,\n  onDisable,\n}: SyncEnabledStateProps) {\n  return (\n    \u003cdiv className={styles.enabledState}\u003e\n      \u003cdiv className={styles.accountSection}\u003e\n        \u003cUserIcon size={24} /\u003e\n        \u003cdiv\u003e\n          \u003cText weight=\"medium\"\u003e{user.email}\u003c/Text\u003e\n          \u003cText size=\"sm\" color=\"muted\"\u003eSigned in\u003c/Text\u003e\n        \u003c/div\u003e\n        \u003cButton variant=\"ghost\" size=\"sm\" iconLeft={\u003cLogoutIcon /\u003e} onClick={onLogout}\u003e\n          Sign out\n        \u003c/Button\u003e\n      \u003c/div\u003e\n\n      \u003cdiv className={styles.settingRow}\u003e\n        \u003cdiv\u003e\n          \u003cText weight=\"medium\"\u003eAuto-sync\u003c/Text\u003e\n          \u003cText size=\"sm\" color=\"muted\"\u003e\n            Automatically sync changes in the background\n          \u003c/Text\u003e\n        \u003c/div\u003e\n        \u003cSegmentedControl\n          value={config.autoSync ? 'auto' : 'manual'}\n          onChange={onAutoSyncChange}\n          options={[\n            { value: 'auto', label: 'Auto' },\n            { value: 'manual', label: 'Manual' },\n          ]}\n        /\u003e\n      \u003c/div\u003e\n\n      \u003cdiv className={styles.dangerZone}\u003e\n        \u003cButton variant=\"ghost\" tone=\"danger\" onClick={onDisable}\u003e\n          Disable Sync\n        \u003c/Button\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n## Verification Criteria\n- [ ] Shows disabled state when sync is off\n- [ ] Enable sync shows login form\n- [ ] Login works with valid credentials\n- [ ] Shows account info when logged in\n- [ ] Auto-sync toggle works\n- [ ] Logout clears user state\n- [ ] Disable sync prompts confirmation\n\n## Files to Create\n- `apps/desktop/renderer/src/components/Settings/SyncSettings.tsx`\n- `apps/desktop/renderer/src/components/Settings/SyncSettings.css.ts`\n\n## Files to Modify\n- `apps/desktop/renderer/src/components/Settings/SettingsPage.tsx` (add Sync section)\n\n## Dependencies\n- scribe-hao.22 (preload bridge)\n- scribe-hao.40 (useSyncStatus hook)\n\n## UNBLOCKS\n- Full sync UI integration","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:23.93392-06:00","updated_at":"2025-12-29T14:39:50.493992-06:00","closed_at":"2025-12-29T14:39:50.493992-06:00","close_reason":"SyncSettingsPanel implemented and integrated into SettingsPage","dependencies":[{"issue_id":"scribe-hao.38","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:23.934304-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.38","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:23.355949-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.39","title":"[Phase 4.7] Integrate SyncStatusIndicator in header bar","description":"# [Phase 4.7] Integrate SyncStatusIndicator in header bar\n\n## Problem Statement\nAdd the SyncStatusIndicator to the application header/toolbar so users always see sync status and can trigger manual sync.\n\n## Why This Architecture\n- **Always visible**: Status in header is glanceable\n- **Non-intrusive**: Small icon that expands on hover/click\n- **Consistent placement**: Near other toolbar actions\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/components/TopToolbar/TopToolbar.tsx` (modifications)\n\n```tsx\nimport { SyncStatusIndicator } from '../Sync/SyncStatusIndicator';\n\n// Inside the TopToolbar component, add SyncStatusIndicator:\n\nexport function TopToolbar({ /* existing props */ }) {\n  // ... existing code ...\n\n  return (\n    \u003cdiv className={styles.toolbar}\u003e\n      {/* Existing toolbar content */}\n      \n      {/* Add sync status indicator */}\n      \u003cdiv className={styles.syncStatus}\u003e\n        \u003cSyncStatusIndicator \n          showLabel={false}  // Compact mode for toolbar\n          onConflictClick={handleConflictClick}\n        /\u003e\n      \u003c/div\u003e\n\n      {/* Other toolbar items */}\n    \u003c/div\u003e\n  );\n}\n```\n\n### File: `apps/desktop/renderer/src/components/TopToolbar/TopToolbar.css.ts` (additions)\n\n```typescript\nexport const syncStatus = style({\n  display: 'flex',\n  alignItems: 'center',\n  marginLeft: 'auto',\n  marginRight: vars.spacing[2],\n});\n```\n\n### Integration in App.tsx or layout\n\n```tsx\nimport { useState, useCallback } from 'react';\nimport { ConflictListModal } from './components/Sync/ConflictListModal';\nimport { useSyncStatus } from './hooks/useSyncStatus';\n\nfunction App() {\n  const { conflicts } = useSyncStatus();\n  const [showConflicts, setShowConflicts] = useState(false);\n\n  const handleConflictClick = useCallback(() =\u003e {\n    if (conflicts.length \u003e 0) {\n      setShowConflicts(true);\n    }\n  }, [conflicts]);\n\n  return (\n    \u003c\u003e\n      {/* Existing app content */}\n      \u003cTopToolbar onConflictClick={handleConflictClick} /\u003e\n      \n      {/* Conflict modal */}\n      \u003cConflictListModal\n        isOpen={showConflicts}\n        onClose={() =\u003e setShowConflicts(false)}\n        conflicts={conflicts}\n        onViewConflict={handleViewConflict}\n        onQuickResolve={handleQuickResolve}\n      /\u003e\n    \u003c/\u003e\n  );\n}\n```\n\n## Verification Criteria\n- [ ] SyncStatusIndicator visible in toolbar\n- [ ] Shows correct status (synced, syncing, error, offline)\n- [ ] Clicking conflict badge opens ConflictListModal\n- [ ] Tooltip shows last sync time\n- [ ] Does not appear when sync is disabled\n\n## Files to Modify\n- `apps/desktop/renderer/src/components/TopToolbar/TopToolbar.tsx`\n- `apps/desktop/renderer/src/components/TopToolbar/TopToolbar.css.ts`\n- `apps/desktop/renderer/src/App.tsx` (or layout component)\n\n## Dependencies\n- scribe-hao.33 (SyncStatusIndicator component)\n- scribe-hao.34 (ConflictListModal for conflict click)\n- scribe-hao.40 (useSyncStatus hook)\n\n## UNBLOCKS\n- Full sync UI integration complete","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:24.124811-06:00","updated_at":"2025-12-29T14:45:26.913843-06:00","closed_at":"2025-12-29T14:45:26.913843-06:00","close_reason":"SyncStatusIndicator integrated into TopToolbar with ConflictListModal and ConflictCompareView wired up in App.tsx","dependencies":[{"issue_id":"scribe-hao.39","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:24.125153-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.39","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:23.548116-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.39","depends_on_id":"scribe-hao.37","type":"blocks","created_at":"2025-12-27T22:04:23.75255-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.4","title":"[Phase 0.4] Verify no account prompts when sync is disabled","description":"# [Phase 0.4] Verify no account prompts when sync is disabled\n\n## Problem Statement\nUsers who don't want sync should NEVER be prompted to create an account or sign in. The app should work completely without any account-related UI when sync is disabled.\n\n## Why This is Critical (P0)\n- Many users are hostile to forced account creation\n- Enterprise users may be prohibited from creating external accounts\n- Privacy-focused users don't want any hint of cloud services\n- Account prompts can feel invasive and hurt user trust\n\n## Verification Checklist\n\n### 1. No account prompts on first launch\n- [ ] App opens directly to note editor\n- [ ] No \"Sign in to sync\" modal\n- [ ] No \"Create account\" button in main UI\n- [ ] Settings shows sync toggle, not account form\n\n### 2. No account prompts during normal use\n- [ ] Saving notes doesn't trigger sync prompt\n- [ ] Creating daily notes doesn't suggest sync\n- [ ] No \"Enable sync to access on mobile\" banners\n- [ ] No nudges or hints about syncing\n\n### 3. Account UI only appears when user initiates\n- [ ] User must click \"Enable sync\" toggle first\n- [ ] Account creation only in Settings \u003e Sync \u003e Enable flow\n- [ ] No modal popups, only inline in settings\n\n## Implementation Verification\n\n### Audit all modals and prompts\n```bash\n# Search for any sync-related prompts\ngrep -rn \"sync\\|account\\|sign in\\|login\" apps/desktop/renderer/src/components/**/*.tsx\n```\n\n### Ensure no sync prompts in main views\n```typescript\n// These components should NOT have sync prompts:\n// - Sidebar\n// - NoteEditor\n// - Header\n// - CommandPalette\n// - Daily/Meeting creation\n\n// Sync UI should ONLY be in:\n// - Settings/SyncSettings.tsx\n// - Settings/SyncSettingsPanel.tsx (when enabled)\n// - sync/* components (conflict resolution, status)\n```\n\n### Test scenario\n```typescript\ndescribe('Account prompts', () =\u003e {\n  it('does not show account prompt on first launch', async () =\u003e {\n    await launchAppWithFreshVault();\n    const modal = screen.queryByRole('dialog');\n    expect(modal).toBeNull();\n  });\n  \n  it('does not prompt for account when creating notes', async () =\u003e {\n    await createNote('Test note');\n    await saveNote();\n    const syncPrompt = screen.queryByText(/sync|account|sign in/i);\n    expect(syncPrompt).toBeNull();\n  });\n  \n  it('only shows account UI in settings sync section', async () =\u003e {\n    await openSettings();\n    await clickSyncSection();\n    await clickEnableSync();\n    // NOW account form should appear\n    expect(screen.getByLabelText('Email')).toBeInTheDocument();\n  });\n});\n```\n\n## Files to Audit\n- `apps/desktop/renderer/src/components/Sidebar/`\n- `apps/desktop/renderer/src/components/Editor/`\n- `apps/desktop/renderer/src/components/Header/`\n- `apps/desktop/renderer/src/App.tsx`\n- Any modal or dialog components\n\n## Dependencies\n- scribe-hao.1 (Verify SyncEngine not initialized)\n- scribe-hao.2 (Verify no network calls)\n- scribe-hao.3 (Add sync toggle to Settings)\n\n## UNBLOCKS\n- Phase 1 can begin (all opt-in guards verified)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-27T21:28:17.578985-06:00","updated_at":"2025-12-29T13:11:17.379726-06:00","closed_at":"2025-12-29T13:11:17.379726-06:00","close_reason":"Audited codebase - confirmed no sync prompts exist. Created 14 integration tests verifying sync-prompt-free user experience. Phase 0 complete.","dependencies":[{"issue_id":"scribe-hao.4","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:17.579351-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.4","depends_on_id":"scribe-hao.3","type":"blocks","created_at":"2025-12-27T22:03:08.41296-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.40","title":"[Phase 4.8] Implement useSyncStatus hook","description":"# [Phase 4.8] Implement useSyncStatus hook\n\n## Problem Statement\nCreate a React hook that provides sync status, progress, and conflicts to components. Handles subscription to sync events from the preload bridge.\n\n## Why This Architecture\n- **Centralized state**: One hook manages all sync UI state\n- **Event subscription**: Automatically subscribes/unsubscribes to IPC events\n- **Memoized**: Prevents unnecessary re-renders\n\n## Implementation\n\n### File: `apps/desktop/renderer/src/hooks/useSyncStatus.ts`\n\n```typescript\nimport { useState, useEffect, useCallback, useMemo } from 'react';\nimport type { SyncStatus, SyncProgress, SyncConflict } from '@scribe/shared';\n\nexport type SyncState = \n  | 'disabled'   // Sync feature is off\n  | 'offline'    // No network connection\n  | 'synced'     // All changes synced\n  | 'syncing'    // Sync in progress\n  | 'pending'    // Has unsynced changes\n  | 'error'      // Sync failed\n  | 'conflict';  // Has unresolved conflicts\n\nexport interface UseSyncStatusResult {\n  /** Whether sync feature is enabled */\n  isEnabled: boolean;\n  /** Current sync state for UI */\n  state: SyncState;\n  /** Detailed status from sync engine */\n  status: SyncStatus | null;\n  /** Progress during active sync */\n  progress: SyncProgress | null;\n  /** Pending conflicts */\n  conflicts: SyncConflict[];\n  /** Last successful sync timestamp */\n  lastSyncAt: number | null;\n  /** Error message if sync failed */\n  error: string | null;\n  /** Trigger manual sync */\n  syncNow: () =\u003e Promise\u003cvoid\u003e;\n  /** Resolve a conflict */\n  resolveConflict: (noteId: string, resolution: 'local' | 'remote' | 'keepBoth') =\u003e Promise\u003cvoid\u003e;\n  /** Refresh status from server */\n  refresh: () =\u003e Promise\u003cvoid\u003e;\n}\n\n/**\n * Hook for accessing sync status and controls.\n * \n * Automatically subscribes to sync status and conflict events.\n * Provides computed `state` for simple UI conditionals.\n * \n * @example\n * ```tsx\n * function SyncIndicator() {\n *   const { state, syncNow, conflicts } = useSyncStatus();\n *   \n *   return (\n *     \u003cbutton onClick={syncNow} disabled={state === 'syncing'}\u003e\n *       {state === 'syncing' ? 'Syncing...' : 'Sync'}\n *       {conflicts.length \u003e 0 \u0026\u0026 \u003cBadge\u003e{conflicts.length}\u003c/Badge\u003e}\n *     \u003c/button\u003e\n *   );\n * }\n * ```\n */\nexport function useSyncStatus(): UseSyncStatusResult {\n  const [isEnabled, setIsEnabled] = useState(false);\n  const [status, setStatus] = useState\u003cSyncStatus | null\u003e(null);\n  const [progress, setProgress] = useState\u003cSyncProgress | null\u003e(null);\n  const [conflicts, setConflicts] = useState\u003cSyncConflict[]\u003e([]);\n  const [error, setError] = useState\u003cstring | null\u003e(null);\n  const [lastSyncAt, setLastSyncAt] = useState\u003cnumber | null\u003e(null);\n\n  // Initial load\n  useEffect(() =\u003e {\n    loadInitialState();\n  }, []);\n\n  // Subscribe to status changes\n  useEffect(() =\u003e {\n    if (!isEnabled) return;\n\n    const unsubStatus = window.scribe.sync.onStatusChange((newStatus) =\u003e {\n      setStatus(newStatus);\n      setError(null);\n      \n      if (newStatus.lastSyncAt) {\n        setLastSyncAt(newStatus.lastSyncAt);\n      }\n      \n      // Update progress if syncing\n      if (newStatus.phase \u0026\u0026 newStatus.phase !== 'idle') {\n        setProgress({\n          phase: newStatus.phase,\n          totalItems: newStatus.totalItems ?? 0,\n          processedItems: newStatus.processedItems ?? 0,\n          conflicts: newStatus.conflictCount ?? 0,\n        });\n      } else {\n        setProgress(null);\n      }\n    });\n\n    const unsubConflict = window.scribe.sync.onConflict((conflict) =\u003e {\n      setConflicts((prev) =\u003e {\n        // Add or update conflict\n        const existing = prev.findIndex((c) =\u003e c.noteId === conflict.noteId);\n        if (existing \u003e= 0) {\n          const updated = [...prev];\n          updated[existing] = conflict;\n          return updated;\n        }\n        return [...prev, conflict];\n      });\n    });\n\n    return () =\u003e {\n      unsubStatus();\n      unsubConflict();\n    };\n  }, [isEnabled]);\n\n  const loadInitialState = useCallback(async () =\u003e {\n    try {\n      const enabled = await window.scribe.sync.isEnabled();\n      setIsEnabled(enabled);\n\n      if (enabled) {\n        const statusResult = await window.scribe.sync.getStatus();\n        if (statusResult.enabled \u0026\u0026 statusResult.status) {\n          setStatus(statusResult.status);\n          setLastSyncAt(statusResult.status.lastSyncAt ?? null);\n        }\n\n        const pendingConflicts = await window.scribe.sync.getConflicts();\n        setConflicts(pendingConflicts);\n      }\n    } catch (e) {\n      setError(e instanceof Error ? e.message : 'Failed to load sync status');\n    }\n  }, []);\n\n  const syncNow = useCallback(async () =\u003e {\n    if (!isEnabled) return;\n    \n    try {\n      setError(null);\n      await window.scribe.sync.syncNow();\n    } catch (e) {\n      setError(e instanceof Error ? e.message : 'Sync failed');\n    }\n  }, [isEnabled]);\n\n  const resolveConflict = useCallback(async (\n    noteId: string,\n    resolution: 'local' | 'remote' | 'keepBoth'\n  ) =\u003e {\n    try {\n      await window.scribe.sync.resolveConflict(noteId, resolution);\n      setConflicts((prev) =\u003e prev.filter((c) =\u003e c.noteId !== noteId));\n    } catch (e) {\n      setError(e instanceof Error ? e.message : 'Failed to resolve conflict');\n    }\n  }, []);\n\n  const refresh = useCallback(async () =\u003e {\n    await loadInitialState();\n  }, [loadInitialState]);\n\n  // Compute overall state\n  const state = useMemo((): SyncState =\u003e {\n    if (!isEnabled) return 'disabled';\n    if (conflicts.length \u003e 0) return 'conflict';\n    if (error) return 'error';\n    if (progress \u0026\u0026 progress.phase !== 'idle') return 'syncing';\n    if (status?.pendingChanges \u0026\u0026 status.pendingChanges \u003e 0) return 'pending';\n    if (status?.online === false) return 'offline';\n    return 'synced';\n  }, [isEnabled, conflicts.length, error, progress, status]);\n\n  return {\n    isEnabled,\n    state,\n    status,\n    progress,\n    conflicts,\n    lastSyncAt,\n    error,\n    syncNow,\n    resolveConflict,\n    refresh,\n  };\n}\n```\n\n## Verification Criteria\n- [ ] `isEnabled` reflects sync feature state\n- [ ] `state` correctly computes from underlying data\n- [ ] Status updates trigger re-render\n- [ ] Conflict events add to conflicts array\n- [ ] `syncNow()` triggers sync\n- [ ] `resolveConflict()` removes from list\n- [ ] Cleanup unsubscribes on unmount\n\n## Files to Create\n- `apps/desktop/renderer/src/hooks/useSyncStatus.ts`\n\n## Dependencies\n- scribe-hao.22 (preload bridge with event subscriptions)\n\n## UNBLOCKS\n- scribe-hao.33 (SyncStatusIndicator)\n- scribe-hao.37 (SyncProgressModal)\n- scribe-hao.38 (SyncSettingsPanel)\n- scribe-hao.39 (Header integration)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:24.340309-06:00","updated_at":"2025-12-29T14:17:44.505348-06:00","closed_at":"2025-12-29T14:17:44.505348-06:00","close_reason":"Implemented useSyncStatus hook with 25 passing tests. Provides isEnabled, state, status, conflicts, pendingCount, lastSyncAt, error, isSyncing, syncNow(), resolveConflict(), and refresh() APIs.","dependencies":[{"issue_id":"scribe-hao.40","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:24.340654-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.40","depends_on_id":"scribe-hao.33","type":"blocks","created_at":"2025-12-27T22:04:23.960214-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.41","title":"[Phase 5.1] Unit tests for SyncDatabase","description":"# [Phase 5.1] Unit tests for SyncDatabase\n\n## Problem Statement\nCreate comprehensive unit tests for the SyncDatabase SQLite wrapper that handles local sync state persistence.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/sync-database.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach } from 'vitest';\nimport { SyncDatabase } from './sync-database';\nimport Database from 'better-sqlite3';\nimport { mkdtempSync, rmSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\ndescribe('SyncDatabase', () =\u003e {\n  let db: SyncDatabase;\n  let tempDir: string;\n  let dbPath: string;\n\n  beforeEach(() =\u003e {\n    tempDir = mkdtempSync(join(tmpdir(), 'sync-db-test-'));\n    dbPath = join(tempDir, 'sync.sqlite3');\n    db = new SyncDatabase(dbPath);\n  });\n\n  afterEach(() =\u003e {\n    db.close();\n    rmSync(tempDir, { recursive: true, force: true });\n  });\n\n  describe('initialization', () =\u003e {\n    it('should create database file', () =\u003e {\n      expect(() =\u003e new SyncDatabase(dbPath)).not.toThrow();\n    });\n\n    it('should run migrations on first open', () =\u003e {\n      const db2 = new SyncDatabase(dbPath);\n      // Should have schema version set\n      const version = db2.getSchemaVersion();\n      expect(version).toBeGreaterThan(0);\n      db2.close();\n    });\n\n    it('should not re-run migrations on subsequent opens', () =\u003e {\n      db.close();\n      const db2 = new SyncDatabase(dbPath);\n      // Should work without errors\n      expect(db2.getSchemaVersion()).toBeGreaterThan(0);\n      db2.close();\n    });\n  });\n\n  describe('note hashes', () =\u003e {\n    const noteId = 'note-123';\n    const hash = 'abc123hash';\n\n    it('should store and retrieve note hash', () =\u003e {\n      db.updateNoteHash(noteId, hash);\n      expect(db.getNoteHash(noteId)).toBe(hash);\n    });\n\n    it('should return null for unknown note', () =\u003e {\n      expect(db.getNoteHash('unknown')).toBeNull();\n    });\n\n    it('should update existing hash', () =\u003e {\n      db.updateNoteHash(noteId, hash);\n      db.updateNoteHash(noteId, 'newhash');\n      expect(db.getNoteHash(noteId)).toBe('newhash');\n    });\n\n    it('should remove note hash', () =\u003e {\n      db.updateNoteHash(noteId, hash);\n      db.removeNoteHash(noteId);\n      expect(db.getNoteHash(noteId)).toBeNull();\n    });\n  });\n\n  describe('pending changes', () =\u003e {\n    it('should record pending change', () =\u003e {\n      db.recordPendingChange({\n        noteId: 'note-1',\n        changeType: 'create',\n        contentHash: 'hash1',\n        timestamp: Date.now(),\n      });\n\n      const changes = db.getPendingChanges();\n      expect(changes).toHaveLength(1);\n      expect(changes[0].noteId).toBe('note-1');\n      expect(changes[0].changeType).toBe('create');\n    });\n\n    it('should coalesce changes to same note', () =\u003e {\n      const now = Date.now();\n      db.recordPendingChange({\n        noteId: 'note-1',\n        changeType: 'create',\n        contentHash: 'hash1',\n        timestamp: now,\n      });\n      db.recordPendingChange({\n        noteId: 'note-1',\n        changeType: 'update',\n        contentHash: 'hash2',\n        timestamp: now + 1000,\n      });\n\n      const changes = db.getPendingChanges();\n      expect(changes).toHaveLength(1);\n      expect(changes[0].changeType).toBe('update');\n      expect(changes[0].contentHash).toBe('hash2');\n    });\n\n    it('should return changes in chronological order', () =\u003e {\n      const now = Date.now();\n      db.recordPendingChange({ noteId: 'note-2', changeType: 'create', contentHash: 'h2', timestamp: now + 1000 });\n      db.recordPendingChange({ noteId: 'note-1', changeType: 'create', contentHash: 'h1', timestamp: now });\n\n      const changes = db.getPendingChanges();\n      expect(changes[0].noteId).toBe('note-1');\n      expect(changes[1].noteId).toBe('note-2');\n    });\n\n    it('should clear specific changes by ID', () =\u003e {\n      db.recordPendingChange({ noteId: 'note-1', changeType: 'create', contentHash: 'h1', timestamp: Date.now() });\n      db.recordPendingChange({ noteId: 'note-2', changeType: 'create', contentHash: 'h2', timestamp: Date.now() });\n\n      const changes = db.getPendingChanges();\n      db.clearPendingChanges([changes[0].id!]);\n\n      const remaining = db.getPendingChanges();\n      expect(remaining).toHaveLength(1);\n      expect(remaining[0].noteId).toBe('note-2');\n    });\n\n    it('should handle delete with null hash', () =\u003e {\n      db.recordPendingChange({\n        noteId: 'note-1',\n        changeType: 'delete',\n        contentHash: null,\n        timestamp: Date.now(),\n      });\n\n      const changes = db.getPendingChanges();\n      expect(changes[0].contentHash).toBeNull();\n    });\n  });\n\n  describe('sync token', () =\u003e {\n    it('should return null initially', () =\u003e {\n      expect(db.getLastSyncToken()).toBeNull();\n    });\n\n    it('should store and retrieve sync token', () =\u003e {\n      db.setLastSyncToken('token-abc-123');\n      expect(db.getLastSyncToken()).toBe('token-abc-123');\n    });\n\n    it('should update sync token', () =\u003e {\n      db.setLastSyncToken('token-1');\n      db.setLastSyncToken('token-2');\n      expect(db.getLastSyncToken()).toBe('token-2');\n    });\n  });\n\n  describe('note versions', () =\u003e {\n    it('should store and retrieve version', () =\u003e {\n      db.setNoteVersion('note-1', 5);\n      expect(db.getNoteVersion('note-1')).toBe(5);\n    });\n\n    it('should return 0 for unknown note', () =\u003e {\n      expect(db.getNoteVersion('unknown')).toBe(0);\n    });\n\n    it('should update version', () =\u003e {\n      db.setNoteVersion('note-1', 1);\n      db.setNoteVersion('note-1', 2);\n      expect(db.getNoteVersion('note-1')).toBe(2);\n    });\n  });\n\n  describe('pending change count', () =\u003e {\n    it('should return 0 when empty', () =\u003e {\n      expect(db.getPendingChangeCount()).toBe(0);\n    });\n\n    it('should count pending changes', () =\u003e {\n      db.recordPendingChange({ noteId: 'note-1', changeType: 'create', contentHash: 'h1', timestamp: Date.now() });\n      db.recordPendingChange({ noteId: 'note-2', changeType: 'update', contentHash: 'h2', timestamp: Date.now() });\n      expect(db.getPendingChangeCount()).toBe(2);\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] All CRUD operations for note hashes tested\n- [ ] Pending changes coalescing tested\n- [ ] Chronological ordering verified\n- [ ] Sync token persistence tested\n- [ ] Version tracking tested\n- [ ] Edge cases (null, empty) handled\n\n## Files to Create\n- `packages/engine-sync/src/sync-database.test.ts`\n\n## Dependencies\n- scribe-hao.10 (SyncDatabase implementation)\n\n## UNBLOCKS\n- scribe-hao.42 (SyncEngine tests build on this)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:24.545622-06:00","updated_at":"2025-12-29T14:39:51.893199-06:00","closed_at":"2025-12-29T14:39:51.893199-06:00","close_reason":"SyncDatabase unit tests already exist and pass (39 tests)","dependencies":[{"issue_id":"scribe-hao.41","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:24.545957-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.41","depends_on_id":"scribe-hao.10","type":"blocks","created_at":"2025-12-27T22:04:41.703782-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.42","title":"[Phase 5.2] Unit tests for SyncEngine","description":"# [Phase 5.2] Unit tests for SyncEngine\n\n## Problem Statement\nCreate unit tests for the main SyncEngine class, testing initialization, configuration, and high-level sync operations.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/sync-engine.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { createSyncEngine, SyncEngine } from './sync-engine';\nimport { mkdtempSync, rmSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\ndescribe('SyncEngine', () =\u003e {\n  let engine: SyncEngine;\n  let tempDir: string;\n  let vaultPath: string;\n\n  beforeEach(() =\u003e {\n    tempDir = mkdtempSync(join(tmpdir(), 'sync-engine-test-'));\n    vaultPath = tempDir;\n  });\n\n  afterEach(async () =\u003e {\n    if (engine) {\n      await engine.shutdown();\n    }\n    rmSync(tempDir, { recursive: true, force: true });\n  });\n\n  describe('createSyncEngine', () =\u003e {\n    it('should create engine with default config', () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      expect(engine).toBeDefined();\n      expect(engine.isEnabled()).toBe(false); // Disabled by default\n    });\n\n    it('should respect enabled flag in config', () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: { enabled: true },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      expect(engine.isEnabled()).toBe(true);\n    });\n  });\n\n  describe('initialization', () =\u003e {\n    it('should initialize without errors', async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      await expect(engine.initialize()).resolves.not.toThrow();\n    });\n\n    it('should load existing sync state on init', async () =\u003e {\n      // Create first engine, set some state\n      const engine1 = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: { enabled: true },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine1.initialize();\n      await engine1.shutdown();\n\n      // Create second engine, should load state\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n\n      // State should be preserved\n      expect(engine.isEnabled()).toBe(true);\n    });\n  });\n\n  describe('enable/disable', () =\u003e {\n    beforeEach(async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n    });\n\n    it('should enable sync with credentials', async () =\u003e {\n      await engine.enable({ email: 'test@example.com', token: 'token123' });\n      expect(engine.isEnabled()).toBe(true);\n    });\n\n    it('should disable sync', async () =\u003e {\n      await engine.enable({ email: 'test@example.com', token: 'token123' });\n      await engine.disable();\n      expect(engine.isEnabled()).toBe(false);\n    });\n  });\n\n  describe('trackChange', () =\u003e {\n    beforeEach(async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: { enabled: true },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n    });\n\n    it('should track note changes when enabled', async () =\u003e {\n      const note = {\n        id: 'note-123',\n        metadata: { title: 'Test', type: 'regular', createdAt: '', updatedAt: '' },\n        content: {},\n      };\n\n      await engine.trackChange(note, 'create');\n      expect(engine.hasPendingChanges()).toBe(true);\n    });\n\n    it('should not track changes when disabled', async () =\u003e {\n      await engine.disable();\n\n      const note = {\n        id: 'note-123',\n        metadata: { title: 'Test', type: 'regular', createdAt: '', updatedAt: '' },\n        content: {},\n      };\n\n      await engine.trackChange(note, 'create');\n      expect(engine.hasPendingChanges()).toBe(false);\n    });\n  });\n\n  describe('trackDelete', () =\u003e {\n    beforeEach(async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: { enabled: true },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n    });\n\n    it('should track deletions', () =\u003e {\n      engine.trackDelete('note-123');\n      expect(engine.hasPendingChanges()).toBe(true);\n    });\n  });\n\n  describe('getStatus', () =\u003e {\n    it('should return status when enabled', async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: { enabled: true },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n\n      const status = engine.getStatus();\n      expect(status.phase).toBe('idle');\n      expect(status.pendingChanges).toBe(0);\n    });\n  });\n\n  describe('config', () =\u003e {\n    beforeEach(async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: {\n          syncIntervalMs: 30000,\n          autoSync: true,\n        },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n    });\n\n    it('should return current config', () =\u003e {\n      const config = engine.getConfig();\n      expect(config.syncIntervalMs).toBe(30000);\n      expect(config.autoSync).toBe(true);\n    });\n\n    it('should update config', async () =\u003e {\n      await engine.updateConfig({ autoSync: false });\n      const config = engine.getConfig();\n      expect(config.autoSync).toBe(false);\n    });\n  });\n\n  describe('shutdown', () =\u003e {\n    it('should cleanup resources on shutdown', async () =\u003e {\n      engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n      await engine.initialize();\n\n      await expect(engine.shutdown()).resolves.not.toThrow();\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Engine creation with various configs tested\n- [ ] Enable/disable lifecycle tested\n- [ ] Change tracking tested\n- [ ] Status reporting tested\n- [ ] Config get/set tested\n- [ ] Shutdown cleanup tested\n\n## Files to Create\n- `packages/engine-sync/src/sync-engine.test.ts`\n\n## Dependencies\n- scribe-hao.16 (SyncEngine implementation)\n- scribe-hao.41 (SyncDatabase tests as foundation)\n\n## UNBLOCKS\n- scribe-hao.45 (integration tests build on unit tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:24.750209-06:00","updated_at":"2025-12-29T14:39:52.070733-06:00","closed_at":"2025-12-29T14:39:52.070733-06:00","close_reason":"SyncEngine unit tests already exist and pass (28 tests)","dependencies":[{"issue_id":"scribe-hao.42","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:24.750557-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.42","depends_on_id":"scribe-hao.11","type":"blocks","created_at":"2025-12-27T22:04:41.897549-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.43","title":"[Phase 5.3] Unit tests for content hash computation","description":"# [Phase 5.3] Unit tests for content hash computation\n\n## Problem Statement\nTest the content hash computation to ensure consistent, deterministic hashing of note content for change detection.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/content-hash.test.ts`\n\n```typescript\nimport { describe, it, expect } from 'vitest';\nimport { computeContentHash, ContentHasher } from './content-hash';\n\ndescribe('computeContentHash', () =\u003e {\n  it('should return consistent hash for same content', () =\u003e {\n    const note = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [{ type: 'paragraph', children: [{ type: 'text', text: 'Hello' }] }] } },\n    };\n\n    const hash1 = computeContentHash(note);\n    const hash2 = computeContentHash(note);\n\n    expect(hash1).toBe(hash2);\n  });\n\n  it('should return different hash for different content', () =\u003e {\n    const note1 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [{ type: 'text', text: 'Hello' }] } },\n    };\n\n    const note2 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [{ type: 'text', text: 'World' }] } },\n    };\n\n    expect(computeContentHash(note1)).not.toBe(computeContentHash(note2));\n  });\n\n  it('should ignore id in hash computation', () =\u003e {\n    const note1 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [] } },\n    };\n\n    const note2 = {\n      id: 'note-2', // Different ID\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [] } },\n    };\n\n    expect(computeContentHash(note1)).toBe(computeContentHash(note2));\n  });\n\n  it('should include metadata changes in hash', () =\u003e {\n    const note1 = {\n      id: 'note-1',\n      metadata: { title: 'Original', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [] } },\n    };\n\n    const note2 = {\n      id: 'note-1',\n      metadata: { title: 'Changed', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: { root: { children: [] } },\n    };\n\n    expect(computeContentHash(note1)).not.toBe(computeContentHash(note2));\n  });\n\n  it('should ignore updatedAt timestamp in hash', () =\u003e {\n    const note1 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01T00:00:00' },\n      content: { root: { children: [] } },\n    };\n\n    const note2 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-02T00:00:00' },\n      content: { root: { children: [] } },\n    };\n\n    expect(computeContentHash(note1)).toBe(computeContentHash(note2));\n  });\n\n  it('should handle empty content', () =\u003e {\n    const note = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: {},\n    };\n\n    expect(() =\u003e computeContentHash(note)).not.toThrow();\n    expect(computeContentHash(note)).toBeTruthy();\n  });\n\n  it('should handle complex nested content', () =\u003e {\n    const note = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: {\n        root: {\n          children: [\n            { type: 'heading', level: 1, children: [{ type: 'text', text: 'Title' }] },\n            { type: 'paragraph', children: [\n              { type: 'text', text: 'Some ' },\n              { type: 'text', text: 'bold', format: 1 },\n              { type: 'text', text: ' text' },\n            ] },\n            { type: 'list', children: [\n              { type: 'listitem', children: [{ type: 'text', text: 'Item 1' }] },\n              { type: 'listitem', children: [{ type: 'text', text: 'Item 2' }] },\n            ] },\n          ],\n        },\n      },\n    };\n\n    const hash = computeContentHash(note);\n    expect(hash).toMatch(/^[a-f0-9]{64}$/); // SHA-256 hex\n  });\n\n  it('should be order-sensitive for arrays', () =\u003e {\n    const note1 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01', tags: ['a', 'b'] },\n      content: {},\n    };\n\n    const note2 = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01', tags: ['b', 'a'] },\n      content: {},\n    };\n\n    expect(computeContentHash(note1)).not.toBe(computeContentHash(note2));\n  });\n});\n\ndescribe('ContentHasher', () =\u003e {\n  it('should be reusable', () =\u003e {\n    const hasher = new ContentHasher();\n    const note = {\n      id: 'note-1',\n      metadata: { title: 'Test', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n      content: {},\n    };\n\n    const hash1 = hasher.computeHash(note);\n    const hash2 = hasher.computeHash(note);\n\n    expect(hash1).toBe(hash2);\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Same content produces same hash\n- [ ] Different content produces different hash\n- [ ] ID is excluded from hash\n- [ ] Metadata changes affect hash\n- [ ] Timestamp (updatedAt) excluded\n- [ ] Complex nested content handled\n- [ ] Order sensitivity verified\n\n## Files to Create\n- `packages/engine-sync/src/content-hash.test.ts`\n\n## Dependencies\n- scribe-hao.9 (content-hash implementation)\n\n## UNBLOCKS\n- scribe-hao.45 (integration tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:24.952616-06:00","updated_at":"2025-12-29T14:39:52.244166-06:00","closed_at":"2025-12-29T14:39:52.244166-06:00","close_reason":"Content hash unit tests exist and pass (23 tests)","dependencies":[{"issue_id":"scribe-hao.43","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:24.952979-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.43","depends_on_id":"scribe-hao.13","type":"blocks","created_at":"2025-12-27T22:04:42.092524-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.44","title":"[Phase 5.4] Unit tests for ConflictResolver","description":"# [Phase 5.4] Unit tests for ConflictResolver\n\n## Problem Statement\nTest the ConflictResolver to ensure correct conflict detection, auto-resolution heuristics, and manual resolution handling.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/conflict-resolver.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach } from 'vitest';\nimport { ConflictResolver, type SyncConflict } from './conflict-resolver';\n\ndescribe('ConflictResolver', () =\u003e {\n  let resolver: ConflictResolver;\n\n  beforeEach(() =\u003e {\n    resolver = new ConflictResolver({\n      defaultStrategy: 'manual',\n      autoResolveThresholdMs: 5000, // 5 seconds\n    });\n  });\n\n  const createConflict = (overrides: Partial\u003cSyncConflict\u003e = {}): SyncConflict =\u003e ({\n    noteId: 'note-123',\n    localNote: {\n      id: 'note-123',\n      metadata: { title: 'Local Title', type: 'regular', createdAt: '', updatedAt: '' },\n      content: { text: 'local content' },\n    },\n    remoteNote: {\n      id: 'note-123',\n      metadata: { title: 'Remote Title', type: 'regular', createdAt: '', updatedAt: '' },\n      content: { text: 'remote content' },\n    },\n    localVersion: 5,\n    remoteVersion: 6,\n    localModifiedAt: Date.now() - 10000,\n    remoteModifiedAt: Date.now() - 5000,\n    ...overrides,\n  });\n\n  describe('isConflict', () =\u003e {\n    it('should detect conflict when versions differ', () =\u003e {\n      const localNote = { id: 'n1', metadata: {}, content: {} };\n      const remoteNote = { id: 'n1', metadata: {}, content: {} };\n\n      expect(resolver.isConflict(localNote, remoteNote, 5, 6)).toBe(true);\n    });\n\n    it('should not detect conflict when versions match', () =\u003e {\n      const localNote = { id: 'n1', metadata: {}, content: {} };\n      const remoteNote = { id: 'n1', metadata: {}, content: {} };\n\n      expect(resolver.isConflict(localNote, remoteNote, 5, 5)).toBe(false);\n    });\n  });\n\n  describe('autoResolve', () =\u003e {\n    it('should auto-resolve identical content as remote', () =\u003e {\n      const conflict = createConflict({\n        localNote: {\n          id: 'note-123',\n          metadata: { title: 'Same', type: 'regular', createdAt: '', updatedAt: '' },\n          content: { text: 'same content' },\n        },\n        remoteNote: {\n          id: 'note-123',\n          metadata: { title: 'Same', type: 'regular', createdAt: '', updatedAt: '' },\n          content: { text: 'same content' },\n        },\n      });\n\n      const result = resolver.autoResolve(conflict);\n      expect(result.resolution).toBe('remote');\n      expect(result.requiresUserInput).toBe(false);\n    });\n\n    it('should auto-resolve recent changes based on timestamp', () =\u003e {\n      const now = Date.now();\n      const conflict = createConflict({\n        localModifiedAt: now - 1000, // 1 second ago\n        remoteModifiedAt: now - 2000, // 2 seconds ago\n      });\n\n      const result = resolver.autoResolve(conflict);\n      expect(result.resolution).toBe('local'); // Local is newer\n      expect(result.requiresUserInput).toBe(false);\n    });\n\n    it('should require manual resolution for divergent changes', () =\u003e {\n      const conflict = createConflict({\n        localModifiedAt: Date.now() - 60000, // 1 minute ago\n        remoteModifiedAt: Date.now() - 30000, // 30 seconds ago\n      });\n\n      const result = resolver.autoResolve(conflict);\n      expect(result.resolution).toBe('manual');\n      expect(result.requiresUserInput).toBe(true);\n    });\n\n    it('should store pending conflict for manual resolution', () =\u003e {\n      const conflict = createConflict();\n      resolver.autoResolve(conflict);\n\n      expect(resolver.hasConflict(conflict.noteId)).toBe(true);\n      expect(resolver.getPendingConflicts()).toHaveLength(1);\n    });\n  });\n\n  describe('resolveManually', () =\u003e {\n    it('should resolve with local version', () =\u003e {\n      const conflict = createConflict();\n      resolver.autoResolve(conflict); // Store as pending\n\n      const result = resolver.resolveManually(conflict.noteId, 'local');\n      expect(result.resolution).toBe('local');\n      expect(result.resolvedNote).toBe(conflict.localNote);\n      expect(result.requiresUserInput).toBe(false);\n    });\n\n    it('should resolve with remote version', () =\u003e {\n      const conflict = createConflict();\n      resolver.autoResolve(conflict);\n\n      const result = resolver.resolveManually(conflict.noteId, 'remote');\n      expect(result.resolution).toBe('remote');\n      expect(result.resolvedNote).toBe(conflict.remoteNote);\n    });\n\n    it('should resolve with keepBoth and create copy', () =\u003e {\n      const conflict = createConflict();\n      resolver.autoResolve(conflict);\n\n      const result = resolver.resolveManually(conflict.noteId, 'keepBoth');\n      expect(result.resolution).toBe('keepBoth');\n      expect(result.resolvedNote).toBe(conflict.remoteNote);\n      expect(result.copyNote).toBeDefined();\n      expect(result.copyNote?.id).not.toBe(conflict.localNote.id);\n      expect(result.copyNote?.metadata.title).toContain('conflict copy');\n    });\n\n    it('should remove conflict after resolution', () =\u003e {\n      const conflict = createConflict();\n      resolver.autoResolve(conflict);\n      resolver.resolveManually(conflict.noteId, 'local');\n\n      expect(resolver.hasConflict(conflict.noteId)).toBe(false);\n    });\n\n    it('should throw for unknown conflict', () =\u003e {\n      expect(() =\u003e resolver.resolveManually('unknown', 'local')).toThrow();\n    });\n  });\n\n  describe('getPendingConflicts', () =\u003e {\n    it('should return empty array initially', () =\u003e {\n      expect(resolver.getPendingConflicts()).toEqual([]);\n    });\n\n    it('should return all pending conflicts', () =\u003e {\n      resolver.autoResolve(createConflict({ noteId: 'note-1' }));\n      resolver.autoResolve(createConflict({ noteId: 'note-2' }));\n\n      const pending = resolver.getPendingConflicts();\n      expect(pending).toHaveLength(2);\n    });\n  });\n\n  describe('clearConflict', () =\u003e {\n    it('should remove a conflict without resolution', () =\u003e {\n      const conflict = createConflict();\n      resolver.autoResolve(conflict);\n      resolver.clearConflict(conflict.noteId);\n\n      expect(resolver.hasConflict(conflict.noteId)).toBe(false);\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Version-based conflict detection works\n- [ ] Auto-resolution for identical content\n- [ ] Timestamp-based auto-resolution\n- [ ] Manual resolution fallback\n- [ ] keepBoth creates valid copy\n- [ ] Pending conflicts tracked correctly\n- [ ] Error handling for invalid operations\n\n## Files to Create\n- `packages/engine-sync/src/conflict-resolver.test.ts`\n\n## Dependencies\n- scribe-hao.14 (ConflictResolver implementation)\n\n## UNBLOCKS\n- scribe-hao.46 (conflict resolution integration tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:25.160242-06:00","updated_at":"2025-12-29T14:39:52.412503-06:00","closed_at":"2025-12-29T14:39:52.412503-06:00","close_reason":"ConflictResolver unit tests exist and pass (23 tests)","dependencies":[{"issue_id":"scribe-hao.44","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:25.160603-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.44","depends_on_id":"scribe-hao.14","type":"blocks","created_at":"2025-12-27T22:04:42.287389-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.45","title":"[Phase 5.5] Integration tests for sync flow (push/pull)","description":"# [Phase 5.5] Integration tests for sync flow (push/pull)\n\n## Problem Statement\nCreate integration tests that verify the complete sync flow including pushing local changes, pulling remote changes, and proper coordination between components.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/sync-flow.integration.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { createSyncEngine } from './sync-engine';\nimport { mkdtempSync, rmSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\n// Mock server responses\nconst mockServer = {\n  push: vi.fn(),\n  pull: vi.fn(),\n  status: vi.fn(),\n};\n\ndescribe('Sync Flow Integration', () =\u003e {\n  let tempDir: string;\n  let engine: ReturnType\u003ctypeof createSyncEngine\u003e;\n  let savedNotes: Map\u003cstring, unknown\u003e;\n  let deletedNotes: Set\u003cstring\u003e;\n\n  beforeEach(async () =\u003e {\n    tempDir = mkdtempSync(join(tmpdir(), 'sync-flow-test-'));\n    savedNotes = new Map();\n    deletedNotes = new Set();\n\n    // Reset mocks\n    mockServer.push.mockReset();\n    mockServer.pull.mockReset();\n    mockServer.status.mockReset();\n\n    engine = createSyncEngine({\n      vaultPath: tempDir,\n      databasePath: join(tempDir, 'sync.sqlite3'),\n      serverUrl: 'https://mock.server',\n      config: { enabled: true },\n      onSaveNote: async (note) =\u003e { savedNotes.set(note.id, note); },\n      onDeleteNote: async (noteId) =\u003e { deletedNotes.add(noteId); },\n      // Inject mock transport\n      transport: {\n        push: mockServer.push,\n        pull: mockServer.pull,\n        getStatus: mockServer.status,\n      },\n    });\n\n    await engine.initialize();\n  });\n\n  afterEach(async () =\u003e {\n    await engine.shutdown();\n    rmSync(tempDir, { recursive: true, force: true });\n  });\n\n  describe('push flow', () =\u003e {\n    it('should push local changes to server', async () =\u003e {\n      // Track a local change\n      const note = {\n        id: 'note-1',\n        metadata: { title: 'Test', type: 'regular', createdAt: '', updatedAt: '' },\n        content: { text: 'hello' },\n      };\n      await engine.trackChange(note, 'create');\n\n      // Mock successful push\n      mockServer.push.mockResolvedValue({\n        results: [{ noteId: 'note-1', success: true, newVersion: 1 }],\n        serverTime: Date.now(),\n      });\n      mockServer.pull.mockResolvedValue({\n        changes: [],\n        syncToken: 'token-1',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      // Run sync\n      await engine.syncNow();\n\n      expect(mockServer.push).toHaveBeenCalled();\n      expect(engine.hasPendingChanges()).toBe(false);\n    });\n\n    it('should handle push failures gracefully', async () =\u003e {\n      const note = {\n        id: 'note-1',\n        metadata: { title: 'Test', type: 'regular', createdAt: '', updatedAt: '' },\n        content: {},\n      };\n      await engine.trackChange(note, 'create');\n\n      // Mock failed push\n      mockServer.push.mockResolvedValue({\n        results: [{ noteId: 'note-1', success: false, error: 'Server error' }],\n        serverTime: Date.now(),\n      });\n      mockServer.pull.mockResolvedValue({\n        changes: [],\n        syncToken: '',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      // Change should still be pending\n      expect(engine.hasPendingChanges()).toBe(true);\n    });\n  });\n\n  describe('pull flow', () =\u003e {\n    it('should apply pulled notes to local vault', async () =\u003e {\n      mockServer.push.mockResolvedValue({ results: [], serverTime: Date.now() });\n      mockServer.pull.mockResolvedValue({\n        changes: [\n          {\n            noteId: 'remote-note-1',\n            changeType: 'create',\n            serverVersion: 1,\n            contentHash: 'abc',\n            timestamp: Date.now(),\n            note: {\n              id: 'remote-note-1',\n              metadata: { title: 'From Server', type: 'regular', createdAt: '', updatedAt: '' },\n              content: { text: 'remote content' },\n            },\n          },\n        ],\n        syncToken: 'token-1',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      expect(savedNotes.has('remote-note-1')).toBe(true);\n    });\n\n    it('should handle remote deletions', async () =\u003e {\n      mockServer.push.mockResolvedValue({ results: [], serverTime: Date.now() });\n      mockServer.pull.mockResolvedValue({\n        changes: [\n          {\n            noteId: 'deleted-note',\n            changeType: 'delete',\n            serverVersion: 2,\n            contentHash: null,\n            timestamp: Date.now(),\n            note: null,\n          },\n        ],\n        syncToken: 'token-1',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      expect(deletedNotes.has('deleted-note')).toBe(true);\n    });\n\n    it('should update sync token after pull', async () =\u003e {\n      mockServer.push.mockResolvedValue({ results: [], serverTime: Date.now() });\n      mockServer.pull.mockResolvedValue({\n        changes: [],\n        syncToken: 'new-token-123',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      // Next pull should use new token\n      await engine.syncNow();\n      expect(mockServer.pull).toHaveBeenLastCalledWith('new-token-123');\n    });\n  });\n\n  describe('conflict detection', () =\u003e {\n    it('should detect conflict when local and remote diverge', async () =\u003e {\n      // Track local change\n      const localNote = {\n        id: 'conflict-note',\n        metadata: { title: 'Local Edit', type: 'regular', createdAt: '', updatedAt: '' },\n        content: { text: 'local version' },\n      };\n      await engine.trackChange(localNote, 'update');\n\n      // Server returns different version\n      mockServer.push.mockResolvedValue({\n        results: [{ noteId: 'conflict-note', success: false, conflict: true }],\n        serverTime: Date.now(),\n      });\n      mockServer.pull.mockResolvedValue({\n        changes: [\n          {\n            noteId: 'conflict-note',\n            changeType: 'update',\n            serverVersion: 3,\n            contentHash: 'xyz',\n            timestamp: Date.now(),\n            note: {\n              id: 'conflict-note',\n              metadata: { title: 'Remote Edit', type: 'regular', createdAt: '', updatedAt: '' },\n              content: { text: 'remote version' },\n            },\n          },\n        ],\n        syncToken: 'token-1',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      const conflicts = engine.getPendingConflicts();\n      expect(conflicts.length).toBeGreaterThan(0);\n    });\n  });\n\n  describe('pagination', () =\u003e {\n    it('should handle paginated pull responses', async () =\u003e {\n      mockServer.push.mockResolvedValue({ results: [], serverTime: Date.now() });\n\n      // First page\n      mockServer.pull.mockResolvedValueOnce({\n        changes: [\n          { noteId: 'note-1', changeType: 'create', serverVersion: 1, contentHash: 'a', timestamp: 1, note: { id: 'note-1', metadata: {}, content: {} } },\n        ],\n        syncToken: 'page-1',\n        hasMore: true,\n        serverTime: Date.now(),\n      });\n\n      // Second page\n      mockServer.pull.mockResolvedValueOnce({\n        changes: [\n          { noteId: 'note-2', changeType: 'create', serverVersion: 1, contentHash: 'b', timestamp: 2, note: { id: 'note-2', metadata: {}, content: {} } },\n        ],\n        syncToken: 'page-2',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      expect(savedNotes.size).toBe(2);\n      expect(mockServer.pull).toHaveBeenCalledTimes(2);\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Push sends local changes to server\n- [ ] Failed pushes preserve pending changes\n- [ ] Pull applies remote changes locally\n- [ ] Remote deletions are processed\n- [ ] Sync token is updated and reused\n- [ ] Conflicts are detected and queued\n- [ ] Pagination is handled correctly\n\n## Files to Create\n- `packages/engine-sync/src/sync-flow.integration.test.ts`\n\n## Dependencies\n- scribe-hao.16 (SyncEngine)\n- scribe-hao.15 (SyncCoordinator)\n- scribe-hao.12 (SyncTransport)\n\n## UNBLOCKS\n- scribe-hao.50 (end-to-end tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:25.373136-06:00","updated_at":"2025-12-29T14:39:52.5833-06:00","closed_at":"2025-12-29T14:39:52.5833-06:00","close_reason":"Integration tests for sync flow created and pass (16 tests)","dependencies":[{"issue_id":"scribe-hao.45","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:25.37346-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.45","depends_on_id":"scribe-hao.15","type":"blocks","created_at":"2025-12-27T22:04:42.484001-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.46","title":"[Phase 5.6] Integration tests for conflict resolution","description":"# [Phase 5.6] Integration tests for conflict resolution\n\n## Problem Statement\nTest the complete conflict resolution flow from detection through resolution, including auto-resolution, manual resolution, and the \"keep both\" option.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/conflict-resolution.integration.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { createSyncEngine } from './sync-engine';\nimport { mkdtempSync, rmSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\ndescribe('Conflict Resolution Integration', () =\u003e {\n  let tempDir: string;\n  let engine: ReturnType\u003ctypeof createSyncEngine\u003e;\n  let savedNotes: Map\u003cstring, unknown\u003e;\n  const mockTransport = {\n    push: vi.fn(),\n    pull: vi.fn(),\n  };\n\n  beforeEach(async () =\u003e {\n    tempDir = mkdtempSync(join(tmpdir(), 'conflict-test-'));\n    savedNotes = new Map();\n\n    engine = createSyncEngine({\n      vaultPath: tempDir,\n      databasePath: join(tempDir, 'sync.sqlite3'),\n      serverUrl: 'https://mock.server',\n      config: { \n        enabled: true,\n        conflictStrategy: 'manual', // Force manual resolution\n      },\n      onSaveNote: async (note) =\u003e { savedNotes.set(note.id, note); },\n      onDeleteNote: vi.fn(),\n      transport: mockTransport,\n    });\n\n    await engine.initialize();\n  });\n\n  afterEach(async () =\u003e {\n    await engine.shutdown();\n    rmSync(tempDir, { recursive: true, force: true });\n  });\n\n  describe('conflict lifecycle', () =\u003e {\n    it('should detect conflict and store for manual resolution', async () =\u003e {\n      // Simulate local edit\n      const localNote = {\n        id: 'note-1',\n        metadata: { title: 'Local', type: 'regular', createdAt: '', updatedAt: '' },\n        content: { text: 'local changes' },\n      };\n      await engine.trackChange(localNote, 'update');\n\n      // Simulate server returning conflicting version\n      mockTransport.push.mockResolvedValue({\n        results: [{ noteId: 'note-1', success: false, error: 'Version conflict', conflict: true }],\n        serverTime: Date.now(),\n      });\n      mockTransport.pull.mockResolvedValue({\n        changes: [{\n          noteId: 'note-1',\n          changeType: 'update',\n          serverVersion: 5,\n          timestamp: Date.now(),\n          note: {\n            id: 'note-1',\n            metadata: { title: 'Remote', type: 'regular', createdAt: '', updatedAt: '' },\n            content: { text: 'remote changes' },\n          },\n        }],\n        syncToken: 'token',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      const conflicts = engine.getPendingConflicts();\n      expect(conflicts).toHaveLength(1);\n      expect(conflicts[0].noteId).toBe('note-1');\n      expect(conflicts[0].localNote.metadata.title).toBe('Local');\n      expect(conflicts[0].remoteNote.metadata.title).toBe('Remote');\n    });\n\n    it('should resolve conflict with local version', async () =\u003e {\n      // Create conflict scenario\n      await createConflictScenario();\n\n      // Resolve with local\n      await engine.resolveConflict('note-1', 'local');\n\n      // Verify\n      expect(engine.getPendingConflicts()).toHaveLength(0);\n      const saved = savedNotes.get('note-1') as { metadata: { title: string } };\n      expect(saved.metadata.title).toBe('Local');\n    });\n\n    it('should resolve conflict with remote version', async () =\u003e {\n      await createConflictScenario();\n\n      await engine.resolveConflict('note-1', 'remote');\n\n      expect(engine.getPendingConflicts()).toHaveLength(0);\n      const saved = savedNotes.get('note-1') as { metadata: { title: string } };\n      expect(saved.metadata.title).toBe('Remote');\n    });\n\n    it('should resolve conflict with keepBoth option', async () =\u003e {\n      await createConflictScenario();\n\n      await engine.resolveConflict('note-1', 'keepBoth');\n\n      expect(engine.getPendingConflicts()).toHaveLength(0);\n      \n      // Should have original + copy\n      expect(savedNotes.size).toBe(2);\n      \n      // One should be the conflict copy\n      const titles = Array.from(savedNotes.values())\n        .map((n) =\u003e (n as { metadata: { title: string } }).metadata.title);\n      expect(titles.some((t) =\u003e t.includes('conflict copy'))).toBe(true);\n    });\n  });\n\n  describe('multiple conflicts', () =\u003e {\n    it('should handle multiple simultaneous conflicts', async () =\u003e {\n      // Track changes for two notes\n      for (let i = 1; i \u003c= 2; i++) {\n        await engine.trackChange({\n          id: `note-${i}`,\n          metadata: { title: `Local ${i}`, type: 'regular', createdAt: '', updatedAt: '' },\n          content: {},\n        }, 'update');\n      }\n\n      // Both conflict\n      mockTransport.push.mockResolvedValue({\n        results: [\n          { noteId: 'note-1', success: false, conflict: true },\n          { noteId: 'note-2', success: false, conflict: true },\n        ],\n        serverTime: Date.now(),\n      });\n      mockTransport.pull.mockResolvedValue({\n        changes: [\n          { noteId: 'note-1', changeType: 'update', serverVersion: 2, timestamp: Date.now(), note: { id: 'note-1', metadata: { title: 'Remote 1' }, content: {} } },\n          { noteId: 'note-2', changeType: 'update', serverVersion: 2, timestamp: Date.now(), note: { id: 'note-2', metadata: { title: 'Remote 2' }, content: {} } },\n        ],\n        syncToken: 'token',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      expect(engine.getPendingConflicts()).toHaveLength(2);\n\n      // Resolve each differently\n      await engine.resolveConflict('note-1', 'local');\n      await engine.resolveConflict('note-2', 'remote');\n\n      expect(engine.getPendingConflicts()).toHaveLength(0);\n    });\n  });\n\n  describe('delete conflicts', () =\u003e {\n    it('should detect local delete vs remote edit conflict', async () =\u003e {\n      // Local delete\n      engine.trackDelete('note-1');\n\n      // Remote edit\n      mockTransport.push.mockResolvedValue({\n        results: [{ noteId: 'note-1', success: false, conflict: true, error: 'Note was modified' }],\n        serverTime: Date.now(),\n      });\n      mockTransport.pull.mockResolvedValue({\n        changes: [{\n          noteId: 'note-1',\n          changeType: 'update',\n          serverVersion: 3,\n          timestamp: Date.now(),\n          note: { id: 'note-1', metadata: { title: 'Edited' }, content: {} },\n        }],\n        syncToken: 'token',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      const conflicts = engine.getPendingConflicts();\n      expect(conflicts).toHaveLength(1);\n      // Should have remote note, local is null (deleted)\n    });\n  });\n\n  // Helper function\n  async function createConflictScenario() {\n    await engine.trackChange({\n      id: 'note-1',\n      metadata: { title: 'Local', type: 'regular', createdAt: '', updatedAt: '' },\n      content: { text: 'local' },\n    }, 'update');\n\n    mockTransport.push.mockResolvedValue({\n      results: [{ noteId: 'note-1', success: false, conflict: true }],\n      serverTime: Date.now(),\n    });\n    mockTransport.pull.mockResolvedValue({\n      changes: [{\n        noteId: 'note-1',\n        changeType: 'update',\n        serverVersion: 5,\n        timestamp: Date.now(),\n        note: { id: 'note-1', metadata: { title: 'Remote', type: 'regular', createdAt: '', updatedAt: '' }, content: { text: 'remote' } },\n      }],\n      syncToken: 'token',\n      hasMore: false,\n      serverTime: Date.now(),\n    });\n\n    await engine.syncNow();\n  }\n});\n```\n\n## Verification Criteria\n- [ ] Conflicts detected and stored correctly\n- [ ] Local resolution applies local version\n- [ ] Remote resolution applies remote version\n- [ ] keepBoth creates copy with correct naming\n- [ ] Multiple conflicts handled independently\n- [ ] Delete conflicts handled appropriately\n- [ ] Resolution clears pending conflicts\n\n## Files to Create\n- `packages/engine-sync/src/conflict-resolution.integration.test.ts`\n\n## Dependencies\n- scribe-hao.14 (ConflictResolver)\n- scribe-hao.15 (SyncCoordinator)\n- scribe-hao.44 (ConflictResolver unit tests)\n\n## UNBLOCKS\n- scribe-hao.50 (end-to-end tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:25.589575-06:00","updated_at":"2025-12-29T14:45:27.079189-06:00","closed_at":"2025-12-29T14:45:27.079189-06:00","close_reason":"Conflict resolution integration tests created and pass (14 tests)","dependencies":[{"issue_id":"scribe-hao.46","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:25.589981-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.46","depends_on_id":"scribe-hao.16","type":"blocks","created_at":"2025-12-27T22:04:42.687157-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.47","title":"[Phase 5.7] Integration tests for network failure recovery","description":"# [Phase 5.7] Integration tests for network failure recovery\n\n## Problem Statement\nTest sync behavior during network failures, including retry logic, offline queuing, and recovery when connectivity is restored.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/network-recovery.integration.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { createSyncEngine } from './sync-engine';\nimport { mkdtempSync, rmSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\ndescribe('Network Recovery Integration', () =\u003e {\n  let tempDir: string;\n  let engine: ReturnType\u003ctypeof createSyncEngine\u003e;\n  const mockTransport = {\n    push: vi.fn(),\n    pull: vi.fn(),\n  };\n  const mockNetworkMonitor = {\n    isOnline: vi.fn().mockReturnValue(true),\n    onStatusChange: vi.fn(),\n  };\n\n  beforeEach(async () =\u003e {\n    tempDir = mkdtempSync(join(tmpdir(), 'network-test-'));\n    mockTransport.push.mockReset();\n    mockTransport.pull.mockReset();\n    mockNetworkMonitor.isOnline.mockReturnValue(true);\n\n    engine = createSyncEngine({\n      vaultPath: tempDir,\n      databasePath: join(tempDir, 'sync.sqlite3'),\n      serverUrl: 'https://mock.server',\n      config: { enabled: true, autoSync: false },\n      onSaveNote: vi.fn(),\n      onDeleteNote: vi.fn(),\n      transport: mockTransport,\n      networkMonitor: mockNetworkMonitor,\n    });\n\n    await engine.initialize();\n  });\n\n  afterEach(async () =\u003e {\n    await engine.shutdown();\n    rmSync(tempDir, { recursive: true, force: true });\n  });\n\n  describe('offline detection', () =\u003e {\n    it('should not attempt sync when offline', async () =\u003e {\n      mockNetworkMonitor.isOnline.mockReturnValue(false);\n\n      await engine.trackChange({\n        id: 'note-1',\n        metadata: { title: 'Test', type: 'regular', createdAt: '', updatedAt: '' },\n        content: {},\n      }, 'create');\n\n      const result = await engine.syncNow();\n\n      expect(result.success).toBe(false);\n      expect(result.error).toContain('offline');\n      expect(mockTransport.push).not.toHaveBeenCalled();\n    });\n\n    it('should queue changes while offline', async () =\u003e {\n      mockNetworkMonitor.isOnline.mockReturnValue(false);\n\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n      await engine.trackChange({ id: 'note-2', metadata: {}, content: {} }, 'create');\n\n      expect(engine.hasPendingChanges()).toBe(true);\n      // Changes should be preserved for later\n    });\n\n    it('should sync queued changes when back online', async () =\u003e {\n      // Go offline, make changes\n      mockNetworkMonitor.isOnline.mockReturnValue(false);\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n\n      // Go back online\n      mockNetworkMonitor.isOnline.mockReturnValue(true);\n      mockTransport.push.mockResolvedValue({\n        results: [{ noteId: 'note-1', success: true, newVersion: 1 }],\n        serverTime: Date.now(),\n      });\n      mockTransport.pull.mockResolvedValue({\n        changes: [],\n        syncToken: 'token',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      expect(mockTransport.push).toHaveBeenCalled();\n      expect(engine.hasPendingChanges()).toBe(false);\n    });\n  });\n\n  describe('transient failures', () =\u003e {\n    it('should retry on temporary network error', async () =\u003e {\n      // First call fails, second succeeds\n      mockTransport.push\n        .mockRejectedValueOnce(new Error('Network error'))\n        .mockResolvedValueOnce({\n          results: [{ noteId: 'note-1', success: true, newVersion: 1 }],\n          serverTime: Date.now(),\n        });\n      mockTransport.pull.mockResolvedValue({\n        changes: [],\n        syncToken: 'token',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n      \n      // First sync fails\n      const result1 = await engine.syncNow();\n      expect(result1.success).toBe(false);\n\n      // Second sync succeeds (after \"recovery\")\n      const result2 = await engine.syncNow();\n      expect(result2.success).toBe(true);\n    });\n\n    it('should preserve changes after failed sync', async () =\u003e {\n      mockTransport.push.mockRejectedValue(new Error('Server error'));\n      mockTransport.pull.mockResolvedValue({\n        changes: [],\n        syncToken: '',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n      await engine.syncNow();\n\n      // Changes should still be pending\n      expect(engine.hasPendingChanges()).toBe(true);\n    });\n  });\n\n  describe('partial failures', () =\u003e {\n    it('should handle partial push success', async () =\u003e {\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n      await engine.trackChange({ id: 'note-2', metadata: {}, content: {} }, 'create');\n\n      mockTransport.push.mockResolvedValue({\n        results: [\n          { noteId: 'note-1', success: true, newVersion: 1 },\n          { noteId: 'note-2', success: false, error: 'Server error' },\n        ],\n        serverTime: Date.now(),\n      });\n      mockTransport.pull.mockResolvedValue({\n        changes: [],\n        syncToken: 'token',\n        hasMore: false,\n        serverTime: Date.now(),\n      });\n\n      await engine.syncNow();\n\n      // note-1 should be synced, note-2 still pending\n      expect(engine.hasPendingChanges()).toBe(true);\n      // Verify only note-2 is in pending changes\n    });\n  });\n\n  describe('timeout handling', () =\u003e {\n    it('should timeout long-running requests', async () =\u003e {\n      mockTransport.push.mockImplementation(\n        () =\u003e new Promise((resolve) =\u003e setTimeout(resolve, 60000))\n      );\n\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n\n      // Should timeout before 60s\n      const result = await engine.syncNow();\n      expect(result.success).toBe(false);\n      expect(result.error).toContain('timeout');\n    }, 10000);\n  });\n\n  describe('server errors', () =\u003e {\n    it('should handle 5xx server errors gracefully', async () =\u003e {\n      mockTransport.push.mockRejectedValue({ status: 500, message: 'Internal Server Error' });\n\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n      const result = await engine.syncNow();\n\n      expect(result.success).toBe(false);\n      expect(engine.hasPendingChanges()).toBe(true); // Retry later\n    });\n\n    it('should handle 401 auth errors', async () =\u003e {\n      mockTransport.push.mockRejectedValue({ status: 401, message: 'Unauthorized' });\n\n      await engine.trackChange({ id: 'note-1', metadata: {}, content: {} }, 'create');\n      const result = await engine.syncNow();\n\n      expect(result.success).toBe(false);\n      expect(result.error).toContain('auth');\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Offline detection prevents sync attempts\n- [ ] Changes queue while offline\n- [ ] Queued changes sync when back online\n- [ ] Transient failures allow retry\n- [ ] Changes preserved after failures\n- [ ] Partial success handled correctly\n- [ ] Timeout handling works\n- [ ] Server error codes handled appropriately\n\n## Files to Create\n- `packages/engine-sync/src/network-recovery.integration.test.ts`\n\n## Dependencies\n- scribe-hao.11 (NetworkMonitor)\n- scribe-hao.12 (SyncTransport)\n- scribe-hao.15 (SyncCoordinator)\n\n## UNBLOCKS\n- scribe-hao.50 (end-to-end tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:25.77048-06:00","updated_at":"2025-12-29T20:46:19.007525-06:00","closed_at":"2025-12-29T20:46:19.007525-06:00","close_reason":"Implemented integration tests for network failure recovery with 28 test cases covering offline detection, transient failures, partial failures, timeouts, server errors, and recovery scenarios","dependencies":[{"issue_id":"scribe-hao.47","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:25.770881-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.47","depends_on_id":"scribe-hao.32","type":"blocks","created_at":"2025-12-27T22:04:42.89114-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.48","title":"[Phase 5.8] Integration tests for vault migration","description":"# [Phase 5.8] Integration tests for vault migration\n\n## Problem Statement\nTest the migration path for existing vaults that don't have sync enabled, ensuring a smooth upgrade experience without data loss.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/vault-migration.integration.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeEach, afterEach, vi } from 'vitest';\nimport { createSyncEngine } from './sync-engine';\nimport { mkdtempSync, rmSync, writeFileSync, mkdirSync, readFileSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\ndescribe('Vault Migration Integration', () =\u003e {\n  let tempDir: string;\n  let vaultPath: string;\n\n  beforeEach(() =\u003e {\n    tempDir = mkdtempSync(join(tmpdir(), 'migration-test-'));\n    vaultPath = tempDir;\n  });\n\n  afterEach(() =\u003e {\n    rmSync(tempDir, { recursive: true, force: true });\n  });\n\n  describe('fresh vault', () =\u003e {\n    it('should initialize sync for a new vault', async () =\u003e {\n      const engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      await engine.initialize();\n\n      // Should have created sync database\n      expect(() =\u003e readFileSync(join(tempDir, 'sync.sqlite3'))).not.toThrow();\n\n      await engine.shutdown();\n    });\n  });\n\n  describe('existing vault without sync', () =\u003e {\n    beforeEach(() =\u003e {\n      // Create a vault structure without sync\n      mkdirSync(join(vaultPath, 'notes'), { recursive: true });\n      writeFileSync(\n        join(vaultPath, 'notes', 'note-1.json'),\n        JSON.stringify({\n          id: 'note-1',\n          metadata: { title: 'Existing Note', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n          content: { text: 'existing content' },\n        })\n      );\n      writeFileSync(\n        join(vaultPath, 'notes', 'note-2.json'),\n        JSON.stringify({\n          id: 'note-2',\n          metadata: { title: 'Another Note', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n          content: { text: 'more content' },\n        })\n      );\n    });\n\n    it('should not modify existing notes during migration', async () =\u003e {\n      const engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      await engine.initialize();\n\n      // Existing notes should be unchanged\n      const note1 = JSON.parse(readFileSync(join(vaultPath, 'notes', 'note-1.json'), 'utf-8'));\n      expect(note1.id).toBe('note-1');\n      expect(note1.metadata.title).toBe('Existing Note');\n\n      await engine.shutdown();\n    });\n\n    it('should compute hashes for existing notes on first enable', async () =\u003e {\n      const engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      await engine.initialize();\n\n      // Enable sync - should hash existing notes\n      await engine.enable({ email: 'test@example.com', token: 'token' });\n\n      // Hashes should be stored (internal check via hasPendingChanges after first sync)\n      // In real implementation, would verify hashes are in database\n\n      await engine.shutdown();\n    });\n  });\n\n  describe('vault with partial sync state', () =\u003e {\n    beforeEach(() =\u003e {\n      // Create vault with some sync state\n      mkdirSync(join(vaultPath, 'derived'), { recursive: true });\n      \n      // Create a partially synced note\n      writeFileSync(\n        join(vaultPath, 'notes', 'synced-note.json'),\n        JSON.stringify({\n          id: 'synced-note',\n          metadata: { title: 'Synced', type: 'regular', createdAt: '2024-01-01', updatedAt: '2024-01-01' },\n          content: {},\n        })\n      );\n\n      // Create a new unsynced note\n      writeFileSync(\n        join(vaultPath, 'notes', 'new-note.json'),\n        JSON.stringify({\n          id: 'new-note',\n          metadata: { title: 'New', type: 'regular', createdAt: '2024-01-02', updatedAt: '2024-01-02' },\n          content: {},\n        })\n      );\n    });\n\n    it('should detect notes that need syncing', async () =\u003e {\n      const engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com',\n        config: { enabled: true },\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      await engine.initialize();\n\n      // New note should be detected as needing sync\n      // Implementation-specific verification\n\n      await engine.shutdown();\n    });\n  });\n\n  describe('sync database upgrade', () =\u003e {\n    it('should migrate from older schema version', async () =\u003e {\n      // Create old-format sync database\n      const dbPath = join(tempDir, 'sync.sqlite3');\n      // Write minimal v1 database (implementation-specific)\n\n      const engine = createSyncEngine({\n        vaultPath,\n        databasePath: dbPath,\n        serverUrl: 'https://sync.example.com',\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      // Should migrate without error\n      await expect(engine.initialize()).resolves.not.toThrow();\n\n      await engine.shutdown();\n    });\n  });\n\n  describe('config migration', () =\u003e {\n    it('should read legacy config format', async () =\u003e {\n      // Create legacy config\n      mkdirSync(join(vaultPath, '.scribe'), { recursive: true });\n      writeFileSync(\n        join(vaultPath, '.scribe', 'sync.json'),\n        JSON.stringify({\n          // Legacy format\n          server: 'https://old.sync.example.com',\n          auto_sync: true,\n        })\n      );\n\n      const engine = createSyncEngine({\n        vaultPath,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl: 'https://sync.example.com', // Default\n        onSaveNote: vi.fn(),\n        onDeleteNote: vi.fn(),\n      });\n\n      await engine.initialize();\n\n      // Should have migrated config\n      const config = engine.getConfig();\n      // Verify legacy values are preserved or migrated\n\n      await engine.shutdown();\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Fresh vaults initialize correctly\n- [ ] Existing notes are not modified\n- [ ] Hashes computed for existing notes\n- [ ] Partial sync state handled\n- [ ] Schema migrations work\n- [ ] Legacy config formats migrated\n\n## Files to Create\n- `packages/engine-sync/src/vault-migration.integration.test.ts`\n\n## Dependencies\n- scribe-hao.10 (SyncDatabase)\n- scribe-hao.16 (SyncEngine)\n- scribe-hao.21 (main.ts integration)\n\n## UNBLOCKS\n- scribe-hao.50 (end-to-end tests)","status":"closed","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:25.960823-06:00","updated_at":"2025-12-29T20:59:14.989847-06:00","closed_at":"2025-12-29T20:59:14.989847-06:00","close_reason":"Implemented vault-migration.integration.test.ts with 23 tests covering: fresh vault initialization, existing vault without sync, vault with partial sync state, sync database upgrades, config migration, and end-to-end migration scenarios. All tests pass.","dependencies":[{"issue_id":"scribe-hao.48","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:25.961212-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.48","depends_on_id":"scribe-hao.21","type":"blocks","created_at":"2025-12-27T22:04:43.096142-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.48","depends_on_id":"scribe-hao.32","type":"blocks","created_at":"2025-12-27T22:04:43.30681-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.49","title":"[Phase 5.9] Server endpoint tests","description":"# [Phase 5.9] Server endpoint tests\n\n## Problem Statement\nTest the sync server endpoints including authentication, push, pull, and status. Uses Cloudflare's miniflare for local testing.\n\n## Test Coverage\n\n### File: `apps/sync-server/src/routes/routes.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeAll, afterAll, beforeEach } from 'vitest';\nimport { unstable_dev } from 'wrangler';\nimport type { UnstableDevWorker } from 'wrangler';\n\ndescribe('Sync Server Endpoints', () =\u003e {\n  let worker: UnstableDevWorker;\n\n  beforeAll(async () =\u003e {\n    worker = await unstable_dev('src/index.ts', {\n      experimental: { disableExperimentalWarning: true },\n      local: true,\n      persist: false,\n    });\n  });\n\n  afterAll(async () =\u003e {\n    await worker.stop();\n  });\n\n  describe('GET /health', () =\u003e {\n    it('should return ok status', async () =\u003e {\n      const res = await worker.fetch('/health');\n      expect(res.status).toBe(200);\n      const body = await res.json();\n      expect(body.status).toBe('ok');\n    });\n  });\n\n  describe('POST /api/auth/register', () =\u003e {\n    it('should create new user', async () =\u003e {\n      const res = await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          email: 'test@example.com',\n          password: 'password123',\n        }),\n      });\n\n      expect(res.status).toBe(201);\n      const body = await res.json();\n      expect(body.accessToken).toBeDefined();\n      expect(body.refreshToken).toBeDefined();\n      expect(body.user.email).toBe('test@example.com');\n    });\n\n    it('should reject duplicate email', async () =\u003e {\n      // First registration\n      await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: 'dupe@example.com', password: 'password123' }),\n      });\n\n      // Second registration with same email\n      const res = await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: 'dupe@example.com', password: 'password123' }),\n      });\n\n      expect(res.status).toBe(409);\n    });\n\n    it('should reject weak password', async () =\u003e {\n      const res = await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: 'test2@example.com', password: '123' }),\n      });\n\n      expect(res.status).toBe(400);\n    });\n  });\n\n  describe('POST /api/auth/login', () =\u003e {\n    beforeEach(async () =\u003e {\n      // Create test user\n      await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: 'login@example.com', password: 'password123' }),\n      });\n    });\n\n    it('should return tokens for valid credentials', async () =\u003e {\n      const res = await worker.fetch('/api/auth/login', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: 'login@example.com', password: 'password123' }),\n      });\n\n      expect(res.status).toBe(200);\n      const body = await res.json();\n      expect(body.accessToken).toBeDefined();\n    });\n\n    it('should reject invalid credentials', async () =\u003e {\n      const res = await worker.fetch('/api/auth/login', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: 'login@example.com', password: 'wrongpassword' }),\n      });\n\n      expect(res.status).toBe(401);\n    });\n  });\n\n  describe('POST /api/sync/push', () =\u003e {\n    let accessToken: string;\n\n    beforeEach(async () =\u003e {\n      // Register and get token\n      const res = await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: `push-${Date.now()}@example.com`, password: 'password123' }),\n      });\n      const body = await res.json();\n      accessToken = body.accessToken;\n    });\n\n    it('should accept valid changes', async () =\u003e {\n      const res = await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          Authorization: `Bearer ${accessToken}`,\n        },\n        body: JSON.stringify({\n          changes: [{\n            noteId: 'note-1',\n            changeType: 'create',\n            contentHash: 'abc123',\n            baseVersion: 0,\n            note: { id: 'note-1', metadata: { title: 'Test' }, content: {} },\n          }],\n        }),\n      });\n\n      expect(res.status).toBe(200);\n      const body = await res.json();\n      expect(body.results[0].success).toBe(true);\n      expect(body.results[0].newVersion).toBe(1);\n    });\n\n    it('should require authentication', async () =\u003e {\n      const res = await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ changes: [] }),\n      });\n\n      expect(res.status).toBe(401);\n    });\n\n    it('should detect version conflicts', async () =\u003e {\n      // Create note\n      await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          Authorization: `Bearer ${accessToken}`,\n        },\n        body: JSON.stringify({\n          changes: [{ noteId: 'conflict-note', changeType: 'create', baseVersion: 0, note: { id: 'conflict-note', metadata: {}, content: {} } }],\n        }),\n      });\n\n      // Try to update with wrong version\n      const res = await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          Authorization: `Bearer ${accessToken}`,\n        },\n        body: JSON.stringify({\n          changes: [{ noteId: 'conflict-note', changeType: 'update', baseVersion: 0, note: { id: 'conflict-note', metadata: {}, content: { updated: true } } }],\n        }),\n      });\n\n      const body = await res.json();\n      expect(body.results[0].conflict).toBe(true);\n    });\n  });\n\n  describe('GET /api/sync/pull', () =\u003e {\n    let accessToken: string;\n\n    beforeEach(async () =\u003e {\n      const res = await worker.fetch('/api/auth/register', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({ email: `pull-${Date.now()}@example.com`, password: 'password123' }),\n      });\n      const body = await res.json();\n      accessToken = body.accessToken;\n    });\n\n    it('should return empty for new user', async () =\u003e {\n      const res = await worker.fetch('/api/sync/pull', {\n        headers: { Authorization: `Bearer ${accessToken}` },\n      });\n\n      expect(res.status).toBe(200);\n      const body = await res.json();\n      expect(body.changes).toEqual([]);\n    });\n\n    it('should return pushed notes', async () =\u003e {\n      // Push a note\n      await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          Authorization: `Bearer ${accessToken}`,\n        },\n        body: JSON.stringify({\n          changes: [{ noteId: 'pull-test', changeType: 'create', baseVersion: 0, note: { id: 'pull-test', metadata: { title: 'Pull Test' }, content: {} } }],\n        }),\n      });\n\n      // Pull\n      const res = await worker.fetch('/api/sync/pull', {\n        headers: { Authorization: `Bearer ${accessToken}` },\n      });\n\n      const body = await res.json();\n      expect(body.changes).toHaveLength(1);\n      expect(body.changes[0].noteId).toBe('pull-test');\n    });\n\n    it('should use sync token for incremental sync', async () =\u003e {\n      // Push first note\n      await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${accessToken}` },\n        body: JSON.stringify({ changes: [{ noteId: 'note-1', changeType: 'create', baseVersion: 0, note: { id: 'note-1', metadata: {}, content: {} } }] }),\n      });\n\n      // First pull\n      const res1 = await worker.fetch('/api/sync/pull', {\n        headers: { Authorization: `Bearer ${accessToken}` },\n      });\n      const body1 = await res1.json();\n      const token = body1.syncToken;\n\n      // Push second note\n      await worker.fetch('/api/sync/push', {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json', Authorization: `Bearer ${accessToken}` },\n        body: JSON.stringify({ changes: [{ noteId: 'note-2', changeType: 'create', baseVersion: 0, note: { id: 'note-2', metadata: {}, content: {} } }] }),\n      });\n\n      // Second pull with token\n      const res2 = await worker.fetch(`/api/sync/pull?token=${token}`, {\n        headers: { Authorization: `Bearer ${accessToken}` },\n      });\n      const body2 = await res2.json();\n\n      // Should only have the new note\n      expect(body2.changes).toHaveLength(1);\n      expect(body2.changes[0].noteId).toBe('note-2');\n    });\n  });\n\n  describe('rate limiting', () =\u003e {\n    it('should enforce rate limits', async () =\u003e {\n      // Make many requests quickly\n      const requests = Array.from({ length: 15 }, () =\u003e\n        worker.fetch('/api/auth/login', {\n          method: 'POST',\n          headers: { 'Content-Type': 'application/json' },\n          body: JSON.stringify({ email: 'test@example.com', password: 'wrong' }),\n        })\n      );\n\n      const responses = await Promise.all(requests);\n      const statuses = responses.map((r) =\u003e r.status);\n\n      // Some should be rate limited\n      expect(statuses).toContain(429);\n    });\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Health endpoint works\n- [ ] Registration creates user\n- [ ] Login returns tokens\n- [ ] Push accepts changes\n- [ ] Version conflicts detected\n- [ ] Pull returns notes\n- [ ] Sync token enables incremental sync\n- [ ] Rate limiting works\n\n## Files to Create\n- `apps/sync-server/src/routes/routes.test.ts`\n\n## Dependencies\n- scribe-hao.23 (sync-server package)\n- scribe-hao.25-31 (all server endpoints)\n\n## UNBLOCKS\n- scribe-hao.50 (end-to-end tests)","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:26.209871-06:00","updated_at":"2025-12-27T22:01:02.013362-06:00","dependencies":[{"issue_id":"scribe-hao.49","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:26.210288-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.49","depends_on_id":"scribe-hao.48","type":"blocks","created_at":"2025-12-27T22:04:43.501085-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.5","title":"[Phase 1.1] Create packages/engine-sync/ package structure","description":"# [Phase 1.1] Create packages/engine-sync/ package structure\n\n## Problem Statement\nCreate the new sync engine package following existing Scribe conventions for package structure, naming, and configuration.\n\n## Why This Architecture\n- **Monorepo pattern**: Follows existing `packages/engine-*` naming convention\n- **Shared across clients**: Desktop now, mobile and web later\n- **Clear boundaries**: Sync logic isolated from UI and storage concerns\n\n## Package Structure\n```\npackages/\n  engine-sync/\n    src/\n      index.ts                  # Public exports\n      types.ts                  # Internal sync-specific types\n      sync-engine.ts            # Main SyncEngine class\n      sync-coordinator.ts       # Orchestrates sync cycles\n      sync-transport.ts         # HTTP client with retry\n      sync-database.ts          # SQLite wrapper\n      sync-config.ts            # Config loading/saving\n      change-tracker.ts         # Observes local changes\n      conflict-resolver.ts      # Conflict detection/resolution\n      network-monitor.ts        # Online/offline detection\n      content-hash.ts           # SHA-256 hashing\n    package.json\n    tsconfig.json\n    vitest.config.ts\n    eslint.config.js\n    README.md\n```\n\n## Implementation\n\n### 1. package.json\n```json\n{\n  \"name\": \"@scribe/engine-sync\",\n  \"version\": \"0.1.0\",\n  \"private\": true,\n  \"type\": \"module\",\n  \"main\": \"./src/index.ts\",\n  \"types\": \"./src/index.ts\",\n  \"exports\": {\n    \".\": \"./src/index.ts\"\n  },\n  \"scripts\": {\n    \"build\": \"tsc --noEmit\",\n    \"lint\": \"eslint .\",\n    \"test\": \"vitest run\",\n    \"test:watch\": \"vitest\"\n  },\n  \"dependencies\": {\n    \"better-sqlite3\": \"^11.0.0\",\n    \"@scribe/shared\": \"workspace:*\"\n  },\n  \"devDependencies\": {\n    \"@scribe/test-utils\": \"workspace:*\",\n    \"@types/better-sqlite3\": \"^7.6.11\",\n    \"typescript\": \"^5.7.0\",\n    \"vitest\": \"^2.1.0\"\n  }\n}\n```\n\n### 2. tsconfig.json\n```json\n{\n  \"extends\": \"../../config/tsconfig/node.json\",\n  \"compilerOptions\": {\n    \"outDir\": \"./dist\",\n    \"rootDir\": \"./src\"\n  },\n  \"include\": [\"src/**/*\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\n### 3. vitest.config.ts\n```typescript\nimport { defineConfig } from 'vitest/config';\nimport baseConfig from '../../config/vitest/base';\n\nexport default defineConfig({\n  ...baseConfig,\n  test: {\n    ...baseConfig.test,\n    include: ['src/**/*.test.ts'],\n  },\n});\n```\n\n### 4. src/index.ts (initial exports)\n```typescript\n// Types\nexport type { SyncEngine, SyncStatus, SyncResult, SyncConfig } from './types';\n\n// Main class (to be implemented)\n// export { createSyncEngine } from './sync-engine';\n\n// Utilities (to be implemented)\n// export { computeContentHash } from './content-hash';\n```\n\n### 5. README.md\n```markdown\n# @scribe/engine-sync\n\nSync engine for Scribe, enabling multi-device synchronization with offline-first support.\n\n## Architecture\n\n- **Document-level sync**: Each note syncs as a whole JSON blob\n- **Offline-first**: Changes queue locally, sync when online\n- **Conflict detection**: Optimistic concurrency with manual resolution\n\n## Usage\n\nSync is opt-in. See the main app for integration.\n\n## Development\n\n\\`\\`\\`bash\nbun test packages/engine-sync\n\\`\\`\\`\n```\n\n## Verification Criteria\n- [ ] Package builds successfully: `bun build packages/engine-sync`\n- [ ] Lint passes: `bun lint packages/engine-sync`\n- [ ] Can be imported from other packages\n- [ ] Matches existing package conventions\n\n## Files to Create\n- `packages/engine-sync/package.json`\n- `packages/engine-sync/tsconfig.json`\n- `packages/engine-sync/vitest.config.ts`\n- `packages/engine-sync/eslint.config.js`\n- `packages/engine-sync/src/index.ts`\n- `packages/engine-sync/src/types.ts`\n- `packages/engine-sync/README.md`\n\n## Dependencies\n- None (first Phase 1 task)\n\n## UNBLOCKS\n- All other Phase 1 tasks (scribe-hao.6 through scribe-hao.16)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:17.757676-06:00","updated_at":"2025-12-29T13:15:07.429504-06:00","closed_at":"2025-12-29T13:15:07.429504-06:00","close_reason":"Created packages/engine-sync/ with package.json, tsconfig.json, vitest.config.ts, eslint.config.js, src/index.ts, src/types.ts, and README.md. Package registered, typecheck and lint pass.","dependencies":[{"issue_id":"scribe-hao.5","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:17.758035-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.5","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:01.519246-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.50","title":"[Phase 5.10] End-to-end sync scenario tests","description":"# [Phase 5.10] End-to-end sync scenario tests\n\n## Problem Statement\nCreate comprehensive end-to-end tests that simulate real multi-device sync scenarios, including initial sync, concurrent edits, and conflict resolution.\n\n## Test Coverage\n\n### File: `packages/engine-sync/src/e2e.test.ts`\n\n```typescript\nimport { describe, it, expect, beforeAll, afterAll, beforeEach } from 'vitest';\nimport { createSyncEngine } from './sync-engine';\nimport { unstable_dev } from 'wrangler';\nimport type { UnstableDevWorker } from 'wrangler';\nimport { mkdtempSync, rmSync, writeFileSync, mkdirSync } from 'fs';\nimport { join } from 'path';\nimport { tmpdir } from 'os';\n\ndescribe('End-to-End Sync Scenarios', () =\u003e {\n  let server: UnstableDevWorker;\n  let serverUrl: string;\n\n  beforeAll(async () =\u003e {\n    server = await unstable_dev('../sync-server/src/index.ts', {\n      experimental: { disableExperimentalWarning: true },\n      local: true,\n      persist: false,\n    });\n    serverUrl = `http://localhost:${server.port}`;\n  });\n\n  afterAll(async () =\u003e {\n    await server.stop();\n  });\n\n  describe('Scenario: Initial sync from empty vault', () =\u003e {\n    let tempDir: string;\n    let engine: ReturnType\u003ctypeof createSyncEngine\u003e;\n    let credentials: { email: string; token: string };\n\n    beforeEach(async () =\u003e {\n      tempDir = mkdtempSync(join(tmpdir(), 'e2e-initial-'));\n      \n      // Register user\n      const res = await fetch(`${serverUrl}/api/auth/register`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          email: `e2e-${Date.now()}@example.com`,\n          password: 'password123',\n        }),\n      });\n      const body = await res.json();\n      credentials = { email: body.user.email, token: body.accessToken };\n\n      engine = createSyncEngine({\n        vaultPath: tempDir,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl,\n        config: { enabled: true },\n        credentials,\n        onSaveNote: async () =\u003e {},\n        onDeleteNote: async () =\u003e {},\n      });\n      await engine.initialize();\n    });\n\n    afterEach(async () =\u003e {\n      await engine.shutdown();\n      rmSync(tempDir, { recursive: true, force: true });\n    });\n\n    it('should sync local notes to server', async () =\u003e {\n      // Create local notes\n      const notes = [\n        { id: 'note-1', metadata: { title: 'First', type: 'regular' }, content: { text: 'one' } },\n        { id: 'note-2', metadata: { title: 'Second', type: 'regular' }, content: { text: 'two' } },\n      ];\n\n      for (const note of notes) {\n        await engine.trackChange(note, 'create');\n      }\n\n      // Sync\n      const result = await engine.syncNow();\n\n      expect(result.success).toBe(true);\n      expect(result.pushed).toBe(2);\n      expect(engine.hasPendingChanges()).toBe(false);\n    });\n  });\n\n  describe('Scenario: Two devices syncing', () =\u003e {\n    let device1Dir: string;\n    let device2Dir: string;\n    let device1: ReturnType\u003ctypeof createSyncEngine\u003e;\n    let device2: ReturnType\u003ctypeof createSyncEngine\u003e;\n    let savedNotes1: Map\u003cstring, unknown\u003e;\n    let savedNotes2: Map\u003cstring, unknown\u003e;\n\n    beforeEach(async () =\u003e {\n      device1Dir = mkdtempSync(join(tmpdir(), 'e2e-device1-'));\n      device2Dir = mkdtempSync(join(tmpdir(), 'e2e-device2-'));\n      savedNotes1 = new Map();\n      savedNotes2 = new Map();\n\n      // Register shared user\n      const res = await fetch(`${serverUrl}/api/auth/register`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          email: `multidevice-${Date.now()}@example.com`,\n          password: 'password123',\n        }),\n      });\n      const body = await res.json();\n      const credentials = { email: body.user.email, token: body.accessToken };\n\n      // Create both devices with same account\n      device1 = createSyncEngine({\n        vaultPath: device1Dir,\n        databasePath: join(device1Dir, 'sync.sqlite3'),\n        serverUrl,\n        config: { enabled: true },\n        credentials,\n        onSaveNote: async (note) =\u003e { savedNotes1.set(note.id, note); },\n        onDeleteNote: async () =\u003e {},\n      });\n\n      device2 = createSyncEngine({\n        vaultPath: device2Dir,\n        databasePath: join(device2Dir, 'sync.sqlite3'),\n        serverUrl,\n        config: { enabled: true },\n        credentials,\n        onSaveNote: async (note) =\u003e { savedNotes2.set(note.id, note); },\n        onDeleteNote: async () =\u003e {},\n      });\n\n      await device1.initialize();\n      await device2.initialize();\n    });\n\n    afterEach(async () =\u003e {\n      await device1.shutdown();\n      await device2.shutdown();\n      rmSync(device1Dir, { recursive: true, force: true });\n      rmSync(device2Dir, { recursive: true, force: true });\n    });\n\n    it('should sync notes from device 1 to device 2', async () =\u003e {\n      // Device 1 creates a note\n      const note = { id: 'shared-note', metadata: { title: 'Shared', type: 'regular' }, content: { text: 'from device 1' } };\n      await device1.trackChange(note, 'create');\n      await device1.syncNow();\n\n      // Device 2 syncs and gets the note\n      await device2.syncNow();\n\n      expect(savedNotes2.has('shared-note')).toBe(true);\n      const received = savedNotes2.get('shared-note') as { metadata: { title: string } };\n      expect(received.metadata.title).toBe('Shared');\n    });\n\n    it('should handle non-conflicting edits', async () =\u003e {\n      // Both devices create different notes\n      await device1.trackChange({ id: 'note-a', metadata: { title: 'A' }, content: {} }, 'create');\n      await device2.trackChange({ id: 'note-b', metadata: { title: 'B' }, content: {} }, 'create');\n\n      // Both sync\n      await device1.syncNow();\n      await device2.syncNow();\n      await device1.syncNow(); // Device 1 gets note-b\n\n      expect(savedNotes1.has('note-b')).toBe(true);\n      expect(savedNotes2.has('note-a')).toBe(true);\n    });\n\n    it('should detect conflict on simultaneous edit', async () =\u003e {\n      // Create shared note\n      const note = { id: 'conflict-note', metadata: { title: 'Original' }, content: {} };\n      await device1.trackChange(note, 'create');\n      await device1.syncNow();\n      await device2.syncNow(); // Device 2 gets the note\n\n      // Both edit simultaneously (before syncing)\n      savedNotes1.set('conflict-note', { ...note, metadata: { title: 'Edit by D1' } });\n      savedNotes2.set('conflict-note', { ...note, metadata: { title: 'Edit by D2' } });\n\n      await device1.trackChange({ ...note, metadata: { title: 'Edit by D1' } }, 'update');\n      await device2.trackChange({ ...note, metadata: { title: 'Edit by D2' } }, 'update');\n\n      // Device 1 syncs first\n      await device1.syncNow();\n\n      // Device 2 syncs - should conflict\n      await device2.syncNow();\n\n      const conflicts = device2.getPendingConflicts();\n      expect(conflicts).toHaveLength(1);\n      expect(conflicts[0].noteId).toBe('conflict-note');\n    });\n  });\n\n  describe('Scenario: Offline then online', () =\u003e {\n    it('should sync accumulated changes when back online', async () =\u003e {\n      const tempDir = mkdtempSync(join(tmpdir(), 'e2e-offline-'));\n      const savedNotes = new Map();\n\n      // Register user\n      const res = await fetch(`${serverUrl}/api/auth/register`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          email: `offline-${Date.now()}@example.com`,\n          password: 'password123',\n        }),\n      });\n      const body = await res.json();\n\n      const engine = createSyncEngine({\n        vaultPath: tempDir,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl,\n        config: { enabled: true },\n        credentials: { email: body.user.email, token: body.accessToken },\n        onSaveNote: async (note) =\u003e { savedNotes.set(note.id, note); },\n        onDeleteNote: async () =\u003e {},\n      });\n      await engine.initialize();\n\n      // Make changes \"offline\" (don't sync)\n      await engine.trackChange({ id: 'offline-1', metadata: { title: 'Offline 1' }, content: {} }, 'create');\n      await engine.trackChange({ id: 'offline-2', metadata: { title: 'Offline 2' }, content: {} }, 'create');\n      await engine.trackChange({ id: 'offline-3', metadata: { title: 'Offline 3' }, content: {} }, 'create');\n\n      expect(engine.hasPendingChanges()).toBe(true);\n\n      // \"Come back online\" and sync\n      const result = await engine.syncNow();\n\n      expect(result.success).toBe(true);\n      expect(result.pushed).toBe(3);\n      expect(engine.hasPendingChanges()).toBe(false);\n\n      await engine.shutdown();\n      rmSync(tempDir, { recursive: true, force: true });\n    });\n  });\n\n  describe('Scenario: Large vault initial sync', () =\u003e {\n    it('should handle initial sync of many notes', async () =\u003e {\n      const tempDir = mkdtempSync(join(tmpdir(), 'e2e-large-'));\n\n      const res = await fetch(`${serverUrl}/api/auth/register`, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify({\n          email: `large-${Date.now()}@example.com`,\n          password: 'password123',\n        }),\n      });\n      const body = await res.json();\n\n      const engine = createSyncEngine({\n        vaultPath: tempDir,\n        databasePath: join(tempDir, 'sync.sqlite3'),\n        serverUrl,\n        config: { enabled: true },\n        credentials: { email: body.user.email, token: body.accessToken },\n        onSaveNote: async () =\u003e {},\n        onDeleteNote: async () =\u003e {},\n      });\n      await engine.initialize();\n\n      // Create 50 notes\n      for (let i = 0; i \u003c 50; i++) {\n        await engine.trackChange({\n          id: `note-${i}`,\n          metadata: { title: `Note ${i}` },\n          content: { text: `Content for note ${i}` },\n        }, 'create');\n      }\n\n      const result = await engine.syncNow();\n\n      expect(result.success).toBe(true);\n      expect(result.pushed).toBe(50);\n\n      await engine.shutdown();\n      rmSync(tempDir, { recursive: true, force: true });\n    }, 30000); // Longer timeout for large sync\n  });\n});\n```\n\n## Verification Criteria\n- [ ] Initial sync works for new vault\n- [ ] Notes sync between devices\n- [ ] Non-conflicting edits merge correctly\n- [ ] Conflicts detected for simultaneous edits\n- [ ] Offline changes sync when back online\n- [ ] Large vault sync completes successfully\n- [ ] All scenarios complete without data loss\n\n## Files to Create\n- `packages/engine-sync/src/e2e.test.ts`\n\n## Dependencies\n- All Phase 1-3 implementations\n- scribe-hao.49 (server tests verify server works)\n- scribe-hao.45-48 (integration tests verify components)\n\n## UNBLOCKS\n- Sync Engine ready for production use","status":"open","priority":2,"issue_type":"task","created_at":"2025-12-27T21:28:26.454813-06:00","updated_at":"2025-12-27T22:01:48.406335-06:00","dependencies":[{"issue_id":"scribe-hao.50","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:26.455199-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.50","depends_on_id":"scribe-hao.48","type":"blocks","created_at":"2025-12-27T22:04:43.691902-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.51","title":"[Phase 0.5] Verify sync initialization after engine-sync package exists","description":"# [Phase 0.5] Verify sync initialization after engine-sync package exists\n\n## Problem Statement\nAfter Phase 1 creates the `packages/engine-sync/` package with proper `loadSyncConfig()`, we need to verify the complete initialization flow works correctly and that no sync code runs when disabled.\n\n## Why This Exists\nThis is the **verification counterpart** to scribe-hao.1. The skeleton was added early, but we can only fully verify once the real implementation exists.\n\n## Implementation Steps\n\n### 1. Replace temporary checkSyncEnabled with real implementation\n```typescript\n// apps/desktop/electron/main/src/main.ts\n\nimport { loadSyncConfig, createSyncEngine } from '@scribe/engine-sync';\n\nasync function initializeEngines(vaultPath: string): Promise\u003cvoid\u003e {\n  // ... existing engine initialization ...\n  \n  // SYNC: Disabled by default - only initialize if explicitly enabled\n  const syncConfig = await loadSyncConfig(vaultPath);\n  if (syncConfig?.enabled === true) {\n    deps.syncEngine = await createSyncEngine({\n      vaultPath,\n      config: syncConfig,\n      vault: deps.vault,\n    });\n    logger.info('Sync engine initialized', { deviceId: deps.syncEngine.getDeviceId() });\n  } else {\n    deps.syncEngine = null;\n    logger.info('Sync disabled - no sync engine initialized');\n  }\n}\n```\n\n### 2. Add integration test for disabled state\n```typescript\n// apps/desktop/sync-disabled.integration.test.ts\n\ndescribe('Sync Disabled State', () =\u003e {\n  it('should not initialize SyncEngine when sync.json is missing', async () =\u003e {\n    const deps = await initializeTestApp({ withSyncConfig: false });\n    expect(deps.syncEngine).toBeNull();\n  });\n\n  it('should not initialize SyncEngine when enabled is false', async () =\u003e {\n    await writeSyncConfig({ enabled: false });\n    const deps = await initializeTestApp();\n    expect(deps.syncEngine).toBeNull();\n  });\n\n  it('should not make any network calls when disabled', async () =\u003e {\n    const networkSpy = vi.spyOn(global, 'fetch');\n    const deps = await initializeTestApp({ withSyncConfig: false });\n    \n    // Simulate user activity\n    await deps.vault.save(createTestNote());\n    await new Promise(r =\u003e setTimeout(r, 100));\n    \n    expect(networkSpy).not.toHaveBeenCalled();\n  });\n});\n```\n\n### 3. Verify bundle doesn't include sync code when disabled\nAdd a build-time check that verifies lazy loading works correctly.\n\n## Verification Criteria\n- [ ] `loadSyncConfig()` from engine-sync works correctly\n- [ ] `createSyncEngine()` is never called when disabled\n- [ ] No network requests occur during normal app usage when disabled\n- [ ] Bundle analysis shows sync code is not loaded when disabled\n\n## Files to Modify\n- `apps/desktop/electron/main/src/main.ts` (replace temporary implementation)\n- `apps/desktop/sync-disabled.integration.test.ts` (NEW)\n\n## Dependencies\n- scribe-hao.1 (Skeleton pattern exists)\n- scribe-hao.5 (engine-sync package exists)\n- scribe-hao.16 (SyncEngine class exists)\n\n## UNBLOCKS\n- scribe-hao.21 (Full SyncEngine integration in main.ts)","status":"closed","priority":0,"issue_type":"task","created_at":"2025-12-27T22:15:00.010835-06:00","updated_at":"2025-12-29T13:54:46.809007-06:00","closed_at":"2025-12-29T13:54:46.809007-06:00","close_reason":"Created loadSyncConfig, isSyncEnabled, saveSyncConfig functions. Updated main.ts to use engine-sync package. 218 engine-sync tests + 20 integration tests pass.","dependencies":[{"issue_id":"scribe-hao.51","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T22:15:00.011229-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.52","title":"[Phase 2.7] Implement vault migration when sync is first enabled","description":"# [Phase 2.7] Implement vault migration when sync is first enabled\n\n## Problem Statement\nWhen a user enables sync for the first time on an existing vault, all existing notes need to be prepared for synchronization:\n1. Add `SyncMetadata` to each note\n2. Compute initial content hashes\n3. Queue all notes for initial upload to server\n\nThis is a **critical missing piece** - without it, existing notes would never sync.\n\n## User Flow\n1. User clicks \"Enable Sync\" in Settings\n2. User creates account / enters API key\n3. **Migration runs**: \n   - Progress modal shows \"Preparing X notes for sync...\"\n   - Each note gets SyncMetadata added\n   - All notes queued for push\n4. Initial sync begins uploading notes\n\n## Implementation\n\n### 1. VaultMigrator class\n```typescript\n// packages/engine-sync/src/vault-migrator.ts\n\nimport type { Note, NoteId } from '@scribe/shared';\nimport type { IVault } from '@scribe/storage-fs';\nimport type { SyncDatabase } from './sync-database';\nimport type { ContentHasher } from './content-hash';\n\nexport interface MigrationProgress {\n  total: number;\n  completed: number;\n  currentNote?: string;\n  phase: 'scanning' | 'migrating' | 'queueing' | 'complete';\n}\n\nexport interface VaultMigratorConfig {\n  vault: IVault;\n  database: SyncDatabase;\n  contentHasher: ContentHasher;\n  onProgress?: (progress: MigrationProgress) =\u003e void;\n}\n\nexport class VaultMigrator {\n  private readonly vault: IVault;\n  private readonly database: SyncDatabase;\n  private readonly contentHasher: ContentHasher;\n  private readonly onProgress?: (progress: MigrationProgress) =\u003e void;\n\n  constructor(config: VaultMigratorConfig) {\n    this.vault = config.vault;\n    this.database = config.database;\n    this.contentHasher = config.contentHasher;\n    this.onProgress = config.onProgress;\n  }\n\n  /**\n   * Migrate all existing notes to be sync-ready.\n   * Should be called once when sync is first enabled.\n   */\n  async migrateVault(): Promise\u003c{ migrated: number; errors: string[] }\u003e {\n    const errors: string[] = [];\n    \n    // Phase 1: Scan all notes\n    this.reportProgress({ total: 0, completed: 0, phase: 'scanning' });\n    const noteIds = await this.vault.listNoteIds();\n    const total = noteIds.length;\n\n    // Phase 2: Migrate each note\n    let completed = 0;\n    for (const noteId of noteIds) {\n      try {\n        this.reportProgress({ \n          total, \n          completed, \n          currentNote: noteId, \n          phase: 'migrating' \n        });\n\n        await this.migrateNote(noteId);\n        completed++;\n      } catch (error) {\n        errors.push(`Failed to migrate ${noteId}: ${error}`);\n      }\n    }\n\n    // Phase 3: Queue all for initial push\n    this.reportProgress({ total, completed, phase: 'queueing' });\n    await this.queueInitialPush(noteIds);\n\n    this.reportProgress({ total, completed: total, phase: 'complete' });\n\n    return { migrated: completed, errors };\n  }\n\n  private async migrateNote(noteId: NoteId): Promise\u003cvoid\u003e {\n    const note = await this.vault.read(noteId);\n    if (!note) return;\n\n    // Skip if already has sync metadata\n    if (note.sync?.version) {\n      return;\n    }\n\n    // Add SyncMetadata\n    const contentHash = this.contentHasher.computeHash(note);\n    const migratedNote: Note = {\n      ...note,\n      sync: {\n        version: 1,                    // Initial version\n        contentHash,\n        serverVersion: undefined,      // Never synced\n        syncedAt: undefined,           // Never synced\n        deviceId: await this.database.getDeviceId(),\n      },\n    };\n\n    // Save back to vault\n    await this.vault.save(migratedNote);\n\n    // Record in sync state table\n    this.database.setSyncState(noteId, {\n      localVersion: 1,\n      serverVersion: null,\n      contentHash,\n      lastSyncedAt: null,\n      status: 'pending',\n    });\n  }\n\n  private async queueInitialPush(noteIds: NoteId[]): Promise\u003cvoid\u003e {\n    for (const noteId of noteIds) {\n      const note = await this.vault.read(noteId);\n      if (note) {\n        this.database.queueChange(noteId, 'create', 1, note);\n      }\n    }\n  }\n\n  private reportProgress(progress: MigrationProgress): void {\n    this.onProgress?.(progress);\n  }\n}\n```\n\n### 2. Migration check on sync enable\n```typescript\n// Called when user enables sync\n\nasync function enableSync(vaultPath: string, apiKey: string): Promise\u003cvoid\u003e {\n  // 1. Save sync config\n  await saveSyncConfig(vaultPath, { enabled: true, apiKeyHash: hash(apiKey), ... });\n  \n  // 2. Initialize sync engine\n  const syncEngine = await createSyncEngine({ vaultPath, ... });\n  \n  // 3. Check if migration needed\n  const needsMigration = await syncEngine.checkMigrationNeeded();\n  if (needsMigration) {\n    // 4. Run migration with progress callback\n    await syncEngine.migrateVault((progress) =\u003e {\n      // Update UI progress modal\n      mainWindow.webContents.send('sync:migrationProgress', progress);\n    });\n  }\n  \n  // 5. Start initial sync\n  await syncEngine.triggerSync();\n}\n```\n\n### 3. IPC for progress updates\n```typescript\n// Add to IPC contract\nSYNC_MIGRATION_PROGRESS: 'sync:migrationProgress',  // Event\n\n// In preload\nonMigrationProgress: (callback: (progress: MigrationProgress) =\u003e void) =\u003e {\n  ipcRenderer.on('sync:migrationProgress', (_, progress) =\u003e callback(progress));\n},\n```\n\n## Edge Cases\n- **Large vaults**: Progress UI prevents user thinking app is frozen\n- **Interrupted migration**: Track migration state, resume on next launch\n- **Corrupted notes**: Skip and log errors, don't block migration\n- **Notes added during migration**: Will be caught by normal ChangeTracker\n\n## Files to Create\n- `packages/engine-sync/src/vault-migrator.ts`\n- `packages/engine-sync/src/vault-migrator.test.ts`\n\n## Dependencies\n- scribe-hao.9 (ContentHasher)\n- scribe-hao.10 (SyncDatabase)\n- scribe-hao.16 (SyncEngine)\n- scribe-hao.7 (SyncMetadata in BaseNote)\n\n## UNBLOCKS\n- scribe-hao.37 (SyncProgressModal UI)\n- scribe-hao.21 (SyncEngine initialization - needs to check migration)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T22:16:17.905092-06:00","updated_at":"2025-12-29T14:03:05.581937-06:00","closed_at":"2025-12-29T14:03:05.581937-06:00","close_reason":"Implemented VaultMigrator with migrateVault, needsMigration methods. Adds SyncMetadata, queues notes for push. 16 tests passing.","dependencies":[{"issue_id":"scribe-hao.52","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T22:16:17.90552-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.53","title":"[Phase 2.8] Implement secure API key storage using Electron safeStorage","description":"# [Phase 2.8] Implement secure API key storage using Electron safeStorage\n\n## Problem Statement\nThe sync API key is a sensitive credential that must be stored securely. It cannot be stored in plaintext in `sync.json`. Electron provides `safeStorage` for encrypted credential storage.\n\n## Why This is Important\n- API key grants full access to user's synced notes\n- Plaintext storage is a security vulnerability\n- Enterprise users may have compliance requirements for credential storage\n- Users expect their credentials to be protected\n\n## Electron safeStorage Overview\n- Uses OS-level credential storage (Keychain on macOS, Credential Manager on Windows, libsecret on Linux)\n- Encrypts data with user's login credentials\n- Data is automatically decrypted when app runs under same user\n- No manual key management needed\n\n## Implementation\n\n### 1. Credential Manager Class\n```typescript\n// apps/desktop/electron/main/src/sync/credential-manager.ts\n\nimport { safeStorage } from 'electron';\nimport * as fs from 'fs/promises';\nimport * as path from 'path';\n\nconst CREDENTIAL_FILE_NAME = '.sync-credentials';\n\nexport interface SyncCredentials {\n  apiKey: string;\n  userId?: string;\n}\n\n/**\n * Secure credential storage for sync API keys.\n * \n * Uses Electron's safeStorage API which encrypts data using\n * the OS-level credential store:\n * - macOS: Keychain\n * - Windows: DPAPI (Credential Manager)\n * - Linux: libsecret (GNOME Keyring, KWallet, etc.)\n */\nexport class CredentialManager {\n  private readonly credentialPath: string;\n\n  constructor(vaultPath: string) {\n    // Store encrypted credentials in vault's .scribe directory\n    this.credentialPath = path.join(vaultPath, '.scribe', CREDENTIAL_FILE_NAME);\n  }\n\n  /**\n   * Check if safeStorage encryption is available.\n   * May be false on some Linux systems without libsecret.\n   */\n  isEncryptionAvailable(): boolean {\n    return safeStorage.isEncryptionAvailable();\n  }\n\n  /**\n   * Store API key securely.\n   */\n  async storeCredentials(credentials: SyncCredentials): Promise\u003cvoid\u003e {\n    if (!this.isEncryptionAvailable()) {\n      throw new Error(\n        'Secure storage not available. Please install a keyring service (e.g., gnome-keyring).'\n      );\n    }\n\n    const plaintext = JSON.stringify(credentials);\n    const encrypted = safeStorage.encryptString(plaintext);\n    \n    // Ensure directory exists\n    await fs.mkdir(path.dirname(this.credentialPath), { recursive: true });\n    \n    // Write encrypted buffer to file\n    await fs.writeFile(this.credentialPath, encrypted);\n  }\n\n  /**\n   * Retrieve stored API key.\n   * Returns null if no credentials stored.\n   */\n  async getCredentials(): Promise\u003cSyncCredentials | null\u003e {\n    if (!this.isEncryptionAvailable()) {\n      return null;\n    }\n\n    try {\n      const encrypted = await fs.readFile(this.credentialPath);\n      const plaintext = safeStorage.decryptString(encrypted);\n      return JSON.parse(plaintext) as SyncCredentials;\n    } catch {\n      return null; // File doesn't exist or decryption failed\n    }\n  }\n\n  /**\n   * Get just the API key (convenience method).\n   */\n  async getApiKey(): Promise\u003cstring | null\u003e {\n    const credentials = await this.getCredentials();\n    return credentials?.apiKey ?? null;\n  }\n\n  /**\n   * Delete stored credentials (on sync disable).\n   */\n  async clearCredentials(): Promise\u003cvoid\u003e {\n    try {\n      await fs.unlink(this.credentialPath);\n    } catch {\n      // File might not exist, that's fine\n    }\n  }\n\n  /**\n   * Check if credentials are stored.\n   */\n  async hasCredentials(): Promise\u003cboolean\u003e {\n    try {\n      await fs.access(this.credentialPath);\n      return true;\n    } catch {\n      return false;\n    }\n  }\n}\n```\n\n### 2. Integration with SyncEngine\n```typescript\n// When creating SyncEngine, load API key from secure storage\n\nconst credentialManager = new CredentialManager(vaultPath);\nconst apiKey = await credentialManager.getApiKey();\n\nif (!apiKey) {\n  throw new Error('No API key found. Please enable sync in Settings.');\n}\n\nconst transport = new SyncTransport(syncConfig.serverUrl, apiKey);\n```\n\n### 3. Enable Sync Flow\n```typescript\n// In sync enable handler\n\nasync function handleEnableSync(\n  vaultPath: string, \n  credentials: SyncCredentials\n): Promise\u003cvoid\u003e {\n  const credentialManager = new CredentialManager(vaultPath);\n  \n  // Store credentials securely first\n  await credentialManager.storeCredentials(credentials);\n  \n  // Then save config (without API key!)\n  await saveSyncConfig(vaultPath, {\n    enabled: true,\n    deviceId: crypto.randomUUID(),\n    enabledAt: Date.now(),\n    serverUrl: DEFAULT_SYNC_CONFIG.serverUrl,\n    // Note: NO API key in config!\n  });\n}\n```\n\n### 4. Disable Sync Flow\n```typescript\nasync function handleDisableSync(vaultPath: string): Promise\u003cvoid\u003e {\n  const credentialManager = new CredentialManager(vaultPath);\n  \n  // Clear credentials\n  await credentialManager.clearCredentials();\n  \n  // Update config\n  const config = await loadSyncConfig(vaultPath);\n  if (config) {\n    await saveSyncConfig(vaultPath, { ...config, enabled: false });\n  }\n}\n```\n\n## Fallback for Unsupported Systems\nOn systems without libsecret (rare), show an error explaining that secure storage is required:\n\n```typescript\nif (!credentialManager.isEncryptionAvailable()) {\n  dialog.showErrorBox(\n    'Secure Storage Required',\n    'Sync requires a system keyring service.\\n\\n' +\n    'Please install gnome-keyring or another keyring provider.'\n  );\n  return;\n}\n```\n\n## Files to Create\n- `apps/desktop/electron/main/src/sync/credential-manager.ts`\n- `apps/desktop/electron/main/src/sync/credential-manager.test.ts`\n\n## Dependencies\n- scribe-hao.3 (SyncConfig schema - credentials stored separately)\n\n## UNBLOCKS\n- scribe-hao.12 (SyncTransport needs API key)\n- scribe-hao.16 (SyncEngine needs API key)\n- scribe-hao.38 (SyncSettingsPanel needs to store credentials on enable)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T22:17:30.304042-06:00","updated_at":"2025-12-29T14:03:05.760064-06:00","closed_at":"2025-12-29T14:03:05.760064-06:00","close_reason":"Implemented CredentialManager using Electron safeStorage. Secure credential storage with storeCredentials, getCredentials, clearCredentials. 16 tests passing.","dependencies":[{"issue_id":"scribe-hao.53","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T22:17:30.304517-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.6","title":"[Phase 1.2] Define sync types in @scribe/shared","description":"# [Phase 1.2] Define sync types in @scribe/shared\n\n## Problem Statement\nDefine all sync-related types in the shared package so they can be used by both client (desktop, mobile, web) and server.\n\n## Types to Define\n\n### 1. SyncMetadata (for BaseNote extension)\n```typescript\n// packages/shared/src/types/sync-types.ts\n\n/**\n * Sync metadata attached to each note.\n * Optional field on BaseNote - only present when sync is enabled.\n */\nexport interface SyncMetadata {\n  /** Per-note monotonic counter, starts at 1 */\n  version: number;\n  /** SHA-256 of serialized sync-relevant fields (truncated to 16 chars) */\n  contentHash: string;\n  /** Last known server version (for conflict detection) */\n  serverVersion?: number;\n  /** Timestamp of last successful sync (ms since epoch) */\n  syncedAt?: number;\n  /** Device ID that made the last local change */\n  deviceId?: string;\n}\n```\n\n### 2. Sync Protocol Types\n```typescript\n// Push request/response\nexport interface SyncPushRequest {\n  deviceId: string;\n  changes: SyncChange[];\n}\n\nexport interface SyncChange {\n  noteId: string;\n  operation: 'create' | 'update' | 'delete';\n  version: number;\n  baseVersion?: number;\n  contentHash?: string;\n  payload?: unknown; // Full note for create/update\n}\n\nexport interface SyncPushResponse {\n  accepted: {\n    noteId: string;\n    serverVersion: number;\n    serverSequence: number;\n  }[];\n  conflicts: {\n    noteId: string;\n    serverVersion: number;\n    serverNote: unknown; // Full server note\n  }[];\n  errors: {\n    noteId: string;\n    error: string;\n    retryable: boolean;\n  }[];\n}\n\n// Pull request/response\nexport interface SyncPullRequest {\n  deviceId: string;\n  sinceSequence?: number;\n  limit?: number;\n  priorityNoteIds?: string[];\n}\n\nexport interface SyncPullResponse {\n  changes: {\n    noteId: string;\n    operation: 'create' | 'update' | 'delete';\n    version: number;\n    serverSequence: number;\n    note?: unknown;\n    timestamp: string;\n  }[];\n  hasMore: boolean;\n  latestSequence: number;\n  serverTime: string;\n}\n```\n\n### 3. Sync Status Types\n```typescript\nexport type SyncState = 'idle' | 'syncing' | 'offline' | 'error' | 'disabled';\n\nexport interface SyncStatus {\n  state: SyncState;\n  lastSyncAt?: number;\n  pendingChanges: number;\n  conflictCount: number;\n  error?: string;\n  nextSyncAt?: number;\n}\n\nexport interface SyncResult {\n  pushed: number;\n  pulled: number;\n  conflicts: number;\n  errors: string[];\n}\n```\n\n### 4. Conflict Types\n```typescript\nexport interface Conflict {\n  noteId: string;\n  localNote: unknown;\n  remoteNote: unknown;\n  localVersion: number;\n  remoteVersion: number;\n  detectedAt: number;\n  type: 'edit' | 'delete-edit' | 'edit-delete';\n}\n\nexport type ConflictResolution =\n  | { type: 'keep_local' }\n  | { type: 'keep_remote' }\n  | { type: 'keep_both' };\n```\n\n### 5. Config Types\n```typescript\nexport interface SyncConfig {\n  enabled: boolean;\n  serverUrl: string;\n  apiKeyHash: string;\n  deviceId: string;\n  lastSyncSequence: number;\n  enabledAt: number;\n}\n\nexport interface SyncEnableOptions {\n  strategy: 'push_local' | 'pull_remote' | 'merge';\n  apiKey: string;\n  serverUrl?: string;\n}\n```\n\n## Export from shared\n```typescript\n// packages/shared/src/types/index.ts\nexport * from './sync-types.js';\n\n// packages/shared/src/index.ts\nexport * from './types/sync-types.js';\n```\n\n## Files to Create/Modify\n- `packages/shared/src/types/sync-types.ts` (NEW)\n- `packages/shared/src/types/index.ts` (MODIFY)\n- `packages/shared/src/index.ts` (MODIFY)\n\n## Dependencies\n- scribe-hao.5 (Create engine-sync package)\n\n## UNBLOCKS\n- scribe-hao.7 (Add SyncMetadata to BaseNote)\n- scribe-hao.8 (Extend EngineName and ErrorCode)\n- scribe-hao.17 (IPC contract extension)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:17.938132-06:00","updated_at":"2025-12-29T13:17:17.620725-06:00","closed_at":"2025-12-29T13:17:17.620725-06:00","close_reason":"Added SyncMetadata, SyncPushRequest/Response, SyncPullRequest/Response, SyncConflict, ConflictResolution, SyncState, SyncStatus, SyncResult types. All exports verified, typecheck and lint pass.","dependencies":[{"issue_id":"scribe-hao.6","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:17.938476-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.6","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:01.72958-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.6","depends_on_id":"scribe-hao.5","type":"blocks","created_at":"2025-12-27T22:03:28.066858-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.7","title":"[Phase 1.3] Add SyncMetadata to BaseNote interface","description":"# [Phase 1.3] Add SyncMetadata to BaseNote interface\n\n## Problem Statement\nExtend the BaseNote interface to include optional sync metadata. This enables sync tracking per-note while maintaining backward compatibility with existing notes.\n\n## Current BaseNote (from note-types.ts)\n```typescript\nexport interface BaseNote {\n  id: NoteId;\n  title: string;\n  createdAt: number;\n  updatedAt: number;\n  tags: string[];\n  content: EditorContent;\n  metadata: NoteMetadata;\n}\n```\n\n## Target BaseNote\n```typescript\nexport interface BaseNote {\n  id: NoteId;\n  title: string;\n  createdAt: number;\n  updatedAt: number;\n  tags: string[];\n  content: EditorContent;\n  metadata: NoteMetadata;\n  /** \n   * Sync metadata for multi-device synchronization.\n   * Optional for migration - only present when sync is enabled for this vault.\n   * @since 1.1.0\n   */\n  sync?: SyncMetadata;\n}\n```\n\n## Implementation Steps\n\n### 1. Import SyncMetadata type\n```typescript\n// packages/shared/src/types/note-types.ts\n\nimport type { SyncMetadata } from './sync-types.js';\n```\n\n### 2. Add sync field to BaseNote\n```typescript\nexport interface BaseNote {\n  // ... existing fields ...\n  \n  /**\n   * Sync metadata for multi-device synchronization.\n   * \n   * This field is optional for backward compatibility:\n   * - Vaults without sync enabled: field is undefined\n   * - Vaults with sync enabled: field is present with version/hash\n   * \n   * When present, the sync engine uses this to:\n   * - Detect conflicts (version mismatch)\n   * - Skip unchanged notes (hash comparison)\n   * - Track last sync time per note\n   * \n   * @since 1.1.0\n   */\n  sync?: SyncMetadata;\n}\n```\n\n## Migration Considerations\n\n### Existing Vaults\n- Existing notes won't have `sync` field - that's fine\n- When sync is enabled, notes get `sync` field on first save\n- No migration script needed - field is optional\n\n### JSON Serialization\n- Storage layer already handles unknown fields gracefully\n- No changes needed to FileSystemVault\n\n### Type Guards\nNo changes needed to type guards - sync is on BaseNote, inherited by all variants.\n\n## Verification Criteria\n- [ ] TypeScript compiles without errors\n- [ ] Existing notes without sync field still work\n- [ ] New notes can have sync field added\n- [ ] All note type variants inherit sync field\n\n## Files to Modify\n- `packages/shared/src/types/note-types.ts`\n\n## Dependencies\n- scribe-hao.6 (Define sync types)\n\n## UNBLOCKS\n- scribe-hao.9 (Content hash - needs SyncMetadata defined)\n- scribe-hao.16 (SyncEngine - needs Note type with sync field)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:18.122344-06:00","updated_at":"2025-12-29T13:24:47.848084-06:00","closed_at":"2025-12-29T13:24:47.848084-06:00","close_reason":"Added optional sync?: SyncMetadata field to BaseNote interface in note-types.ts. TypeScript compiles, all variants inherit field.","dependencies":[{"issue_id":"scribe-hao.7","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:18.122717-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.7","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:01.920406-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.7","depends_on_id":"scribe-hao.5","type":"blocks","created_at":"2025-12-27T22:03:28.261477-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.8","title":"[Phase 1.4] Extend EngineName and ErrorCode for sync","description":"# [Phase 1.4] Extend EngineName and ErrorCode for sync\n\n## Problem Statement\nAdd sync to the engine name union and add sync-specific error codes. This enables proper error handling and logging for sync operations.\n\n## Current Definitions (from errors.ts)\n```typescript\nexport type EngineName = 'graph' | 'search' | 'storage' | 'metadata';\n\nexport enum ErrorCode {\n  // ... existing codes ...\n  SYNC_CONFLICT = 'SYNC_CONFLICT',\n  SYNC_FAILED = 'SYNC_FAILED',\n  // (These already exist but need expansion)\n}\n```\n\n## Target Definitions\n\n### 1. Extend EngineName\n```typescript\nexport type EngineName = 'graph' | 'search' | 'storage' | 'metadata' | 'sync';\n```\n\n### 2. Add Sync Error Codes\n```typescript\nexport enum ErrorCode {\n  // ... existing codes ...\n  \n  // Sync-specific error codes\n  /** Network error during sync (timeout, connection refused, etc.) */\n  SYNC_NETWORK_ERROR = 'SYNC_NETWORK_ERROR',\n  /** Authentication failed (invalid API key, expired token) */\n  SYNC_AUTH_FAILED = 'SYNC_AUTH_FAILED',\n  /** Version mismatch detected (conflict) */\n  SYNC_VERSION_MISMATCH = 'SYNC_VERSION_MISMATCH',\n  /** Rate limit exceeded */\n  SYNC_RATE_LIMITED = 'SYNC_RATE_LIMITED',\n  /** Sync is disabled for this vault */\n  SYNC_DISABLED = 'SYNC_DISABLED',\n  /** Invalid note received from server */\n  SYNC_INVALID_NOTE = 'SYNC_INVALID_NOTE',\n  /** Server error (5xx response) */\n  SYNC_SERVER_ERROR = 'SYNC_SERVER_ERROR',\n  /** Device ID conflict */\n  SYNC_DEVICE_CONFLICT = 'SYNC_DEVICE_CONFLICT',\n}\n```\n\n### 3. Add SyncError class\n```typescript\n/**\n * Error class for sync-related operations.\n * Includes noteId for context on per-note errors.\n */\nexport class SyncError extends ScribeError {\n  constructor(\n    code: ErrorCode,\n    message: string,\n    public readonly noteId?: string,\n    cause?: Error\n  ) {\n    super(code, message, cause);\n    this.name = 'SyncError';\n  }\n}\n\n/**\n * Type guard to check if an error is a SyncError\n */\nexport function isSyncError(error: unknown): error is SyncError {\n  return error instanceof SyncError;\n}\n```\n\n### 4. Add User Messages\n```typescript\n// In ScribeError.getUserMessage()\ncase ErrorCode.SYNC_NETWORK_ERROR:\n  return 'Unable to connect to sync server. Please check your internet connection.';\ncase ErrorCode.SYNC_AUTH_FAILED:\n  return 'Sync authentication failed. Please sign in again.';\ncase ErrorCode.SYNC_VERSION_MISMATCH:\n  return 'This note was modified on another device. Please resolve the conflict.';\ncase ErrorCode.SYNC_RATE_LIMITED:\n  return 'Sync rate limit exceeded. Please wait a moment and try again.';\ncase ErrorCode.SYNC_DISABLED:\n  return 'Sync is not enabled for this vault.';\ncase ErrorCode.SYNC_INVALID_NOTE:\n  return 'Received invalid data from sync server.';\ncase ErrorCode.SYNC_SERVER_ERROR:\n  return 'Sync server error. Please try again later.';\ncase ErrorCode.SYNC_DEVICE_CONFLICT:\n  return 'Device conflict detected. Please re-authorize this device.';\n```\n\n## Files to Modify\n- `packages/shared/src/errors.ts`\n\n## Dependencies\n- scribe-hao.6 (Define sync types)\n\n## UNBLOCKS\n- scribe-hao.12 (SyncTransport - needs error codes)\n- scribe-hao.14 (ConflictResolver - needs error codes)\n- scribe-hao.16 (SyncEngine - needs SyncError class)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:18.306445-06:00","updated_at":"2025-12-29T13:24:48.012509-06:00","closed_at":"2025-12-29T13:24:48.012509-06:00","close_reason":"Extended EngineName with sync, added 8 sync error codes, SyncError class, isSyncError type guard, and user-friendly messages.","dependencies":[{"issue_id":"scribe-hao.8","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:18.306805-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.8","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:02.110002-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.8","depends_on_id":"scribe-hao.5","type":"blocks","created_at":"2025-12-27T22:03:28.45082-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-hao.9","title":"[Phase 1.5] Implement content hash computation","description":"# [Phase 1.5] Implement content hash computation\n\n## Problem Statement\nImplement SHA-256 content hashing for conflict detection. The hash includes only user-editable fields that would cause conflicts, not derived metadata.\n\n## Why Content Hash\n- **Fast duplicate detection**: Server can skip processing if hash matches\n- **Conflict detection**: Different hash = different content = potential conflict\n- **Bandwidth optimization**: Don't sync unchanged notes\n\n## Hash Specification (from GH Issue #54)\n\n### Fields INCLUDED in hash\n- `title` - User-editable title\n- `tags` - User-defined tags array\n- `content` - Full EditorContent (Lexical JSON)\n- `type` - Note type discriminator\n- `daily` - For DailyNote variant\n- `meeting` - For MeetingNote variant\n\n### Fields EXCLUDED from hash\n- `id` - Identifier, not content\n- `createdAt` / `updatedAt` - Timestamps\n- `metadata` - Derived from content by engine\n- `sync` - Sync-specific metadata\n\n## Implementation\n\n```typescript\n// packages/engine-sync/src/content-hash.ts\n\nimport { createHash } from 'node:crypto';\nimport type { Note, DailyNote, MeetingNote } from '@scribe/shared';\n\n/** Hash length in hex characters (truncated from 64) */\nconst HASH_LENGTH = 16;\n\n/**\n * Compute content hash for conflict detection.\n * \n * The hash includes only user-editable content fields:\n * - title, tags, content (always)\n * - type (for discriminated union)\n * - daily/meeting (for type-specific variants)\n * \n * Excludes: id, timestamps, metadata (derived), sync (sync-specific)\n * \n * @param note The note to hash\n * @returns 16-character hex hash string\n */\nexport function computeContentHash(note: Note): string {\n  // Build hash input with only conflict-relevant fields\n  const hashInput: Record\u003cstring, unknown\u003e = {\n    title: note.title,\n    tags: note.tags,\n    content: note.content,\n  };\n  \n  // Include type discriminator if present\n  if (note.type) {\n    hashInput.type = note.type;\n  }\n  \n  // Include type-specific data\n  if (isDailyNote(note)) {\n    hashInput.daily = note.daily;\n  }\n  if (isMeetingNote(note)) {\n    hashInput.meeting = note.meeting;\n  }\n  \n  // Serialize and hash\n  const serialized = JSON.stringify(hashInput, Object.keys(hashInput).sort());\n  const hash = createHash('sha256').update(serialized).digest('hex');\n  \n  // Truncate to 16 characters (64 bits of collision resistance)\n  return hash.slice(0, HASH_LENGTH);\n}\n\n// Type guards (could import from @scribe/shared)\nfunction isDailyNote(note: Note): note is DailyNote {\n  return note.type === 'daily';\n}\n\nfunction isMeetingNote(note: Note): note is MeetingNote {\n  return note.type === 'meeting';\n}\n```\n\n## Why Truncate to 16 Characters\n- 16 hex chars = 64 bits = ~10^19 possible values\n- Birthday paradox: collision probability \u003c 0.1% with 1 billion notes\n- Shorter hashes are easier to log and debug\n- Full 64-char hash provides no practical benefit for this use case\n\n## Determinism Considerations\n- **Key sorting**: `Object.keys().sort()` ensures consistent key order\n- **JSON.stringify**: Deterministic for the same input structure\n- **No floating point**: Timestamps excluded, no precision issues\n\n## Test Cases\n```typescript\ndescribe('computeContentHash', () =\u003e {\n  it('returns same hash for same content', () =\u003e {\n    const note = createTestNote({ title: 'Test', tags: ['a', 'b'] });\n    expect(computeContentHash(note)).toBe(computeContentHash(note));\n  });\n  \n  it('returns different hash for different title', () =\u003e {\n    const note1 = createTestNote({ title: 'A' });\n    const note2 = createTestNote({ title: 'B' });\n    expect(computeContentHash(note1)).not.toBe(computeContentHash(note2));\n  });\n  \n  it('ignores updatedAt timestamp changes', () =\u003e {\n    const note1 = createTestNote({ updatedAt: 1000 });\n    const note2 = { ...note1, updatedAt: 2000 };\n    expect(computeContentHash(note1)).toBe(computeContentHash(note2));\n  });\n  \n  it('ignores sync metadata changes', () =\u003e {\n    const note1 = createTestNote({});\n    const note2 = { ...note1, sync: { version: 5, contentHash: 'x' } };\n    expect(computeContentHash(note1)).toBe(computeContentHash(note2));\n  });\n  \n  it('includes daily data for DailyNote', () =\u003e {\n    const note1 = createDailyNote({ date: '2024-01-15' });\n    const note2 = createDailyNote({ date: '2024-01-16' });\n    expect(computeContentHash(note1)).not.toBe(computeContentHash(note2));\n  });\n});\n```\n\n## Files to Create\n- `packages/engine-sync/src/content-hash.ts`\n- `packages/engine-sync/src/content-hash.test.ts`\n\n## Dependencies\n- scribe-hao.5 (Create engine-sync package)\n- scribe-hao.7 (SyncMetadata on BaseNote)\n\n## UNBLOCKS\n- scribe-hao.10 (SyncDatabase - stores content hash)\n- scribe-hao.16 (SyncEngine - uses content hash)","status":"closed","priority":1,"issue_type":"task","created_at":"2025-12-27T21:28:18.491422-06:00","updated_at":"2025-12-29T13:24:48.177951-06:00","closed_at":"2025-12-29T13:24:48.177951-06:00","close_reason":"Implemented computeContentHash, hasContentChanged, matchesHash with 22 passing tests. SHA-256 truncated to 16 chars, deterministic serialization.","dependencies":[{"issue_id":"scribe-hao.9","depends_on_id":"scribe-hao","type":"parent-child","created_at":"2025-12-27T21:28:18.491774-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.9","depends_on_id":"scribe-hao.4","type":"blocks","created_at":"2025-12-27T22:03:02.298554-06:00","created_by":"daemon","metadata":"{}"},{"issue_id":"scribe-hao.9","depends_on_id":"scribe-hao.6","type":"blocks","created_at":"2025-12-27T22:03:28.645103-06:00","created_by":"daemon","metadata":"{}"}]}
{"id":"scribe-lg3","title":"Remove dead TableKeyboardPlugin.tsx from plugins/ directory","description":"The old 516-line TableKeyboardPlugin.tsx in plugins/ directory is dead code. The refactored version lives in plugins/table/ and is already being used by EditorRoot.tsx. Safe to delete the old file.","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T14:11:12.453197-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d","title":"Tech Debt Remediation: GH Issue #52 - Comprehensive Cleanup","description":"# Tech Debt Remediation Epic (GitHub Issue #52)\n\n## Executive Summary\n\nThis epic captures the comprehensive tech debt analysis from GitHub Issue #52. The work is organized into 5 sprints with clear dependency chains, enabling maximum parallelization while respecting logical ordering constraints.\n\n---\n\n## 🔄 REVISION LOG (Dec 25, 2025)\n\n### Changes After Plan Review\n1. **scribe-p2d.8 UPDATED**: NoteHeader uses date-fns PARSING, not just formatting - more complex task\n2. **scribe-p2d.14 DOWNGRADED to P3**: Test utility refactoring has poor effort/value ratio\n3. **scribe-p2d.16 DOWNGRADED to P3**: Type-only file, GH issue says \"keep as-is\" for similar files  \n4. **scribe-p2d.17 CLOSED**: metadata.title isn't deprecated - was a misread of GH issue comments\n\n### Active Task Count\n- **P1 (Critical)**: 12 tasks (was 13, .17 closed)\n- **P2 (Medium)**: 2 tasks (was 4, .14 and .16 downgraded)\n- **P3 (Low)**: 4 tasks (was 2, .14 and .16 added)\n\n---\n\n## ⚠️ IMPORTANT: Pre-Implementation Notes\n\n### For Test Tasks (scribe-p2d.1 through .5)\n**Before writing new tests, check existing coverage!**\n\nA 1896-line `content-extractor.test.ts` exists and may test these modules indirectly. Run:\n```bash\nbun test packages/shared --coverage | grep -E 'block-converters|inline-converters|markdown-escaper|content|frontmatter'\n```\n\nFocus on **gap-filling** rather than duplicating existing tests.\n\n### For Date Deduplication (scribe-p2d.6 through .8)\n**Complete scribe-p2d.9 FIRST** - it verifies the shared date-utils API covers all consumer needs.\n\n**⚠️ scribe-p2d.8 is more complex than .6/.7** - NoteHeader uses date-fns parsing, not just formatting!\n\n### Closed/Merged Beads\n- **scribe-p2d.13**: CLOSED - storage.ts already uses structured logger\n- **scribe-p2d.17**: CLOSED - metadata.title isn't actually deprecated\n- **scribe-p2d.20, .21**: MERGED into scribe-p2d.19 (combined JSDoc task)\n\n---\n\n## Strategic Context\n\n### Why This Matters\n\nScribe is a note-taking application built on Electron + React with a Lexical editor. The codebase has grown to include:\n- **@scribe/shared**: Core types, utilities, content conversion (the \"crown jewels\")\n- **@scribe/engine-core**: Note indexing, task management, graph relationships\n- **@scribe/storage-fs**: File system vault operations, migrations\n- **@scribe/design-system**: UI primitives and theming\n- **apps/desktop**: Electron desktop application\n- **apps/cli**: Command-line interface for power users\n\nThe tech debt identified threatens:\n1. **Data Integrity**: Untested content conversion modules handle user notes\n2. **Maintainability**: Duplicate code across 4+ locations for date formatting\n3. **Debuggability**: Production code using console.* instead of structured logger\n\n### Risk Assessment\n\n| Category | Risk Level | Impact |\n|----------|------------|--------|\n| Missing test coverage on content modules | **CRITICAL** | Data corruption during export |\n| Duplicate date formatting | MEDIUM | Inconsistent UX, maintenance burden |\n| Console usage in prod | MEDIUM | Logs lost, no log levels |\n| Large files | LOW | Developer friction only |\n\n## Dependency Graph Overview (UPDATED)\n\n```\nSPRINT 1 (Wave 1 - Start Here):\n├── scribe-p2d.9: Verify date-utils exports (DO THIS FIRST)\n│   └── Blocks: .6, .7, .8\n│\n├── Test Coverage Tasks (5 parallel tasks)\n│   ├── .1: block-converters.ts tests\n│   ├── .2: inline-converters.ts tests  \n│   ├── .3: markdown-escaper.ts tests\n│   ├── .4: content.ts tests\n│   └── .5: frontmatter.ts tests\n│\n└── Date Deduplication Tasks (after .9 completes)\n    ├── .6: Remove from CLI output.ts (simple)\n    ├── .7: Remove from CLI daily.ts (simple)\n    └── .8: Remove from NoteHeader.tsx (COMPLEX - has parsing)\n\nSPRINT 2 (Wave 2 - Logger Migration):\n├── .10: useVaultPath.ts → structured logger\n├── .11: auto-updater.ts → structured logger\n└── .12: search-engine.ts → structured logger\n\nSPRINT 3 (Wave 3 - Refactoring):\n└── .15: Extract validation/locking from storage.ts\n    (Note: .14 and .16 are now P3 - defer)\n\nSPRINT 4 (Wave 4 - Deprecated Code):\n└── .18: Remove deprecated TaskIndex constructor\n    (Note: .17 CLOSED - not actually deprecated)\n\nSPRINT 5 (Wave 5 - Documentation):\n├── .19: JSDoc for block/inline/frontmatter (MERGED)\n└── .22: Document swallowed promises\n```\n\n## Success Metrics\n\n- [ ] All 5 content modules have \u003e80% test coverage\n- [ ] Zero duplicate date formatting functions\n- [ ] Console usage reduced by 50%+ in production code\n- [ ] Deprecated TaskIndex constructor removed\n\n## Sprint Allocation (Updated)\n\n| Sprint | Focus | Active Tasks | Notes |\n|--------|-------|--------------|-------|\n| 1 | Critical Tests + Dedup | 9 tasks | Start with .9 |\n| 2 | Logger Migration | 3 tasks | .13 was already closed |\n| 3 | Refactoring | 1 task | .14, .16 deferred to P3 |\n| 4 | Deprecated | 1 task | .17 closed |\n| 5 | Documentation | 2 tasks | .19 is merged |\n\n## Labels\n\n- tech-debt\n- maintenance  \n- testing\n- refactoring\n- GH-52","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-25T22:18:32.38643-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"epic"}
{"id":"scribe-p2d.1","title":"[Sprint 1.1] Add comprehensive tests for block-converters.ts","description":"# Add Comprehensive Tests for block-converters.ts\n\n## File Under Test\n`packages/shared/src/block-converters.ts` (357 lines)\n\n## Strategic Context\n\n### Why This is Critical (P1)\nThis module performs **AST transformations** for markdown export - converting Lexical editor nodes to Markdown format. If this code has bugs:\n- User notes could be **corrupted** during export\n- Data could be **lost** or malformed when sharing notes\n- Users lose trust in the application's data integrity\n\n### What This Module Does\nBlock-level node conversion handles:\n- **Headings**: `# H1`, `## H2`, etc. (up to H6)\n- **Paragraphs**: Plain text with inline formatting\n- **Lists**: Ordered (`1.`), unordered (`-`), and checklists (`- [ ]`)\n- **Code blocks**: Fenced code with language hints\n- **Tables**: Complex multi-row, multi-column structures\n- **Blockquotes**: `\u003e ` prefixed content\n- **Horizontal rules**: `---`\n\n### Current State\n- **Lines of code**: 357\n- **Test coverage**: 0% direct tests (but see verification step)\n- **Complexity**: HIGH (recursive AST traversal, context-sensitive output)\n\n---\n\n## IMPORTANT: Pre-Implementation Verification\n\n**Before writing new tests, check existing coverage!**\n\nThere's a 62KB `content-extractor.test.ts` that may already test block-converters indirectly.\n\n```bash\n# Check if block-converters is tested via integration\ngrep -l \"block-converter\\|headingToMarkdown\\|listToMarkdown\" packages/shared/src/*.test.ts\n\n# Check current coverage\nbun test packages/shared --coverage | grep block-converters\n\n# Review content-extractor tests for overlap\ngrep -n \"heading\\|list\\|table\\|code\" packages/shared/src/content-extractor.test.ts | head -30\n```\n\nIf significant coverage already exists, focus on **gap-filling** rather than duplicating tests.\n\n---\n\n## Implementation Plan\n\n### Test Categories\n\n#### 1. Heading Conversion Tests\n```typescript\ndescribe('headingToMarkdown', () =\u003e {\n  it('converts h1 to single #', () =\u003e {});\n  it('converts h2-h6 with correct # count', () =\u003e {});\n  it('preserves inline formatting in headings', () =\u003e {});\n  it('handles empty heading content', () =\u003e {});\n});\n```\n\n#### 2. Paragraph Conversion Tests\n```typescript\ndescribe('paragraphToMarkdown', () =\u003e {\n  it('converts plain text paragraphs', () =\u003e {});\n  it('preserves bold/italic inline formatting', () =\u003e {});\n  it('handles mixed inline styles', () =\u003e {});\n  it('escapes special markdown characters', () =\u003e {});\n});\n```\n\n#### 3. List Conversion Tests\n```typescript\ndescribe('listToMarkdown', () =\u003e {\n  describe('unordered lists', () =\u003e {\n    it('converts single-item list', () =\u003e {});\n    it('converts multi-item list', () =\u003e {});\n    it('handles nested lists (2 levels)', () =\u003e {});\n    it('handles deeply nested lists (3+ levels)', () =\u003e {});\n  });\n  \n  describe('ordered lists', () =\u003e {\n    it('numbers items sequentially', () =\u003e {});\n    it('handles nested ordered lists', () =\u003e {});\n    it('handles mixed ordered/unordered nesting', () =\u003e {});\n  });\n  \n  describe('checklists', () =\u003e {\n    it('renders unchecked as [ ]', () =\u003e {});\n    it('renders checked as [x]', () =\u003e {});\n    it('preserves checklist content', () =\u003e {});\n  });\n});\n```\n\n#### 4. Code Block Tests\n```typescript\ndescribe('codeBlockToMarkdown', () =\u003e {\n  it('wraps in triple backticks', () =\u003e {});\n  it('includes language identifier', () =\u003e {});\n  it('preserves code indentation', () =\u003e {});\n  it('handles empty code blocks', () =\u003e {});\n  it('handles special characters in code', () =\u003e {});\n});\n```\n\n#### 5. Table Conversion Tests\n```typescript\ndescribe('tableToMarkdown', () =\u003e {\n  it('converts simple 2x2 table', () =\u003e {});\n  it('handles header row with separator', () =\u003e {});\n  it('escapes pipe characters in cells', () =\u003e {});\n  it('handles empty cells', () =\u003e {});\n  it('aligns multi-column tables', () =\u003e {});\n});\n```\n\n#### 6. Edge Cases\n```typescript\ndescribe('edge cases', () =\u003e {\n  it('handles deeply nested structures', () =\u003e {});\n  it('handles empty block nodes', () =\u003e {});\n  it('handles malformed input gracefully', () =\u003e {});\n  it('maintains paragraph spacing', () =\u003e {});\n});\n```\n\n### Test Data Strategy\n- Create snapshot tests for complex conversions\n- Use property-based testing for escaping logic\n- Test round-trip where possible (markdown → lexical → markdown)\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/block-converters.test.ts` | CREATE |\n| `packages/shared/src/__fixtures__/block-samples.ts` | CREATE (test fixtures) |\n\n## Verification\n\n```bash\n# Run tests\nbun test packages/shared/src/block-converters.test.ts\n\n# Check coverage\nbun test packages/shared --coverage | grep block-converters\n\n# Target: \u003e80% line coverage\n```\n\n## Success Criteria\n- [ ] Pre-implementation coverage check completed\n- [ ] All test categories implemented (or documented as covered elsewhere)\n- [ ] Coverage \u003e80% for block-converters.ts\n- [ ] No snapshot failures\n- [ ] All edge cases documented with tests\n\n## Dependencies\n- **Blocks**: scribe-p2d.19 (JSDoc docs should come after tests)\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Medium (3-4 hours)\n- **Risk**: Low (pure functions, no side effects)\n\n## Labels\n- testing\n- sprint-1\n- P1-critical\n- content-safety","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:19:01.243168-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.10","title":"[Sprint 2.1] Replace console usage in useVaultPath.ts with structured logger","description":"# Replace Console Usage in useVaultPath.ts\n\n## Problem Statement\n`apps/desktop/renderer/src/hooks/useVaultPath.ts` contains 4 instances of `console.*` that should use the structured logger from `@scribe/shared`.\n\n## Why This Matters\n\n### Production Visibility\nConsole logs in production:\n- Are not captured by Electron's crash reporting\n- Have no log levels (can't filter debug vs error)\n- Are lost when the app closes\n- Don't include structured context\n\n### Debugging Difficulty\nWithout structured logging:\n- Can't filter by severity\n- Can't add context (vault path, user action)\n- Can't aggregate across sessions\n\n## Current Console Usage\n\n```typescript\n// apps/desktop/renderer/src/hooks/useVaultPath.ts\nconsole.log('Loading vault path...');           // Line ~X\nconsole.error('Failed to load vault:', err);    // Line ~Y\nconsole.warn('Vault path not found');           // Line ~Z\nconsole.debug('Vault path resolved:', path);    // Line ~W\n```\n\n## Target Implementation\n\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('useVaultPath');\n\n// Replace console.log with log.info or log.debug\nlog.debug('Loading vault path...');\n\n// Replace console.error with log.error (includes stack trace)\nlog.error('Failed to load vault', { error: err.message, stack: err.stack });\n\n// Replace console.warn with log.warn\nlog.warn('Vault path not found', { defaultPath: defaultVaultPath });\n\n// Replace console.debug with log.debug\nlog.debug('Vault path resolved', { path });\n```\n\n## Implementation Plan\n\n### Step 1: Add Logger Import\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('useVaultPath');\n```\n\n### Step 2: Replace Each Console Call\nMap console methods to logger methods:\n| Console | Logger | Notes |\n|---------|--------|-------|\n| `console.log` | `log.info` or `log.debug` | Use debug for verbose |\n| `console.error` | `log.error` | Add error context |\n| `console.warn` | `log.warn` | Add relevant context |\n| `console.debug` | `log.debug` | Already debug level |\n\n### Step 3: Add Structured Context\nDon't just replace text, add structured data:\n```typescript\n// Before\nconsole.error('Failed:', err);\n\n// After\nlog.error('Vault load failed', { \n  error: err.message,\n  vaultPath: attemptedPath,\n  action: 'loadVaultPath'\n});\n```\n\n### Step 4: Test Logging Output\n```bash\n# Set log level to debug\nLOG_LEVEL=debug bun run dev:desktop\n\n# Verify logs appear with correct format\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `apps/desktop/renderer/src/hooks/useVaultPath.ts` | Replace console with logger |\n\n## Verification\n\n```bash\n# Ensure no console usage remains\ngrep -n \"console\\.\" apps/desktop/renderer/src/hooks/useVaultPath.ts\n\n# Should return empty or only eslint-disable comments\n\n# Run tests\nbun test apps/desktop\n```\n\n## Success Criteria\n- [ ] All console calls replaced with structured logger\n- [ ] Logger creates with appropriate namespace\n- [ ] Structured context added to log calls\n- [ ] Tests pass\n- [ ] Log output verified in dev mode\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: None (Sprint 1 tests can run in parallel)\n\n## Estimated Effort\n- **Size**: Small (30-45 minutes)\n- **Risk**: Low\n\n## Labels\n- refactoring\n- sprint-2\n- P1-high\n- logging\n- desktop","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:22:28.477957-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.11","title":"[Sprint 2.2] Replace console usage in auto-updater.ts with structured logger","description":"# Replace Console Usage in auto-updater.ts\n\n## Problem Statement\n`apps/desktop/electron/main/src/auto-updater.ts` contains 4 instances of `console.*` for logging update events. This should use structured logging for better production debugging.\n\n## Why Auto-Updater Logging is Critical\n\n### Update Failures are Invisible\nIf an auto-update fails, users don't know why. With console.log:\n- Logs are lost after app restart\n- No way to diagnose \"update stuck\" issues\n- No telemetry on update success rates\n\n### User Support\nWhen users report \"app won't update\", we need:\n- What version they're on\n- What version was available\n- Where in the update flow it failed\n- What error occurred\n\n## Current Console Usage\n\n```typescript\n// apps/desktop/electron/main/src/auto-updater.ts\nconsole.log('Checking for updates...');\nconsole.log('Update available:', info);\nconsole.error('Update error:', err);\nconsole.log('Download progress:', percent);\n```\n\n## Target Implementation\n\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('auto-updater');\n\nlog.info('Checking for updates', { \n  currentVersion: app.getVersion(),\n  channel: updateChannel \n});\n\nlog.info('Update available', { \n  version: info.version,\n  releaseDate: info.releaseDate,\n  releaseNotes: info.releaseNotes?.slice(0, 100) // truncate for logging\n});\n\nlog.error('Update check failed', { \n  error: err.message,\n  code: err.code,\n  currentVersion: app.getVersion()\n});\n\nlog.debug('Download progress', { \n  percent: percent.toFixed(1),\n  bytesPerSecond: speed,\n  transferred: transferred,\n  total: total\n});\n```\n\n## Implementation Plan\n\n### Step 1: Add Logger Import\nThe main process already has access to @scribe/shared:\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('auto-updater');\n```\n\n### Step 2: Map Update Events to Log Levels\n\n| Event | Level | Rationale |\n|-------|-------|-----------|\n| checking-for-update | info | User-facing milestone |\n| update-available | info | Important event |\n| update-not-available | debug | Normal operation |\n| download-progress | debug | Verbose, frequent |\n| update-downloaded | info | Important milestone |\n| error | error | Always log errors |\n\n### Step 3: Add Structured Context\nInclude version info, timing, and error details in every log.\n\n### Step 4: Consider File Logging\nFor auto-updater specifically, consider persisting logs:\n```typescript\n// Future enhancement: write update logs to file\n// ~/.scribe/logs/updates.log\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `apps/desktop/electron/main/src/auto-updater.ts` | Replace console with logger |\n\n## Verification\n\n```bash\n# Ensure no console usage remains\ngrep -n \"console\\.\" apps/desktop/electron/main/src/auto-updater.ts\n\n# Run the app and trigger update check\nbun run dev:desktop\n# Check for updates manually via menu\n```\n\n## Success Criteria\n- [ ] All console calls replaced with structured logger\n- [ ] Update events logged with appropriate levels\n- [ ] Version context included in all logs\n- [ ] Error logs include full error details\n- [ ] Tests pass\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small (30-45 minutes)\n- **Risk**: Low\n\n## Labels\n- refactoring\n- sprint-2\n- P1-high\n- logging\n- desktop\n- auto-update","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:22:45.781765-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.12","title":"[Sprint 2.3] Complete TODO: Migrate search-engine.ts to structured logger","description":"# Complete TODO: Migrate search-engine.ts to Structured Logger\n\n## Problem Statement\n`packages/engine-search/src/search-engine.ts` has a TODO comment and eslint-disable for console usage that needs to be addressed:\n\n```typescript\n// eslint-disable-next-line no-console -- TODO: Migrate to logger\nconsole.log('Search index rebuilt');\n```\n\n## Context\n\n### Why Search Engine Logging Matters\nThe search engine is a core component that:\n- Indexes all notes for full-text search\n- Rebuilds indexes on vault changes\n- Can be slow on large vaults\n\nStructured logging helps:\n- Track indexing performance\n- Debug search result issues\n- Monitor index health\n\n### Current State\n- 2 instances of console usage\n- Has eslint-disable comments with TODO\n- Acknowledged as tech debt in the codebase\n\n## Target Implementation\n\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('search-engine');\n\n// Replace index rebuild logging\nlog.info('Search index rebuilt', {\n  noteCount: indexedNotes.length,\n  durationMs: endTime - startTime,\n  vaultPath: vault.path\n});\n\n// Replace search logging (if debug-level)\nlog.debug('Search executed', {\n  query: query.slice(0, 50), // truncate for privacy\n  resultCount: results.length,\n  durationMs: searchTime\n});\n```\n\n## Implementation Plan\n\n### Step 1: Add Logger Import\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('search-engine');\n```\n\n### Step 2: Replace Console Calls\nFind and replace each console usage with appropriate log level.\n\n### Step 3: Remove ESLint Disables\nAfter migration, remove the eslint-disable comments.\n\n### Step 4: Add Performance Metrics\nSince search performance matters, include timing:\n```typescript\nconst start = performance.now();\n// ... indexing logic\nconst duration = performance.now() - start;\nlog.info('Index rebuilt', { durationMs: duration.toFixed(2) });\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `packages/engine-search/src/search-engine.ts` | Replace console, remove disables |\n\n## Verification\n\n```bash\n# Ensure no console usage or eslint-disable for it\ngrep -n \"console\\.\\|no-console\" packages/engine-search/src/search-engine.ts\n\n# Run tests\nbun test packages/engine-search\n\n# Run full test suite to catch regressions\nbun test\n```\n\n## Success Criteria\n- [ ] All console calls replaced\n- [ ] ESLint disable comments removed\n- [ ] Performance metrics included\n- [ ] Tests pass\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small (20-30 minutes)\n- **Risk**: Low\n\n## Labels\n- refactoring\n- sprint-2\n- P1-high\n- logging\n- search\n- tech-debt-acknowledged","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:22:59.956157-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.13","title":"[Sprint 2.4] Add structured logging to storage.ts where appropriate","description":"# Add Structured Logging to storage.ts\n\n## Problem Statement\n`packages/storage-fs/src/storage.ts` has 4 instances of console usage for logging file system operations. These should use structured logging for better debugging.\n\n## Context\n\n### Storage Layer Criticality\nThe storage layer handles:\n- Reading/writing note files\n- File locking for concurrent access\n- Migrations between format versions\n- Atomic writes to prevent corruption\n\nFailures here can cause **data loss**. Good logging is essential.\n\n### Current Console Usage\n```typescript\nconsole.log('Writing note:', noteId);\nconsole.error('Write failed:', error);\nconsole.warn('Lock timeout, retrying...');\nconsole.log('Migration complete');\n```\n\n## Target Implementation\n\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('storage-fs');\n\n// File operations\nlog.debug('Writing note', { \n  noteId, \n  path: notePath,\n  sizeBytes: content.length \n});\n\n// Errors with full context\nlog.error('Write failed', { \n  noteId,\n  path: notePath,\n  error: err.message,\n  code: err.code,\n  syscall: err.syscall\n});\n\n// Warnings for retries\nlog.warn('Lock timeout, retrying', { \n  noteId,\n  attempt: attemptNumber,\n  maxAttempts: MAX_RETRIES,\n  waitMs: backoffDelay\n});\n\n// Migrations\nlog.info('Migration complete', {\n  fromVersion: oldVersion,\n  toVersion: newVersion,\n  noteCount: migratedNotes.length,\n  durationMs: migrationTime\n});\n```\n\n## Implementation Plan\n\n### Step 1: Assess Each Console Call\nReview each console usage and determine:\n- Is this actually needed? (some may be debug cruft)\n- What level should it be?\n- What context should be included?\n\n### Step 2: Add Logger\n```typescript\nimport { createLogger } from '@scribe/shared';\n\nconst log = createLogger('storage-fs');\n```\n\n### Step 3: Replace Strategically\n- Keep error logging (critical)\n- Convert verbose logs to debug level\n- Add structured context to all logs\n\n### Step 4: Consider Log Volume\nStorage operations can be frequent. Use debug level for:\n- Individual file reads/writes\n- Lock acquisition/release\n\nUse info level for:\n- Migrations\n- Vault-level operations\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `packages/storage-fs/src/storage.ts` | Replace console with logger |\n\n## Verification\n\n```bash\n# Check for remaining console usage\ngrep -n \"console\\.\" packages/storage-fs/src/storage.ts\n\n# Run storage tests\nbun test packages/storage-fs\n\n# Run integration tests\nbun test apps/desktop\n```\n\n## Success Criteria\n- [ ] Console calls replaced with structured logger\n- [ ] Appropriate log levels used\n- [ ] File operation context included\n- [ ] Tests pass\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small-Medium (45-60 minutes)\n- **Risk**: Low\n\n## Labels\n- refactoring\n- sprint-2\n- P2-medium\n- logging\n- storage","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T22:23:13.515771-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.14","title":"[Sprint 3.1] Split note-factory.ts (786 lines) by note type","description":"# Split note-factory.ts by Note Type\n\n## ⚠️ PRIORITY DOWNGRADED TO P3\n\nThis is **test utility code** - splitting it provides minimal user-facing value. The 786-line file is complex but:\n- Tests work fine\n- Developers rarely touch this file\n- Effort/reward ratio is poor\n\nConsider deferring indefinitely unless the file becomes a maintenance burden.\n\n---\n\n## Original Problem Statement\n`packages/test-utils/src/note-factory.ts` is 786 lines - the largest file in the codebase. It contains test factories for all note types.\n\n## Why This is P3 (Low Priority)\n\n1. **It's test code** - doesn't affect users\n2. **It works** - no bugs or issues reported\n3. **Low change frequency** - rarely modified\n4. **Time better spent elsewhere** - P1/P2 tasks have higher impact\n\n## If/When Implemented\n\n### Proposed Structure\n```\npackages/test-utils/src/note-factory/\n├── index.ts           # Re-exports\n├── base-factory.ts    # Shared infrastructure\n├── daily-factory.ts   # Daily note specific\n├── meeting-factory.ts # Meeting note specific\n├── person-factory.ts  # Person note specific\n└── generic-factory.ts # createTestNote, createMockNote\n```\n\n## Success Criteria (if done)\n- [ ] Each file \u003c200 lines\n- [ ] All tests pass\n- [ ] No import changes needed\n\n## Estimated Effort\n- **Size**: Medium-Large (3-4 hours)\n- **Risk**: Medium (many tests depend on this)","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T22:23:50.214584-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.15","title":"[Sprint 3.2] Extract validation/locking/migration from storage.ts (646 lines)","description":"# Extract Validation/Locking/Migration from storage.ts\n\n## Problem Statement\n`packages/storage-fs/src/storage.ts` is 646 lines with multiple distinct responsibilities that should be separated for maintainability.\n\n## Current Responsibilities\n\n### 1. Note Validation (~100 lines)\n- Validating note structure before save\n- Checking required fields\n- Type validation\n\n### 2. File Locking (~80 lines)\n- Preventing concurrent writes\n- Lock acquisition/release\n- Timeout handling\n\n### 3. Format Migration (~120 lines)\n- Upgrading note format versions\n- Handling legacy formats\n- Migration error handling\n\n### 4. Core Storage (~350 lines)\n- Read/write operations\n- Directory management\n- Path resolution\n\n## Proposed Structure\n\n```\npackages/storage-fs/src/\n├── storage.ts           # Core storage (reduced to ~350 lines)\n├── note-validator.ts    # Validation logic (already exists, enhance)\n├── file-locker.ts       # File locking abstraction\n└── note-migrator.ts     # Migration logic (already exists, enhance)\n```\n\n## Implementation Plan\n\n### Step 1: Audit Existing Extractors\nCheck what's already extracted:\n- `note-validator.ts` - exists, may need more logic moved in\n- `note-migrator.ts` - exists, may need more logic moved in\n- File locking - probably still inline\n\n### Step 2: Extract File Locking\nCreate `file-locker.ts`:\n```typescript\nexport interface FileLock {\n  release(): Promise\u003cvoid\u003e;\n}\n\nexport interface FileLocker {\n  acquireLock(path: string, timeout?: number): Promise\u003cFileLock\u003e;\n  isLocked(path: string): boolean;\n}\n\nexport function createFileLocker(): FileLocker {\n  // Implementation\n}\n```\n\n### Step 3: Move Inline Validation to Validator\nIf there's validation logic in storage.ts, move it to note-validator.ts.\n\n### Step 4: Consolidate Migration Logic\nIf there's migration logic in storage.ts, move it to note-migrator.ts.\n\n### Step 5: Update Storage Imports\n```typescript\n// storage.ts\nimport { NoteValidator } from './note-validator';\nimport { createFileLocker } from './file-locker';\nimport { NoteMigrator } from './note-migrator';\n```\n\n### Step 6: Run Tests\n```bash\nbun test packages/storage-fs\nbun test apps/desktop\n```\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/storage-fs/src/file-locker.ts` | CREATE |\n| `packages/storage-fs/src/storage.ts` | REDUCE (extract logic) |\n| `packages/storage-fs/src/note-validator.ts` | ENHANCE |\n| `packages/storage-fs/src/note-migrator.ts` | ENHANCE |\n| `packages/storage-fs/src/index.ts` | UPDATE exports |\n\n## Verification\n\n```bash\n# All storage tests pass\nbun test packages/storage-fs\n\n# Integration tests pass\nbun test apps/desktop\n\n# Check file sizes\nwc -l packages/storage-fs/src/storage.ts\n# Should be \u003c 400 lines\n```\n\n## Success Criteria\n- [ ] storage.ts reduced to \u003c400 lines\n- [ ] File locking extracted to separate module\n- [ ] All tests pass\n- [ ] No breaking API changes\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: Sprint 2.4 (logger migration should happen first)\n\n## Estimated Effort\n- **Size**: Medium (2-3 hours)\n- **Risk**: Medium (storage is critical path)\n\n## Labels\n- refactoring\n- sprint-3\n- P2-medium\n- storage","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T22:24:07.083306-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.16","title":"[Sprint 3.3] Split ipc-contract.ts (645 lines) by namespace","description":"# Split ipc-contract.ts by Namespace\n\n## ⚠️ PRIORITY DOWNGRADED TO P3\n\nThis file contains **type definitions only** - no runtime code. The original GitHub issue #52 explicitly says:\n\n\u003e `packages/shared/src/types/note-types.ts` (639 lines) - **Keep as-is (type definitions)**\n\nThe same logic applies here. Type-only files can be large without maintenance burden because:\n- TypeScript provides excellent navigation (go to definition)\n- No runtime complexity to debug\n- Namespaces already provide logical grouping\n\nConsider deferring indefinitely unless developers report navigation issues.\n\n---\n\n## Original Problem Statement\n`packages/shared/src/ipc-contract.ts` is 645 lines containing the entire IPC contract.\n\n## Why This is P3 (Low Priority)\n\n1. **Types only** - no runtime code to debug\n2. **Namespaces work** - already logically organized\n3. **IDE navigation** - TypeScript handles this well\n4. **GH issue says keep as-is** - for similar 639-line type file\n\n## If/When Implemented\n\n### Proposed Structure\n```\npackages/shared/src/ipc/\n├── index.ts              # Re-exports\n├── types.ts              # Shared IPC types\n├── notes-contract.ts     # Notes namespace\n├── tasks-contract.ts     # Tasks namespace\n├── search-contract.ts    # Search namespace\n├── vault-contract.ts     # Vault namespace\n├── app-contract.ts       # App namespace\n└── graph-contract.ts     # Graph namespace\n```\n\n## Estimated Effort\n- **Size**: Medium (2-3 hours)\n- **Risk**: Low (types only)","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T22:24:25.941421-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.17","title":"[Sprint 4.1] Document metadata.title migration path","description":"# Document metadata.title Migration Path\n\n## Problem Statement\nThe `metadata.title` field in notes is deprecated but still referenced in 5 files. Before removing it, we need a documented migration path.\n\n## Context\n\n### What Changed\nOriginally, notes had:\n```typescript\ninterface NoteMetadata {\n  title: string;  // DEPRECATED\n  // ... other fields\n}\n```\n\nNow, titles are derived from:\n1. First heading in content\n2. Filename fallback\n3. Note type default (\"Untitled Daily\", \"Untitled Meeting\")\n\n### Why This Matters\n- Existing notes may have `metadata.title` set\n- Migrations need to handle legacy format\n- Users upgrading from old versions need data preserved\n\n## Current References\n\n| File | Line | Usage |\n|------|------|-------|\n| `packages/shared/src/types/note-types.ts` | ~45 | Type definition with @deprecated |\n| `packages/storage-fs/src/note-migrator.ts` | ~32 | Migration reads old title |\n| `apps/desktop/renderer/src/hooks/useNoteTitle.ts` | ~15 | Fallback to metadata.title |\n| `apps/desktop/test-helpers.ts` | ~89 | Test factories set title |\n| `packages/test-utils/src/note-factory.ts` | ~156 | Test factories set title |\n\n## Documentation to Create\n\n### 1. Migration Strategy Document\nCreate `docs/migrations/metadata-title-deprecation.md`:\n\n```markdown\n# Metadata Title Deprecation\n\n## Background\nNotes originally stored titles in `metadata.title`. This was redundant \nbecause titles are extractable from note content.\n\n## Migration Path\n\n### Phase 1: Dual Read (Current)\n- New code reads title from content first heading\n- Falls back to `metadata.title` for legacy notes\n- Migration code preserves both during format upgrades\n\n### Phase 2: Write Removal (Next Minor Version)\n- Stop writing `metadata.title` on save\n- Continue reading for backwards compatibility\n- Update note-factory test helpers\n\n### Phase 3: Full Removal (Next Major Version)\n- Remove `metadata.title` from type definitions\n- Remove fallback read logic\n- Migration script to clean old notes\n\n## Timeline\n- Phase 1: v1.x (current)\n- Phase 2: v1.x+1\n- Phase 3: v2.0\n\n## Testing\nEach phase requires:\n- Unit tests for migration logic\n- Integration tests with legacy note fixtures\n- Manual testing with real user vaults\n```\n\n### 2. Type Definition Update\nAdd deprecation notice with removal timeline:\n```typescript\ninterface NoteMetadata {\n  /**\n   * @deprecated Since v1.x. Titles are now derived from content.\n   * Will be removed in v2.0. See docs/migrations/metadata-title-deprecation.md\n   */\n  title?: string;\n}\n```\n\n## Implementation Plan\n\n### Step 1: Create Migration Document\nWrite the full migration strategy document.\n\n### Step 2: Update Type Definition\nAdd explicit removal timeline to @deprecated JSDoc.\n\n### Step 3: Add Code Comments\nIn each referencing file, add comment explaining deprecation:\n```typescript\n// DEPRECATED: metadata.title fallback - remove in v2.0\n// See docs/migrations/metadata-title-deprecation.md\nif (!title \u0026\u0026 metadata.title) {\n  title = metadata.title;\n}\n```\n\n### Step 4: Create Tracking Issue\nOpen a GitHub issue for v2.0 to track actual removal.\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `docs/migrations/metadata-title-deprecation.md` | CREATE |\n| `packages/shared/src/types/note-types.ts` | UPDATE deprecation notice |\n| Various files | ADD explanatory comments |\n\n## Verification\n\n```bash\n# Ensure document is well-formed\ncat docs/migrations/metadata-title-deprecation.md\n\n# Ensure deprecation notices are in place\ngrep -rn \"@deprecated.*title\" packages/shared/src/types/\n```\n\n## Success Criteria\n- [ ] Migration document created\n- [ ] Type definition has removal timeline\n- [ ] All references have explanatory comments\n- [ ] Future removal tracked\n\n## Dependencies\n- **Blocks**: scribe-p2d.18 (actual removal)\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small (1 hour)\n- **Risk**: Low (documentation only)\n\n## Labels\n- documentation\n- sprint-4\n- P2-medium\n- deprecated\n- migration","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T22:24:53.235453-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.18","title":"[Sprint 4.2] Remove deprecated TaskIndex constructor","description":"# Remove Deprecated TaskIndex Constructor\n\n## Problem Statement\n`packages/engine-core/src/task-index.ts` (line 140) has a deprecated constructor that creates TaskIndex without TaskPersistence. This should be removed.\n\n## Context\n\n### What Changed\nThe TaskIndex was updated to require TaskPersistence for proper task state saving:\n\n```typescript\n// OLD (deprecated)\nconstructor(vault: IVault) {\n  // No persistence - tasks lost on restart\n}\n\n// NEW (current)\nconstructor(vault: IVault, persistence: TaskPersistence) {\n  // Tasks properly persisted\n}\n```\n\n### Why This Matters\n- Using the old constructor means tasks aren't persisted\n- Any code using old constructor has a bug\n- Keeping deprecated code increases maintenance burden\n\n## Current Usage\n\nSearch for usages of the deprecated constructor:\n```bash\ngrep -rn \"new TaskIndex(\" --include=\"*.ts\" | grep -v persistence\n```\n\n## Implementation Plan\n\n### Step 1: Find All Usages\n```bash\ngrep -rn \"new TaskIndex\" apps/ packages/\n```\n\n### Step 2: Update Test Usages\nTests may use the simpler constructor. Update to use mock persistence:\n```typescript\n// Before\nconst taskIndex = new TaskIndex(vault);\n\n// After\nconst mockPersistence = createMockTaskPersistence();\nconst taskIndex = new TaskIndex(vault, mockPersistence);\n```\n\n### Step 3: Update Production Usages\nAny production code using old constructor is buggy. Fix by providing persistence.\n\n### Step 4: Remove Deprecated Constructor\nDelete the deprecated constructor and update type definition.\n\n### Step 5: Run Tests\n```bash\nbun test packages/engine-core\nbun test apps/desktop\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `packages/engine-core/src/task-index.ts` | Remove deprecated constructor |\n| Test files | Update to use persistence |\n| Any production files | Update to use persistence |\n\n## Verification\n\n```bash\nbun test packages/engine-core\nbun test\nbun run typecheck\n```\n\n## Success Criteria\n- [ ] Deprecated constructor removed\n- [ ] All usages updated to use persistence\n- [ ] Tests pass\n- [ ] Type checking passes\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: None (independent of metadata.title deprecation)\n\n## Estimated Effort\n- **Size**: Small-Medium (1-2 hours)\n- **Risk**: Medium (may have hidden usages)\n\n## Labels\n- refactoring\n- sprint-4\n- P2-medium\n- deprecated\n- breaking-change","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-25T22:25:09.848611-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.19","title":"[Sprint 5.1] Add JSDoc documentation for block-converters.ts","description":"# Add JSDoc Documentation for Content Conversion Modules\n\n## Problem Statement\nThree critical content conversion modules lack sufficient JSDoc documentation:\n- `packages/shared/src/block-converters.ts` (357 lines) - AST transformations\n- `packages/shared/src/inline-converters.ts` (305 lines) - inline formatting\n- `packages/shared/src/frontmatter.ts` (99 lines) - YAML generation\n\n## Why Documentation Matters\n\n### Knowledge Transfer\n- New developers can't understand the conversion logic\n- Complex edge cases are undocumented\n- No explanation of why certain patterns exist\n\n### Maintenance Risk\n- Without docs, refactoring is risky\n- Bug fixes may break undocumented behavior\n- Code reviews can't verify correctness\n\n---\n\n## Part 1: block-converters.ts\n\n### Module Overview\n```typescript\n/**\n * @module block-converters\n * \n * Converts Lexical editor block nodes to Markdown format.\n * \n * ## Supported Block Types\n * - Headings (h1-h6) → # to ######\n * - Paragraphs → plain text with inline formatting\n * - Lists (ordered, unordered, checklist) → - * 1. [ ]\n * - Code blocks → fenced with language\n * - Tables → GitHub-flavored markdown tables\n * - Blockquotes → \u003e prefixed\n * - Horizontal rules → ---\n * \n * @see {@link inline-converters} for inline content handling\n * @see {@link markdown-escaper} for character escaping\n */\n```\n\n### Key Functions to Document\n- `headingToMarkdown` - heading conversion with level\n- `paragraphToMarkdown` - text with inline formatting\n- `listToMarkdown` - recursive list handling\n- `tableToMarkdown` - complex table structure\n- `codeBlockToMarkdown` - fenced code with language\n\n---\n\n## Part 2: inline-converters.ts\n\n### Module Overview\n```typescript\n/**\n * @module inline-converters\n * \n * Converts Lexical inline nodes to Markdown format.\n * \n * ## Format Combination Rules\n * - Bold + Italic = ***text***\n * - Code takes precedence (no nesting)\n * - Strikethrough wraps outer: ~~**text**~~\n * \n * ## Link Types\n * - External: [text](url)\n * - Internal: [[note-name]] or [[note|display]]\n * - Mentions: @PersonName\n */\n```\n\n### Format Priority Matrix\nDocument the nesting order (outer to inner):\n1. Strikethrough (~~)\n2. Bold (**)\n3. Italic (*)\n4. Underline (\u003cu\u003e)\n5. Code (`) - cannot contain other formats\n\n---\n\n## Part 3: frontmatter.ts\n\n### Module Overview\n```typescript\n/**\n * @module frontmatter\n * \n * Generates YAML frontmatter for Markdown export.\n * \n * ## Compatibility\n * Output is compatible with: Obsidian, Hugo, Jekyll, Astro\n * \n * ## Escaping Rules\n * Values are wrapped in double quotes when they contain:\n * - Colons followed by space\n * - Hash symbols, brackets, braces\n * - Leading/trailing whitespace\n */\n```\n\n---\n\n## Implementation Plan\n\n### Step 1: Add Module Overviews\nAdd comprehensive module-level JSDoc at top of each file.\n\n### Step 2: Document Public Functions\nAdd JSDoc with @param, @returns, @example, @remarks for each public function.\n\n### Step 3: Document Complex Internals\nAdd explanatory comments for non-obvious algorithms.\n\n### Step 4: Add @see Cross-References\nLink related modules together.\n\n### Step 5: Verify Documentation\n```bash\nbun run typecheck\nnpx typedoc packages/shared/src/block-converters.ts packages/shared/src/inline-converters.ts packages/shared/src/frontmatter.ts --out /tmp/docs\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/block-converters.ts` | ADD JSDoc |\n| `packages/shared/src/inline-converters.ts` | ADD JSDoc |\n| `packages/shared/src/frontmatter.ts` | ADD JSDoc |\n\n## Success Criteria\n- [ ] All three modules have module-level overview\n- [ ] All public functions documented with @param, @returns\n- [ ] Examples provided for complex functions\n- [ ] Cross-references between related modules\n- [ ] Format combination matrix documented\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: scribe-p2d.1, scribe-p2d.2, scribe-p2d.5 (tests should exist first)\n\n## Estimated Effort\n- **Size**: Medium (3-4 hours total)\n- **Risk**: Low\n\n## Labels\n- documentation\n- sprint-5\n- P3-low\n- jsdoc\n- MERGED from scribe-p2d.19, .20, .21","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T22:25:34.216688-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.2","title":"[Sprint 1.2] Add comprehensive tests for inline-converters.ts","description":"# Add Comprehensive Tests for inline-converters.ts\n\n## File Under Test\n`packages/shared/src/inline-converters.ts` (305 lines)\n\n## Strategic Context\n\n### Why This is Critical (P1)\nThis module handles **inline content conversion** - the text formatting that users see in every note. Bugs here affect:\n- **Bold/Italic rendering**: `**text**` and `*text*` output\n- **Links**: Internal note links and external URLs\n- **Mentions**: @person references that power the people graph\n- **Inline code**: `` `code` `` snippets\n\nIf conversion fails, user formatting is lost or corrupted in exports.\n\n### What This Module Does\nInline content extraction handles:\n- **Text formatting**: Bold, italic, underline, strikethrough, code\n- **Combined formats**: Bold-italic, underlined-code, etc.\n- **Link nodes**: External URLs with display text\n- **Internal links**: Note-to-note references (wiki-style links)\n- **Mentions**: Person mentions that connect to people notes\n- **Escape sequences**: Markdown special character handling\n\n### Current State\n- **Lines of code**: 305\n- **Test coverage**: 0% (NO TESTS)\n- **Complexity**: MEDIUM (format combination logic, link handling)\n\n## Implementation Plan\n\n### Test Categories\n\n#### 1. Text Formatting Tests\n```typescript\ndescribe('textToMarkdown', () =\u003e {\n  describe('single formats', () =\u003e {\n    it('converts bold to **text**', () =\u003e {});\n    it('converts italic to *text*', () =\u003e {});\n    it('converts underline to \u003cu\u003etext\u003c/u\u003e', () =\u003e {});\n    it('converts strikethrough to ~~text~~', () =\u003e {});\n    it('converts code to `text`', () =\u003e {});\n  });\n  \n  describe('combined formats', () =\u003e {\n    it('converts bold+italic to ***text***', () =\u003e {});\n    it('handles bold+code correctly', () =\u003e {});\n    it('handles triple format combinations', () =\u003e {});\n  });\n  \n  describe('format boundaries', () =\u003e {\n    it('handles format changes mid-text', () =\u003e {});\n    it('handles adjacent different formats', () =\u003e {});\n    it('handles nested format contexts', () =\u003e {});\n  });\n});\n```\n\n#### 2. Link Conversion Tests\n```typescript\ndescribe('linkToMarkdown', () =\u003e {\n  describe('external links', () =\u003e {\n    it('converts to [text](url) format', () =\u003e {});\n    it('handles links without display text', () =\u003e {});\n    it('escapes special chars in URLs', () =\u003e {});\n    it('handles email links (mailto:)', () =\u003e {});\n  });\n  \n  describe('internal links', () =\u003e {\n    it('converts wiki-style [[note]] links', () =\u003e {});\n    it('handles links with display text [[note|display]]', () =\u003e {});\n    it('handles links to non-existent notes', () =\u003e {});\n  });\n});\n```\n\n#### 3. Mention Conversion Tests\n```typescript\ndescribe('mentionToMarkdown', () =\u003e {\n  it('converts person mention to @name', () =\u003e {});\n  it('preserves mention metadata', () =\u003e {});\n  it('handles mentions with special characters', () =\u003e {});\n  it('handles multiple mentions in sequence', () =\u003e {});\n});\n```\n\n#### 4. Escape Handling Tests\n```typescript\ndescribe('escapeInlineMarkdown', () =\u003e {\n  it('escapes asterisks that could be formatting', () =\u003e {});\n  it('escapes underscores that could be formatting', () =\u003e {});\n  it('escapes backticks', () =\u003e {});\n  it('preserves already-escaped characters', () =\u003e {});\n  it('handles edge: *text* surrounded by words', () =\u003e {});\n});\n```\n\n#### 5. Integration Tests\n```typescript\ndescribe('inline content integration', () =\u003e {\n  it('converts paragraph with mixed content', () =\u003e {});\n  it('handles formatted text with links', () =\u003e {});\n  it('handles mentions inside formatted text', () =\u003e {});\n});\n```\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/inline-converters.test.ts` | CREATE |\n| `packages/shared/src/__fixtures__/inline-samples.ts` | CREATE (test fixtures) |\n\n## Verification\n\n```bash\n# Run tests\nbun test packages/shared/src/inline-converters.test.ts\n\n# Check coverage\nbun test packages/shared --coverage | grep inline-converters\n\n# Target: \u003e80% line coverage\n```\n\n## Success Criteria\n- [ ] All test categories implemented\n- [ ] Coverage \u003e80% for inline-converters.ts\n- [ ] Format combination matrix tested\n- [ ] Edge cases for escaping documented\n\n## Dependencies\n- **Blocks**: None (fully parallel)\n- **Blocked by**: None\n\n## Relationship to Other Tasks\n- Pairs well with block-converters.ts tests (Sprint 1.1)\n- Both feed into content-extractor integration\n- Test fixtures can be shared\n\n## Estimated Effort\n- **Size**: Medium (3-4 hours)\n- **Risk**: Low (pure functions, predictable inputs)\n\n## Labels\n- testing\n- sprint-1\n- P1-critical\n- content-safety","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:19:25.978278-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.20","title":"[Sprint 5.2] Add JSDoc documentation for inline-converters.ts","description":"# Add JSDoc Documentation for inline-converters.ts\n\n## Problem Statement\n`packages/shared/src/inline-converters.ts` handles inline content conversion (bold, italic, links, mentions) but lacks documentation explaining the format combination logic.\n\n## Documentation Required\n\n### 1. Module Overview\n```typescript\n/**\n * @module inline-converters\n * \n * Converts Lexical inline nodes to Markdown format.\n * \n * ## Supported Inline Types\n * - Text with formatting (bold, italic, underline, strikethrough, code)\n * - External links → [text](url)\n * - Internal links → [[note-name]] or [[note|display]]\n * - Person mentions → @PersonName\n * \n * ## Format Combination Rules\n * - Bold + Italic = ***text***\n * - Code takes precedence (no nesting)\n * - Strikethrough wraps outer: ~~**text**~~\n * \n * @see {@link block-converters} for block-level conversion\n * @see {@link markdown-escaper} for character escaping\n */\n```\n\n### 2. Format Combination Matrix\nDocument the complex format interaction logic:\n```typescript\n/**\n * Applies text formatting to content.\n * \n * ## Format Priority\n * When multiple formats apply, they nest in this order (outer to inner):\n * 1. Strikethrough (~~)\n * 2. Bold (**)\n * 3. Italic (*)\n * 4. Underline (\u003cu\u003e)\n * 5. Code (`) - cannot contain other formats\n * \n * ## Combination Examples\n * | Formats | Output |\n * |---------|--------|\n * | bold | **text** |\n * | italic | *text* |\n * | bold+italic | ***text*** |\n * | strikethrough+bold | ~~**text**~~ |\n * | code | `text` (no other formats) |\n */\n```\n\n### 3. Link Handling Documentation\n```typescript\n/**\n * Converts link nodes to Markdown format.\n * \n * ## Link Types\n * - External: `[display](https://example.com)`\n * - Internal: `[[note-name]]` or `[[note-name|Display Text]]`\n * - Email: `[email](mailto:user@example.com)`\n * \n * ## URL Escaping\n * - Parentheses in URLs are escaped: `url%28with%29parens`\n * - Spaces are encoded: `url%20with%20spaces`\n * \n * @param node - Link node containing url and optional title\n * @returns Markdown link string\n */\n```\n\n## Implementation Plan\n\n### Step 1: Add Module Overview\nDocument the overall purpose and supported types.\n\n### Step 2: Document Format Combination\nExplain the matrix of format interactions.\n\n### Step 3: Document Each Converter\nAdd JSDoc to link, mention, and text converters.\n\n### Step 4: Add Examples\nInclude @example blocks with input/output.\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/inline-converters.ts` | ADD JSDoc |\n\n## Success Criteria\n- [ ] Module overview added\n- [ ] Format combination matrix documented\n- [ ] All converters documented\n- [ ] Examples provided\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: Sprint 1.2 (tests should exist first)\n\n## Estimated Effort\n- **Size**: Small-Medium (1-2 hours)\n- **Risk**: Low\n\n## Labels\n- documentation\n- sprint-5\n- P3-low\n- jsdoc","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T22:25:50.550736-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.21","title":"[Sprint 5.3] Add JSDoc documentation for frontmatter.ts","description":"# Add JSDoc Documentation for frontmatter.ts\n\n## Problem Statement\n`packages/shared/src/frontmatter.ts` generates YAML frontmatter for markdown export but lacks documentation on YAML escaping rules and output format.\n\n## Documentation Required\n\n### 1. Module Overview\n```typescript\n/**\n * @module frontmatter\n * \n * Generates YAML frontmatter for Markdown export.\n * \n * ## Output Format\n * ```yaml\n * ---\n * title: Note Title\n * created: 2024-01-15T10:30:00Z\n * updated: 2024-01-16T14:20:00Z\n * tags:\n *   - tag1\n *   - tag2\n * ---\n * ```\n * \n * ## Compatibility\n * Output is compatible with:\n * - Obsidian\n * - Hugo\n * - Jekyll\n * - Astro\n * - Any YAML 1.1 compliant parser\n * \n * @see {@link content-extractor} for full export pipeline\n */\n```\n\n### 2. Escaping Rules Documentation\n```typescript\n/**\n * Escapes a string value for safe YAML output.\n * \n * ## Escaping Rules\n * \n * ### Quote Wrapping\n * Values are wrapped in double quotes when they contain:\n * - Colons followed by space (`: `)\n * - Hash symbols (`#`)\n * - Square brackets (`[`, `]`)\n * - Curly braces (`{`, `}`)\n * - Leading/trailing whitespace\n * \n * ### Character Escaping\n * Inside double quotes:\n * - `\"` becomes `\\\"`\n * - `\\` becomes `\\\\`\n * - Newlines become `\\n`\n * \n * ### Safe Values\n * These don't need quoting:\n * - Alphanumeric strings\n * - Strings with spaces (but no special chars)\n * \n * @param value - The string to escape\n * @returns YAML-safe string, possibly quoted\n */\n```\n\n## Implementation Plan\n\n### Step 1: Add Module Overview\nDocument purpose, output format, compatibility.\n\n### Step 2: Document Escaping Logic\nExplain when and how values are escaped.\n\n### Step 3: Document Optional Fields\nExplain which fields are included/omitted based on input.\n\n### Step 4: Add Examples\nInclude full frontmatter output examples.\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/frontmatter.ts` | ADD JSDoc |\n\n## Success Criteria\n- [ ] Module overview with output format\n- [ ] Escaping rules documented\n- [ ] Optional field behavior documented\n- [ ] Compatibility notes included\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: Sprint 1.5 (tests should exist first)\n\n## Estimated Effort\n- **Size**: Small (45 minutes)\n- **Risk**: Low\n\n## Labels\n- documentation\n- sprint-5\n- P3-low\n- jsdoc","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T22:26:03.379245-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.22","title":"[Sprint 5.4] Document intentional swallowed promises with explanatory comments","description":"# Document Intentional Swallowed Promises\n\n## Problem Statement\nThe codebase has 7 instances of `.catch(() =\u003e {})` or `.catch(() =\u003e ...)` that intentionally swallow promise rejections. While intentional, they lack explanatory comments.\n\n## Why This Matters\n\n### Code Review Friction\nWithout comments, reviewers may think these are bugs:\n- \"Why is this error ignored?\"\n- \"Shouldn't we handle this?\"\n\n### Future Maintenance\nDevelopers maintaining this code need to understand:\n- Why the error is intentionally ignored\n- What the expected failure scenarios are\n\n## Verified Instances (Accurate as of analysis)\n\n| File | Line | Purpose |\n|------|------|---------|\n| `apps/cli/src/signals.ts` | ~93 | Signal cleanup - can fail if process exiting |\n| `apps/cli/src/signals.ts` | ~106 | Second signal cleanup attempt |\n| `apps/cli/tests/setup.ts` | ~46 | Test cleanup - best effort |\n| `packages/test-utils/src/vault-factory.ts` | ~98 | Temp directory cleanup |\n| `packages/test-utils/src/vault-factory.ts` | ~179 | Temp directory cleanup |\n| `apps/cli/tests/unit/vault-resolver.test.ts` | ~47 | Test cleanup |\n| `apps/desktop/renderer/.../AttendeesWidget.tsx` | ~51 | Returns null on failure (slightly different pattern) |\n\n## Documentation Pattern\n\nReplace:\n```typescript\ncleanup().catch(() =\u003e {});\n```\n\nWith:\n```typescript\n// INTENTIONAL: Best-effort cleanup during process exit/teardown.\n// Expected to fail if directory already removed or process terminating.\n// No user-visible impact if this fails.\ncleanup().catch(() =\u003e {});\n```\n\n## Implementation Plan\n\n### Step 1: Review Each Instance\nFor each swallowed promise:\n1. Understand why it's intentional\n2. Document the expected failure scenarios\n3. Confirm it's truly safe to ignore\n\n### Step 2: Add Comments\nAdd explanatory comment before each `.catch(() =\u003e {})`.\n\n### Step 3: Consider Debug Logging (Optional)\nFor some cases, consider logging at debug level:\n```typescript\ncleanup().catch((err) =\u003e {\n  // Best-effort cleanup - log but don't fail\n  log.debug('Cleanup failed (expected during teardown)', { error: err.message });\n});\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `apps/cli/src/signals.ts` | ADD comments (2 instances) |\n| `apps/cli/tests/setup.ts` | ADD comment |\n| `packages/test-utils/src/vault-factory.ts` | ADD comments (2 instances) |\n| `apps/cli/tests/unit/vault-resolver.test.ts` | ADD comment |\n| `apps/desktop/renderer/src/components/ContextPanel/AttendeesWidget.tsx` | ADD comment (different pattern) |\n\n## Verification\n\n```bash\n# Find all swallowed promises\ngrep -rn \"catch(() =\u003e\" apps/ packages/ --include=\"*.ts\" --include=\"*.tsx\"\n\n# Ensure each has a comment above it\n# Manual review\n```\n\n## Success Criteria\n- [ ] All 7 instances have explanatory comments\n- [ ] Comments explain why swallowing is intentional\n- [ ] Expected failure scenarios documented\n- [ ] No new swallowed promises added without comments\n\n## Dependencies\n- **Blocks**: None\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small (45 minutes)\n- **Risk**: Low\n\n## Labels\n- documentation\n- sprint-5\n- P3-low\n- code-quality","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-25T22:26:22.768444-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.3","title":"[Sprint 1.3] Add comprehensive tests for markdown-escaper.ts","description":"# Add Comprehensive Tests for markdown-escaper.ts\n\n## File Under Test\n`packages/shared/src/markdown-escaper.ts` (336 lines)\n\n## Strategic Context\n\n### Why This is Critical (P1)\nThe markdown escaper is the **defensive layer** that prevents user content from accidentally triggering markdown formatting. This is critical for:\n- **Data fidelity**: User text like `*important*` stays as-is if not intentionally formatted\n- **Security-adjacent**: Prevents injection of unintended markdown structures\n- **Export quality**: Clean, predictable markdown output\n\n### What This Module Does\nEscape/unescape utilities for markdown special characters:\n- **Line-start escaping**: `#`, `\u003e`, `-`, `+`, `*` at start of line\n- **Inline escaping**: `*`, `_`, `` ` ``, `[`, `]`, `(`, `)`, `\\`\n- **Context-aware escaping**: Different rules for table cells (pipe escaping)\n- **Ordered list detection**: Escaping `1.`, `2.`, etc. at line start\n- **Emphasis pattern detection**: Mid-word `*` and `_` handling\n\n### Current State\n- **Lines of code**: 336\n- **Test coverage**: 0% (NO TESTS)\n- **Complexity**: HIGH (state machine, context-sensitive rules)\n\n## Implementation Plan\n\n### Test Categories\n\n#### 1. Line-Start Escaping Tests\n```typescript\ndescribe('escapeLineStart', () =\u003e {\n  it('escapes # that would become heading', () =\u003e {\n    expect(escape('# not a heading')).toBe('\\\\# not a heading');\n  });\n  it('escapes \u003e that would become blockquote', () =\u003e {});\n  it('escapes - that would become list item', () =\u003e {});\n  it('escapes + that would become list item', () =\u003e {});\n  it('escapes * that would become list item', () =\u003e {});\n  it('does NOT escape # mid-line', () =\u003e {});\n  it('handles multiple # at start', () =\u003e {});\n});\n```\n\n#### 2. Ordered List Escaping Tests\n```typescript\ndescribe('escapeOrderedListMarker', () =\u003e {\n  it('escapes \"1. \" at line start', () =\u003e {});\n  it('escapes multi-digit numbers \"10. \"', () =\u003e {});\n  it('does NOT escape \"1.\" without space', () =\u003e {});\n  it('does NOT escape mid-line numbers', () =\u003e {});\n});\n```\n\n#### 3. Emphasis Escaping Tests\n```typescript\ndescribe('escapeEmphasis', () =\u003e {\n  describe('asterisk escaping', () =\u003e {\n    it('escapes *word* pattern', () =\u003e {});\n    it('escapes **word** pattern', () =\u003e {});\n    it('does NOT escape mid-word asterisk', () =\u003e {});\n    it('escapes ***word*** pattern', () =\u003e {});\n  });\n  \n  describe('underscore escaping', () =\u003e {\n    it('escapes _word_ pattern', () =\u003e {});\n    it('escapes __word__ pattern', () =\u003e {});\n    it('does NOT escape mid_word underscores', () =\u003e {});\n  });\n  \n  describe('edge cases', () =\u003e {\n    it('handles \"a*b*c\" (all mid-word)', () =\u003e {});\n    it('handles \"word* not emphasis\"', () =\u003e {});\n    it('handles \"*emphasis* more text\"', () =\u003e {});\n  });\n});\n```\n\n#### 4. Bracket/Parenthesis Escaping Tests\n```typescript\ndescribe('escapeLinkCharacters', () =\u003e {\n  it('escapes [ that could start link text', () =\u003e {});\n  it('escapes ] that could end link text', () =\u003e {});\n  it('escapes ( in link context', () =\u003e {});\n  it('escapes ) in link context', () =\u003e {});\n  it('preserves balanced brackets in prose', () =\u003e {});\n});\n```\n\n#### 5. Table Context Tests\n```typescript\ndescribe('escapeTableContent', () =\u003e {\n  it('escapes | in table cells', () =\u003e {});\n  it('preserves other escaping in table cells', () =\u003e {});\n  it('handles complex cell content', () =\u003e {});\n});\n```\n\n#### 6. State Machine Tests\n```typescript\ndescribe('contextTracking', () =\u003e {\n  it('tracks line start correctly', () =\u003e {});\n  it('resets after newline', () =\u003e {});\n  it('handles Windows line endings (CRLF)', () =\u003e {});\n  it('maintains state across multiple escapes', () =\u003e {});\n});\n```\n\n#### 7. Round-Trip Tests\n```typescript\ndescribe('escape/unescape round-trip', () =\u003e {\n  it('text survives escape → unescape', () =\u003e {});\n  it('formatted text survives round-trip', () =\u003e {});\n  it('complex document survives round-trip', () =\u003e {});\n});\n```\n\n## Property-Based Testing Opportunity\n\nThis module is an excellent candidate for property-based testing:\n\n```typescript\nimport { fc } from '@fast-check/vitest';\n\ndescribe('property-based tests', () =\u003e {\n  it('escape never produces unbalanced backslashes', () =\u003e {\n    fc.assert(fc.property(fc.string(), (s) =\u003e {\n      const escaped = escapeMarkdownText(s);\n      return !escaped.includes('\\\\\\\\\\\\'); // no triple escapes\n    }));\n  });\n  \n  it('escape is idempotent for safe strings', () =\u003e {\n    fc.assert(fc.property(fc.string(), (s) =\u003e {\n      // If string has no special chars, escape should be identity\n    }));\n  });\n});\n```\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/markdown-escaper.test.ts` | CREATE |\n\n## Verification\n\n```bash\n# Run tests\nbun test packages/shared/src/markdown-escaper.test.ts\n\n# Check coverage\nbun test packages/shared --coverage | grep markdown-escaper\n\n# Target: \u003e90% line coverage (escaper is critical)\n```\n\n## Success Criteria\n- [ ] All test categories implemented\n- [ ] Coverage \u003e90% for markdown-escaper.ts (higher bar for critical code)\n- [ ] Property-based tests for invariants\n- [ ] All edge cases from issue #52 covered\n\n## Dependencies\n- **Blocks**: None (fully parallel)\n- **Blocked by**: None\n- **Related**: Feeds into inline-converters.ts testing\n\n## Estimated Effort\n- **Size**: Medium-Large (4-5 hours)\n- **Risk**: Medium (state machine complexity)\n\n## Labels\n- testing\n- sprint-1\n- P1-critical\n- content-safety\n- property-based-testing","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:19:56.861986-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.4","title":"[Sprint 1.4] Add comprehensive tests for content.ts","description":"# Add Comprehensive Tests for content.ts\n\n## File Under Test\n`packages/shared/src/content.ts` (206 lines)\n\n## Strategic Context\n\n### Why This is Critical (P1)\nThis module provides **content creation utilities** - the foundational building blocks for creating note content. Every new note, template, and content structure flows through here:\n- **createEmptyContent()**: Base for all new notes\n- **Content type utilities**: Helpers for structured content creation\n- **Content validation**: Ensuring content meets expected structure\n\n### What This Module Does\nContent creation utilities handle:\n- **Empty content creation**: Properly structured Lexical root nodes\n- **Content type helpers**: Daily, meeting, person note structures\n- **Content structure validation**: Ensuring AST integrity\n- **Content cloning**: Safe deep copies for modification\n\n### Current State\n- **Lines of code**: 206\n- **Test coverage**: 0% (NO TESTS)\n- **Complexity**: MEDIUM (structure creation, type safety)\n\n## Implementation Plan\n\n### Test Categories\n\n#### 1. Empty Content Creation Tests\n```typescript\ndescribe('createEmptyContent', () =\u003e {\n  it('creates valid EditorContent structure', () =\u003e {\n    const content = createEmptyContent();\n    expect(content.root).toBeDefined();\n    expect(content.root.type).toBe('root');\n  });\n  \n  it('includes empty paragraph with correct properties', () =\u003e {\n    const content = createEmptyContent();\n    const paragraph = content.root.children[0];\n    expect(paragraph.type).toBe('paragraph');\n    expect(paragraph.format).toBeDefined();\n    expect(paragraph.indent).toBe(0);\n    expect(paragraph.direction).toBeDefined();\n    expect(paragraph.version).toBeDefined();\n  });\n  \n  it('creates independent instances (not shared references)', () =\u003e {\n    const content1 = createEmptyContent();\n    const content2 = createEmptyContent();\n    content1.root.children.push({ type: 'test' });\n    expect(content2.root.children).toHaveLength(1);\n  });\n  \n  it('matches expected EditorContent type', () =\u003e {\n    const content = createEmptyContent();\n    // Type-level check: this should compile\n    const typed: EditorContent = content;\n    expect(typed).toBeDefined();\n  });\n});\n```\n\n#### 2. Daily Content Creation Tests\n```typescript\ndescribe('createDailyContent', () =\u003e {\n  it('creates content with date heading', () =\u003e {});\n  it('includes default daily note structure', () =\u003e {});\n  it('accepts custom date parameter', () =\u003e {});\n  it('formats date correctly in heading', () =\u003e {});\n});\n```\n\n#### 3. Meeting Content Creation Tests\n```typescript\ndescribe('createMeetingContent', () =\u003e {\n  it('creates content with meeting title', () =\u003e {});\n  it('includes attendees section', () =\u003e {});\n  it('includes agenda section', () =\u003e {});\n  it('includes notes section', () =\u003e {});\n  it('includes action items section', () =\u003e {});\n});\n```\n\n#### 4. Person Content Creation Tests\n```typescript\ndescribe('createPersonContent', () =\u003e {\n  it('creates content with person name heading', () =\u003e {});\n  it('includes contact info section', () =\u003e {});\n  it('includes notes section', () =\u003e {});\n  it('handles special characters in names', () =\u003e {});\n});\n```\n\n#### 5. Content Validation Tests\n```typescript\ndescribe('content validation', () =\u003e {\n  it('validates well-formed content', () =\u003e {});\n  it('rejects missing root', () =\u003e {});\n  it('rejects invalid node types', () =\u003e {});\n  it('handles null/undefined gracefully', () =\u003e {});\n});\n```\n\n#### 6. Content Cloning Tests\n```typescript\ndescribe('content cloning', () =\u003e {\n  it('creates deep copy of content', () =\u003e {});\n  it('modifications to clone do not affect original', () =\u003e {});\n  it('handles complex nested structures', () =\u003e {});\n  it('preserves all node properties', () =\u003e {});\n});\n```\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/content.test.ts` | CREATE |\n\n## Verification\n\n```bash\n# Run tests\nbun test packages/shared/src/content.test.ts\n\n# Check coverage\nbun test packages/shared --coverage | grep content.ts\n\n# Target: \u003e80% line coverage\n```\n\n## Success Criteria\n- [ ] All content creation functions tested\n- [ ] Coverage \u003e80% for content.ts\n- [ ] Type safety verified at runtime\n- [ ] Deep clone independence verified\n\n## Dependencies\n- **Blocks**: None (fully parallel)\n- **Blocked by**: None\n- **Related**: Content creation is used by note-factory.ts\n\n## Estimated Effort\n- **Size**: Small-Medium (2-3 hours)\n- **Risk**: Low (well-defined structures)\n\n## Labels\n- testing\n- sprint-1\n- P1-critical\n- content-safety","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:20:21.589313-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.5","title":"[Sprint 1.5] Add comprehensive tests for frontmatter.ts","description":"# Add Comprehensive Tests for frontmatter.ts\n\n## File Under Test\n`packages/shared/src/frontmatter.ts` (~100 lines)\n\n## Strategic Context\n\n### Why This is Critical (P1)\nFrontmatter is the **metadata header** for markdown exports. YAML frontmatter is used by:\n- **Static site generators**: Hugo, Jekyll, Astro expect valid frontmatter\n- **Note-taking apps**: Obsidian, Logseq parse frontmatter for metadata\n- **Export interoperability**: Users expect their exported notes to work elsewhere\n\nInvalid frontmatter can make exported notes unusable in other tools.\n\n### What This Module Does\nYAML frontmatter generation for markdown export:\n- **Title**: Note title as frontmatter field\n- **Created/Updated dates**: Timestamp metadata\n- **Tags**: Array of tags in YAML format\n- **Custom fields**: Extensible metadata structure\n- **Special character handling**: YAML escaping for edge cases\n\n### Current State\n- **Lines of code**: ~100\n- **Test coverage**: 0% (NO TESTS)\n- **Complexity**: MEDIUM (YAML generation, special char handling)\n\n## Implementation Plan\n\n### Test Categories\n\n#### 1. Basic Frontmatter Generation\n```typescript\ndescribe('generateFrontmatter', () =\u003e {\n  it('generates valid YAML frontmatter structure', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Test' });\n    expect(fm).toMatch(/^---\\n/);\n    expect(fm).toMatch(/\\n---$/);\n  });\n  \n  it('includes title field', () =\u003e {\n    const fm = generateFrontmatter({ title: 'My Note' });\n    expect(fm).toContain('title: My Note');\n  });\n  \n  it('includes created date in ISO format', () =\u003e {\n    const fm = generateFrontmatter({ \n      title: 'Test',\n      createdAt: new Date('2024-01-15T10:30:00Z')\n    });\n    expect(fm).toContain('created: 2024-01-15');\n  });\n  \n  it('includes updated date if different from created', () =\u003e {});\n});\n```\n\n#### 2. Tags Handling Tests\n```typescript\ndescribe('frontmatter tags', () =\u003e {\n  it('formats single tag as YAML array', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Test', tags: ['important'] });\n    expect(fm).toContain('tags:\\n  - important');\n  });\n  \n  it('formats multiple tags correctly', () =\u003e {\n    const fm = generateFrontmatter({ \n      title: 'Test', \n      tags: ['work', 'project', 'urgent'] \n    });\n    expect(fm).toContain('  - work');\n    expect(fm).toContain('  - project');\n    expect(fm).toContain('  - urgent');\n  });\n  \n  it('omits tags field if empty array', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Test', tags: [] });\n    expect(fm).not.toContain('tags:');\n  });\n});\n```\n\n#### 3. Special Character Escaping Tests\n```typescript\ndescribe('YAML special character handling', () =\u003e {\n  it('quotes title containing colon', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Meeting: Q1 Planning' });\n    expect(fm).toContain('title: \"Meeting: Q1 Planning\"');\n  });\n  \n  it('escapes quotes in title', () =\u003e {\n    const fm = generateFrontmatter({ title: 'The \"Big\" Meeting' });\n    expect(fm).toContain('title: \"The \\\\\"Big\\\\\" Meeting\"');\n  });\n  \n  it('handles newlines in title', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Line 1\\nLine 2' });\n    // Should use multiline YAML or escape\n  });\n  \n  it('handles special YAML characters: { } [ ] @ # \u0026', () =\u003e {});\n  \n  it('handles emoji in title', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Celebration  Party' });\n    expect(fm).toContain('Celebration');\n  });\n});\n```\n\n#### 4. Custom Fields Tests\n```typescript\ndescribe('custom frontmatter fields', () =\u003e {\n  it('includes custom string fields', () =\u003e {\n    const fm = generateFrontmatter({ \n      title: 'Test',\n      custom: { author: 'John Doe' }\n    });\n    expect(fm).toContain('author: John Doe');\n  });\n  \n  it('includes custom array fields', () =\u003e {});\n  it('includes custom nested objects', () =\u003e {});\n  it('handles null custom values', () =\u003e {});\n});\n```\n\n#### 5. Edge Cases\n```typescript\ndescribe('edge cases', () =\u003e {\n  it('handles empty title', () =\u003e {});\n  it('handles very long titles (\u003e100 chars)', () =\u003e {});\n  it('handles undefined optional fields', () =\u003e {});\n  it('produces parseable YAML (round-trip test)', () =\u003e {\n    const fm = generateFrontmatter({ title: 'Test', tags: ['a', 'b'] });\n    const parsed = YAML.parse(fm.slice(4, -4)); // strip ---\n    expect(parsed.title).toBe('Test');\n    expect(parsed.tags).toEqual(['a', 'b']);\n  });\n});\n```\n\n## Files to Create/Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/frontmatter.test.ts` | CREATE |\n\n## Verification\n\n```bash\n# Run tests\nbun test packages/shared/src/frontmatter.test.ts\n\n# Check coverage\nbun test packages/shared --coverage | grep frontmatter\n\n# Target: \u003e80% line coverage\n```\n\n## Success Criteria\n- [ ] All frontmatter generation paths tested\n- [ ] Coverage \u003e80% for frontmatter.ts\n- [ ] YAML output is parseable (round-trip verified)\n- [ ] Special characters handled correctly\n\n## Dependencies\n- **Blocks**: None (fully parallel)\n- **Blocked by**: None\n- **Related**: Used by content-extractor for markdown export\n\n## Estimated Effort\n- **Size**: Small (2 hours)\n- **Risk**: Low (well-defined output format)\n\n## Labels\n- testing\n- sprint-1\n- P1-critical\n- content-safety\n- export","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:20:46.927374-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.6","title":"[Sprint 1.6] Remove duplicate formatDate from CLI output.ts","description":"# Remove Duplicate formatDate from CLI output.ts\n\n## Problem Statement\nThe `formatDate` function is duplicated in `apps/cli/src/output.ts` (lines 133-142) when the canonical implementation exists in `@scribe/shared` at `packages/shared/src/date-utils.ts`.\n\n## Why This Matters\n\n### Consistency Risk\nDifferent date formatting implementations can produce subtly different outputs:\n- Timezone handling differences\n- Locale-specific formatting\n- Edge cases (midnight, DST transitions)\n\n### Maintenance Burden\nEvery bug fix or improvement to date formatting needs to happen in 4 places. This is unsustainable and error-prone.\n\n### User Experience\nUsers expect consistent date formatting whether they use the CLI or desktop app. Duplicates make this harder to guarantee.\n\n## Current State\n\n### Duplicate Location\n```typescript\n// apps/cli/src/output.ts, lines 133-142\nfunction formatDate(date: Date): string {\n  // Local duplicate implementation\n}\n```\n\n### Canonical Location\n```typescript\n// packages/shared/src/date-utils.ts, lines 34-80\nexport function formatDate(date: Date, format?: string): string {\n  // Canonical implementation with full format support\n}\n```\n\n## Implementation Plan\n\n### Step 1: Add Import\n```typescript\n// At top of apps/cli/src/output.ts\nimport { formatDate } from '@scribe/shared';\n```\n\n### Step 2: Remove Local Function\nDelete lines 133-142 containing the local `formatDate` implementation.\n\n### Step 3: Verify Usage\nSearch for all usages of `formatDate` in output.ts and ensure they're compatible with the shared implementation signature.\n\n### Step 4: Run Tests\n```bash\nbun test apps/cli\n```\n\n### Step 5: Manual Verification\n```bash\n# Run CLI commands that use date formatting\nscribe list --recent\nscribe show \u003cnote-id\u003e\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `apps/cli/src/output.ts` | Remove duplicate, add import |\n\n## Verification\n\n```bash\n# Ensure no duplicate definitions\ngrep -n \"function formatDate\" apps/cli/src/\n\n# Should only show import, not definition\ngrep -n \"formatDate\" apps/cli/src/output.ts\n\n# Run tests\nbun test apps/cli\n```\n\n## Success Criteria\n- [ ] Local formatDate function removed\n- [ ] Import from @scribe/shared added\n- [ ] All CLI tests pass\n- [ ] Date formatting output unchanged\n\n## Dependencies\n- **Blocks**: None (fully parallel with other dedup tasks)\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small (30 minutes)\n- **Risk**: Low (well-tested shared function)\n\n## Labels\n- refactoring\n- sprint-1\n- P1-high\n- deduplication\n- cli","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:21:15.039303-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.7","title":"[Sprint 1.7] Remove duplicate date functions from CLI daily.ts","description":"# Remove Duplicate Date Functions from CLI daily.ts\n\n## Problem Statement\nThe `formatDateYMD` and `formatDateTitle` functions are duplicated in `apps/cli/src/commands/daily.ts` (lines 17-31). These should use the canonical implementations from `@scribe/shared`.\n\n## Current Duplicates\n\n### formatDateYMD (lines 17-23)\n```typescript\n// apps/cli/src/commands/daily.ts\nfunction formatDateYMD(date: Date): string {\n  const year = date.getFullYear();\n  const month = String(date.getMonth() + 1).padStart(2, '0');\n  const day = String(date.getDate()).padStart(2, '0');\n  return `${year}-${month}-${day}`;\n}\n```\n\n### formatDateTitle (lines 25-31)\n```typescript\nfunction formatDateTitle(date: Date): string {\n  return date.toLocaleDateString('en-US', {\n    weekday: 'long',\n    year: 'numeric',\n    month: 'long',\n    day: 'numeric'\n  });\n}\n```\n\n## Canonical Equivalents in @scribe/shared\n\n```typescript\n// packages/shared/src/date-utils.ts\nexport function formatDateYYYYMMDD(date: Date): string { ... }  // lines 34-45\nexport function formatDateFull(date: Date): string { ... }      // lines 130-149\n```\n\n## Implementation Plan\n\n### Step 1: Verify Canonical Functions\nEnsure the shared functions produce identical output:\n```typescript\n// Test that these are equivalent:\nformatDateYMD(date) === formatDateYYYYMMDD(date)\nformatDateTitle(date) === formatDateFull(date)\n```\n\n### Step 2: Add Imports\n```typescript\n// At top of apps/cli/src/commands/daily.ts\nimport { formatDateYYYYMMDD, formatDateFull } from '@scribe/shared';\n```\n\n### Step 3: Update Usages\nReplace local function calls:\n```typescript\n// Before\nconst dateStr = formatDateYMD(date);\nconst title = formatDateTitle(date);\n\n// After\nconst dateStr = formatDateYYYYMMDD(date);\nconst title = formatDateFull(date);\n```\n\n### Step 4: Remove Local Functions\nDelete lines 17-31 containing the duplicate implementations.\n\n### Step 5: Run Tests\n```bash\nbun test apps/cli\n```\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `apps/cli/src/commands/daily.ts` | Remove duplicates, update imports |\n\n## Verification\n\n```bash\n# Ensure no duplicate definitions\ngrep -n \"function formatDate\" apps/cli/src/commands/\n\n# Run tests\nbun test apps/cli\n\n# Test daily note creation\nscribe daily\nscribe daily --date 2024-01-15\n```\n\n## Success Criteria\n- [ ] Local formatDateYMD function removed\n- [ ] Local formatDateTitle function removed\n- [ ] Imports from @scribe/shared added\n- [ ] All CLI tests pass\n- [ ] Daily note dates formatted correctly\n\n## Dependencies\n- **Blocks**: None (fully parallel)\n- **Blocked by**: None\n\n## Estimated Effort\n- **Size**: Small (30 minutes)\n- **Risk**: Low\n\n## Labels\n- refactoring\n- sprint-1\n- P1-high\n- deduplication\n- cli","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:21:31.032881-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.8","title":"[Sprint 1.8] Remove duplicate date functions from NoteHeader.tsx","description":"# Remove/Consolidate Date Functions from NoteHeader.tsx\n\n## Problem Statement\nThe `NoteHeader` component in `apps/desktop/renderer/src/components/NoteHeader/NoteHeader.tsx` (lines 27-46) contains local date formatting and **parsing** implementations.\n\n## ⚠️ IMPORTANT: This is NOT a Simple Dedup\n\nUnlike the CLI tasks, NoteHeader uses **date-fns parsing**:\n\n```typescript\n// Line 39-45 - parses MM-dd-yyyy format string!\nfunction formatDateString(dateStr: string): string {\n  const date = parse(dateStr, 'MM-dd-yyyy', new Date());\n  return date.toLocaleDateString('en-US', { ... });\n}\n```\n\nThis is fundamentally different from the CLI duplicates because:\n1. It takes a **string in MM-dd-yyyy format**, not a Date object\n2. It uses date-fns `parse()` to convert the string to a Date\n3. The shared `formatDate` functions take Date objects, not formatted strings\n\n## Current Functions\n\n```typescript\n// Line 27-34: Simple timestamp formatting (CAN be replaced)\nfunction formatDate(timestamp: number): string { ... }\n\n// Line 39-45: String parsing + formatting (REQUIRES date-fns or extension)\nfunction formatDateString(dateStr: string): string { ... }\n```\n\n## Implementation Options\n\n### Option A: Keep date-fns for parsing\n```typescript\nimport { parse } from 'date-fns';\nimport { formatDate } from '@scribe/shared';\n\nfunction formatDateString(dateStr: string): string {\n  const date = parse(dateStr, 'MM-dd-yyyy', new Date());\n  return formatDate(date, 'short'); // Use shared for formatting only\n}\n```\n\n### Option B: Extend @scribe/shared with parser\nAdd to date-utils.ts:\n```typescript\nexport function parseDateString(dateStr: string, format: string): Date { ... }\n```\n\n### Option C: Use meeting.date as Date upstream\nIf meeting.date could be stored as timestamp instead of string, this becomes simpler.\n\n## Recommendation\n\n**Option A** - Keep date-fns for parsing, use shared for formatting:\n- Minimal change scope\n- Preserves existing behavior\n- date-fns is already a dependency\n\n## Files to Modify\n\n| File | Action |\n|------|--------|\n| `apps/desktop/renderer/src/components/NoteHeader/NoteHeader.tsx` | Partial refactor |\n\n## Success Criteria\n- [ ] `formatDate(timestamp)` replaced with shared import\n- [ ] `formatDateString` either kept or properly extended\n- [ ] Tests pass\n- [ ] Meeting notes display correct dates\n\n## Dependencies\n- **Blocked by**: scribe-p2d.9 (verify shared API)\n\n## Estimated Effort\n- **Size**: Medium (1 hour - more complex than CLI tasks)\n- **Risk**: Low-Medium (visual verification needed)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:21:46.716672-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-p2d.9","title":"[Sprint 1.9] Verify @scribe/shared date-utils exports cover all dedup needs","description":"# Verify @scribe/shared Date-Utils Exports (PREREQUISITE)\n\n## Purpose\n**This task MUST be completed before scribe-p2d.6, .7, .8** - it verifies that `@scribe/shared` exports all the date utilities needed by CLI and desktop consumers.\n\n## Why This Task Exists\n\n### Dependency Awareness\nTasks 1.6, 1.7, 1.8 depend on this task's findings. If shared package is missing a function, we need to add it first.\n\n### API Design Opportunity\nThis is a chance to review the date-utils API:\n- Are function names clear and consistent?\n- Are there missing utilities that should be added?\n- Should we add format presets for common patterns?\n\n## Current Exports from @scribe/shared\n`packages/shared/src/date-utils.ts` already exports:\n\n| Function | Description |\n|----------|-------------|\n| `formatDate(date, style)` | Formats with 'short', 'medium', 'long', 'iso', 'time' |\n| `formatDateYMD(date)` | Returns 'YYYY-MM-DD' format |\n| `formatDateMMDDYYYY(date)` | Returns 'MM/DD/YYYY' format |\n| `formatDateTitle(date)` | Returns 'Month Day, Year' format |\n| `getRelativeDateString(timestamp)` | Returns relative time like '2 hours ago' |\n| `parseDate(dateString)` | Parses date string to Date |\n| `isToday(date)`, `isYesterday(date)` | Date comparisons |\n\n## Analysis Checklist\n\n### Compare Against Consumer Usage\n\n| Consumer | Current Usage | Shared Equivalent | Match? |\n|----------|---------------|-------------------|--------|\n| CLI output.ts:133 | `formatDate(iso)` → full datetime | `formatDate(date, 'time')` | Verify |\n| CLI daily.ts:17 | `formatDateYMD(date)` | `formatDateYMD(date)` | ✓ |\n| CLI daily.ts:24 | `formatDateTitle(dateStr)` | `formatDateTitle(date)` | Verify signature |\n| NoteHeader.tsx:27 | `formatDate(timestamp)` | `formatDate(date, 'medium')` | Verify |\n| NoteHeader.tsx:39 | `formatDateString(dateStr)` | May need to add | Check |\n\n## Implementation Plan\n\n### Step 1: Audit Consumer Usage\n```bash\n# Check exact signatures needed\ngrep -A5 'function formatDate' apps/cli/src/output.ts\ngrep -A5 'function formatDate' apps/cli/src/commands/daily.ts\ngrep -A5 'function formatDate' apps/desktop/renderer/src/components/NoteHeader/NoteHeader.tsx\n```\n\n### Step 2: Compare Output Formats\nRun the shared functions and compare output to consumer expectations.\n\n### Step 3: Add Missing Functions (if any)\nIf gaps are found, add the missing utilities to `packages/shared/src/date-utils.ts`.\n\n### Step 4: Update Barrel Export\nEnsure all functions are exported from `packages/shared/src/index.ts`.\n\n## Files to Potentially Modify\n\n| File | Action |\n|------|--------|\n| `packages/shared/src/date-utils.ts` | Add missing functions (if any) |\n| `packages/shared/src/index.ts` | Update exports (if needed) |\n\n## Verification\n\n```bash\n# Build shared package\nbun run build --filter=@scribe/shared\n\n# Verify exports\nbun run typecheck\n```\n\n## Success Criteria\n- [ ] All consumer date functions mapped to shared equivalents\n- [ ] Missing functions added (if any)\n- [ ] All functions exported from package barrel\n- [ ] Output format compatibility verified\n\n## Dependencies\n- **Blocks**: scribe-p2d.6, scribe-p2d.7, scribe-p2d.8 (they MUST wait for this)\n- **Blocked by**: None (START THIS FIRST!)\n\n## Estimated Effort\n- **Size**: Small-Medium (1-2 hours including analysis)\n- **Risk**: Low\n\n## Labels\n- refactoring\n- sprint-1\n- P1-high\n- deduplication\n- foundation\n- PREREQUISITE","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-25T22:22:06.163695-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo","title":"Settings Page - Full Implementation (GH Issue #50)","description":"# Settings Page Epic\n\n## Overview\nThis epic implements a comprehensive Settings page for the Scribe desktop application, accessible via a gear icon in the sidebar footer. The settings page opens as a full-screen modal with a VS Code/macOS System Settings-style sidebar navigation pattern.\n\n## Background \u0026 Motivation\nCurrently, Scribe has limited configurability exposed to users:\n- Theme toggle is buried in the sidebar footer\n- Vault location is hardcoded/undiscoverable\n- Update checking requires manual intervention\n- No centralized place for user preferences\n\nA proper Settings page serves several goals:\n1. **Discoverability** - Users can find and modify all app preferences in one place\n2. **Professional UX** - Aligns with user expectations from VS Code, macOS, and modern Electron apps\n3. **Foundation for Growth** - Establishes patterns for future settings (CLI, spellcheck, plugins, etc.)\n4. **Vault Management** - Critical for users with multiple vaults or who need to relocate their data\n\n## Architecture Decision: Full-Screen Modal Pattern\nWe chose a full-screen modal (hiding the sidebar) rather than:\n- **Inline panel**: Would compete with editor space, complex state management\n- **Separate window**: Electron multi-window adds complexity, feels disconnected\n- **Route-based**: Would require router setup, loses context of current session\n\nThe full-screen modal pattern:\n- Familiar from macOS System Preferences, VS Code Settings\n- Clear entry/exit points (gear icon → modal → X/Escape)\n- Can reuse existing Overlay primitive for backdrop and escape handling\n- Sidebar navigation scales well as settings sections grow\n\n## Technical Approach\n\n### Phase 1: Infrastructure (Foundation)\nBuild reusable primitives and IPC infrastructure that enable the feature:\n1. **SegmentedControl** - New design system primitive for theme picker\n2. **Folder Picker IPC** - dialog:selectFolder for vault management\n3. **Vault IPC Channels** - vault:getPath, vault:setPath, vault:create\n\n### Phase 2: UI Shell (Scaffolding)\nBuild the settings page structure without full functionality:\n1. **Sidebar gear icon** - Replace footer with settings trigger\n2. **SettingsPage modal** - Full-screen container with sidebar layout\n3. **Section navigation** - General and Changelog sections\n\n### Phase 3: Settings Functionality (Features)\nImplement actual settings with full behavior:\n1. **Theme setting** - SegmentedControl with immediate apply\n2. **Version + Updates** - Display version, check/install updates\n3. **Vault display** - Show current path (read-only initially)\n4. **Vault switching** - Full hot-reload implementation\n5. **Create new vault** - initializeVault integration\n\n## Key Technical Challenges\n\n### Engine Hot-Reload (Most Complex)\nSwitching vaults at runtime requires:\n- Proper cleanup of existing FileSystemVault instance\n- Re-initialization of SearchEngine, GraphEngine, TaskEngine\n- Renderer state refresh (note list, current note, etc.)\n- Graceful handling of \"current note doesn't exist in new vault\"\n\n**Mitigation**: We'll implement vault switching in waves:\n1. First: Display current path (read-only)\n2. Second: Full switching with engine hot-reload\n3. Fallback: If hot-reload proves too risky, require app restart\n\n### State Synchronization\nSettings changes need to:\n- Persist to config.json (already exists via app:setConfig)\n- Reflect immediately in UI (theme, vault)\n- Handle errors gracefully (invalid vault, failed update)\n\n## Success Criteria\n1. Gear icon visible in sidebar footer, clickable to open settings\n2. Settings modal opens full-screen, closes via X or Escape\n3. Theme switching works immediately with Dark/Light/System options\n4. Version displayed, update checking functional\n5. Vault path displayed, switching to valid vaults works\n6. Create new vault initializes structure correctly\n\n## Out of Scope (Future Work)\n- CLI installation from Settings (separate feature)\n- Actual changelog content (placeholder only)\n- Keyboard shortcuts customization\n- Plugin management\n- Multiple simultaneous vaults\n\n## References\n- GitHub Issue: #50\n- Existing IPC contract: packages/shared/src/ipc-contract.ts\n- Theme system: packages/design-system/src/ThemeProvider.tsx\n- Update hooks: apps/desktop/renderer/src/hooks/useUpdateStatus.ts\n- Vault utilities: packages/storage-fs/src/vault.ts\n\n## Dependency Graph Summary\nWave 1 (Parallel - No blockers): SegmentedControl, Sidebar gear icon, Folder picker IPC, Vault IPC basics\nWave 2 (Depends on Wave 1): SettingsPage shell, Theme setting\nWave 3 (Depends on Wave 2): Version/Update section, Vault display\nWave 4 (Depends on Wave 3): Vault switching (engine hot-reload)\nWave 5 (Depends on Wave 4): Create new vault","status":"tombstone","priority":1,"issue_type":"epic","created_at":"2025-12-23T14:56:09.822152-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"epic"}
{"id":"scribe-roo.1","title":"Create SegmentedControl design system primitive","description":"# Create SegmentedControl Design System Primitive\n\n## What\nBuild a new reusable SegmentedControl component for the design system. This is a mutually exclusive toggle group (like iOS segmented controls or radio button groups styled as connected buttons).\n\n## Why\n- **Required for Theme Picker**: The Settings page needs Dark | Light | System options displayed as a segmented control per the spec\n- **Design System Gap**: No existing component handles this pattern\n- **Reusability**: This pattern will be useful elsewhere (view toggles, filter switches, etc.)\n\n## Technical Approach\n\n### Component API\n```typescript\ninterface SegmentedControlProps\u003cT extends string\u003e {\n  options: Array\u003c{ value: T; label: string; disabled?: boolean }\u003e;\n  value: T;\n  onChange: (value: T) =\u003e void;\n  size?: 'sm' | 'md' | 'lg';\n  fullWidth?: boolean;\n  disabled?: boolean;\n  'aria-label'?: string;\n}\n```\n\n### Styling Requirements\n- Connected buttons with shared border (first/last have rounded corners)\n- Active segment has distinct background (accent color or elevated surface)\n- Smooth transition between states (use vars.animation.duration.fast)\n- Keyboard navigation: arrow keys to move between options\n- Focus visible state on the entire group and active segment\n\n### CSS Variables to Use\n- `vars.color.surface` - Inactive segment background\n- `vars.color.accent` or `vars.color.backgroundAlt` - Active segment\n- `vars.color.border` - Shared border between segments\n- `vars.radius.md` - Corner radius for first/last segments\n- `vars.spacing.2`, `vars.spacing.3` - Internal padding\n\n### Accessibility\n- Role: `radiogroup` on container\n- Each segment: `role=\"radio\"`, `aria-checked`\n- Keyboard: Arrow keys navigate, Enter/Space select\n- Focus management: Roving tabindex pattern\n\n### Files to Create\n1. `SegmentedControl.tsx` - Main component\n2. `SegmentedControl.css.ts` - vanilla-extract styles\n3. `index.ts` - Barrel export\n4. `SegmentedControl.test.tsx` - Unit tests\n\n### Test Cases\n- Renders all options\n- Correct option selected on mount\n- onChange called with correct value on click\n- Keyboard navigation (arrow keys)\n- Disabled state (entire control and individual options)\n- Accessibility attributes present\n\n## Implementation Reference\nSimilar components for reference:\n- Radix UI ToggleGroup: https://www.radix-ui.com/primitives/docs/components/toggle-group\n- Headless UI RadioGroup: https://headlessui.com/react/radio-group\n\n## Parallel Safe\nYes - no dependencies on other tasks. Can be built independently.\n\n## Files\n- packages/design-system/src/primitives/SegmentedControl/SegmentedControl.tsx\n- packages/design-system/src/primitives/SegmentedControl/SegmentedControl.css.ts\n- packages/design-system/src/primitives/SegmentedControl/index.ts\n- packages/design-system/src/primitives/SegmentedControl/SegmentedControl.test.tsx\n- packages/design-system/src/index.ts (add export)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T14:56:09.88867-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.10","title":"Implement theme setting with SegmentedControl","description":"# Implement Theme Setting with SegmentedControl\n\n## What\nBuild the theme setting UI using the new SegmentedControl component, integrating with the existing useTheme hook.\n\n## Why\n- **Core Settings Feature**: Theme switching is one of the most commonly used settings\n- **Demonstrates SegmentedControl**: First real usage of the new primitive\n- **Leverages Existing Infrastructure**: useTheme hook already handles persistence and system preference detection\n\n## Technical Approach\n\n### Component Implementation\n```tsx\n// ThemeSetting.tsx (or inline in GeneralSettings.tsx)\nimport { SegmentedControl } from '@scribe/design-system';\nimport { useTheme } from '@scribe/design-system';\n\nexport function ThemeSetting() {\n  const { theme, setTheme } = useTheme();\n  \n  const options = [\n    { value: 'dark', label: 'Dark' },\n    { value: 'light', label: 'Light' },\n    { value: 'system', label: 'System' },\n  ];\n  \n  return (\n    \u003cSegmentedControl\n      options={options}\n      value={theme}\n      onChange={setTheme}\n      aria-label=\"Theme preference\"\n    /\u003e\n  );\n}\n```\n\n### Integration with GeneralSettings\n```tsx\n// In GeneralSettings.tsx\n\u003cSettingsGroup title=\"Theme\"\u003e\n  \u003cThemeSetting /\u003e\n\u003c/SettingsGroup\u003e\n```\n\n### Behavior\n- **Immediate Apply**: Theme changes instantly when user clicks a segment\n- **Persistence**: useTheme hook already persists to config.json via ThemeStorage adapter\n- **System Detection**: \"System\" option follows OS dark/light preference via media query\n\n### Existing Infrastructure (No Changes Needed)\nThe useTheme hook already provides:\n```typescript\ninterface ThemeContextValue {\n  theme: Theme;                        // User's preference ('dark' | 'light' | 'system')\n  resolvedTheme: 'light' | 'dark';     // Actual applied theme\n  setTheme: (theme: Theme) =\u003e void;    // Persists and applies\n}\n```\n\nThe ThemeProvider already:\n- Loads from config.json on mount\n- Saves to config.json on change\n- Listens to `prefers-color-scheme: dark` media query\n- Applies theme class to document.documentElement\n\n### UX Considerations\n- **Visual Feedback**: Active segment should clearly stand out\n- **System Label**: Consider showing \"(Dark)\" or \"(Light)\" next to \"System\" to indicate resolved value\n- **No Confirmation**: Changes apply immediately, no save button needed\n\n### Enhanced: Show Resolved Theme for System\n```tsx\nexport function ThemeSetting() {\n  const { theme, resolvedTheme, setTheme } = useTheme();\n  \n  const options = [\n    { value: 'dark', label: 'Dark' },\n    { value: 'light', label: 'Light' },\n    { \n      value: 'system', \n      label: theme === 'system' \n        ? `System (${resolvedTheme === 'dark' ? 'Dark' : 'Light'})` \n        : 'System' \n    },\n  ];\n  \n  return (\n    \u003cSegmentedControl\n      options={options}\n      value={theme}\n      onChange={setTheme}\n      aria-label=\"Theme preference\"\n    /\u003e\n  );\n}\n```\n\n## BLOCKED BY\n- scribe-roo.1 (SegmentedControl primitive) - Need the component\n- scribe-roo.8 (GeneralSettings structure) - Need the container\n\n## Files\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx (add ThemeSetting)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.513271-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.11","title":"Implement version display and update checking UI","description":"# Implement Version Display and Update Checking UI\n\n## What\nBuild the version and update checking section in GeneralSettings, showing current version and providing update management.\n\n## Why\n- **User Visibility**: Users should know what version they're running\n- **Update Management**: Centralized place for checking and installing updates\n- **Leverages Existing Hook**: useUpdateStatus already tracks all update states\n\n## Technical Approach\n\n### Component Implementation\n```tsx\n// VersionSetting.tsx\nimport { Button, Text } from '@scribe/design-system';\nimport { useUpdateStatus } from '../../../hooks/useUpdateStatus';\n\nexport function VersionSetting() {\n  const { status, version, error, installUpdate } = useUpdateStatus();\n  \n  const checkForUpdates = () =\u003e {\n    window.scribe.update.check();\n  };\n  \n  return (\n    \u003cdiv className={styles.versionSetting}\u003e\n      \u003cText variant=\"body\"\u003ev{__APP_VERSION__}\u003c/Text\u003e\n      \n      \u003cdiv className={styles.updateControls}\u003e\n        {renderUpdateButton()}\n        {renderStatusMessage()}\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n  \n  function renderUpdateButton() {\n    switch (status) {\n      case 'idle':\n        return \u003cButton onClick={checkForUpdates}\u003eCheck for Updates\u003c/Button\u003e;\n      case 'checking':\n        return \u003cButton disabled\u003eChecking...\u003c/Button\u003e;\n      case 'downloading':\n        return \u003cButton disabled\u003eDownloading...\u003c/Button\u003e;\n      case 'ready':\n        return \u003cButton onClick={installUpdate}\u003eRestart to Update\u003c/Button\u003e;\n      case 'error':\n        return \u003cButton onClick={checkForUpdates}\u003eRetry Check\u003c/Button\u003e;\n    }\n  }\n  \n  function renderStatusMessage() {\n    switch (status) {\n      case 'ready':\n        return \u003cText variant=\"body\" color=\"success\"\u003eUpdate ready: v{version}\u003c/Text\u003e;\n      case 'error':\n        return \u003cText variant=\"body\" color=\"danger\"\u003e{error}\u003c/Text\u003e;\n      default:\n        return null;\n    }\n  }\n}\n```\n\n### State Machine (from useUpdateStatus)\n```\nidle -\u003e checking -\u003e downloading -\u003e ready\n  |        |            |           |\n  v        v            v           v\nerror   (idle)       (idle)     (restart)\n```\n\n### Update Flow\n1. **Idle**: Show \"Check for Updates\" button\n2. **Checking**: Show \"Checking...\" (disabled)\n3. **Downloading**: Show \"Downloading...\" (disabled)\n4. **Ready**: Show \"Restart to Update\" (enabled, calls installUpdate)\n5. **Error**: Show error message, \"Retry Check\" button\n\n### After \"No Update Available\"\nThe useUpdateStatus hook returns to 'idle' when no update is found. We could enhance to show a brief \"You're up to date\" message:\n```tsx\nconst [lastCheckResult, setLastCheckResult] = useState\u003c'none' | 'up-to-date' | null\u003e(null);\n\n// After checking completes with no update\nuseEffect(() =\u003e {\n  if (status === 'idle' \u0026\u0026 lastStatus === 'checking') {\n    setLastCheckResult('up-to-date');\n    setTimeout(() =\u003e setLastCheckResult(null), 3000);\n  }\n}, [status]);\n```\n\n### Toast on Download Complete\nThe spec mentions showing the existing toast notification when download completes. This already happens via UpdateToast component in App.tsx. No changes needed.\n\n### Styling\n```typescript\n// Add to GeneralSettings.css.ts\nexport const versionSetting = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[2],\n});\n\nexport const updateControls = style({\n  display: 'flex',\n  alignItems: 'center',\n  gap: vars.spacing[3],\n});\n```\n\n## BLOCKED BY\n- scribe-roo.8 (GeneralSettings structure) - Need the container\n\n## Files\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx (add VersionSetting)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.581522-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.12","title":"Create useVaultPath hook for vault state management","description":"# Create useVaultPath Hook for Vault State Management\n\n## What\nCreate a custom hook that manages vault path state: fetching current path, tracking loading/error states, and providing methods to change vaults.\n\n## Why\n- **Centralized Vault State**: Keep vault-related state and logic in one place\n- **Loading States**: Handle async vault operations gracefully\n- **Error Handling**: Manage validation errors from vault switching\n- **Reusability**: Can be used in GeneralSettings and potentially elsewhere\n\n## Technical Approach\n\n### Hook API\n```typescript\n// useVaultPath.ts\nexport interface UseVaultPathReturn {\n  // Current vault state\n  path: string | null;\n  isLoading: boolean;\n  error: string | null;\n  \n  // Actions\n  refresh: () =\u003e Promise\u003cvoid\u003e;\n  setVaultPath: (newPath: string) =\u003e Promise\u003cVaultSwitchResult\u003e;\n  createVault: (newPath: string) =\u003e Promise\u003cVaultCreateResult\u003e;\n  validatePath: (path: string) =\u003e Promise\u003cVaultValidationResult\u003e;\n  \n  // Derived state\n  isValid: boolean;\n}\n\nexport function useVaultPath(): UseVaultPathReturn {\n  const [path, setPath] = useState\u003cstring | null\u003e(null);\n  const [isLoading, setIsLoading] = useState(true);\n  const [error, setError] = useState\u003cstring | null\u003e(null);\n  \n  // Fetch current vault path on mount\n  useEffect(() =\u003e {\n    refresh();\n  }, []);\n  \n  const refresh = useCallback(async () =\u003e {\n    setIsLoading(true);\n    setError(null);\n    try {\n      const currentPath = await window.scribe.vault.getPath();\n      setPath(currentPath);\n    } catch (err) {\n      setError('Failed to load vault path');\n    } finally {\n      setIsLoading(false);\n    }\n  }, []);\n  \n  const setVaultPath = useCallback(async (newPath: string) =\u003e {\n    setIsLoading(true);\n    setError(null);\n    try {\n      const result = await window.scribe.vault.setPath(newPath);\n      if (result.success) {\n        setPath(result.path);\n      } else {\n        setError(result.error || 'Failed to switch vault');\n      }\n      return result;\n    } catch (err) {\n      const errorMsg = 'Failed to switch vault';\n      setError(errorMsg);\n      return { success: false, path: newPath, error: errorMsg };\n    } finally {\n      setIsLoading(false);\n    }\n  }, []);\n  \n  const createVault = useCallback(async (newPath: string) =\u003e {\n    setIsLoading(true);\n    setError(null);\n    try {\n      const result = await window.scribe.vault.create(newPath);\n      if (result.success) {\n        setPath(result.path);\n      } else {\n        setError(result.error || 'Failed to create vault');\n      }\n      return result;\n    } catch (err) {\n      const errorMsg = 'Failed to create vault';\n      setError(errorMsg);\n      return { success: false, path: newPath, error: errorMsg };\n    } finally {\n      setIsLoading(false);\n    }\n  }, []);\n  \n  const validatePath = useCallback(async (pathToValidate: string) =\u003e {\n    try {\n      return await window.scribe.vault.validate(pathToValidate);\n    } catch {\n      return { valid: false, missingDirs: ['unknown'] };\n    }\n  }, []);\n  \n  return {\n    path,\n    isLoading,\n    error,\n    refresh,\n    setVaultPath,\n    createVault,\n    validatePath,\n    isValid: path !== null \u0026\u0026 !error,\n  };\n}\n```\n\n### Usage in GeneralSettings\n```tsx\nfunction VaultLocationSetting() {\n  const { path, isLoading, error, setVaultPath, createVault } = useVaultPath();\n  \n  if (isLoading \u0026\u0026 !path) {\n    return \u003cText variant=\"body\" color=\"muted\"\u003eLoading...\u003c/Text\u003e;\n  }\n  \n  return (\n    \u003cdiv\u003e\n      \u003cText variant=\"code\"\u003e{path}\u003c/Text\u003e\n      {error \u0026\u0026 \u003cText variant=\"body\" color=\"danger\"\u003e{error}\u003c/Text\u003e}\n      \u003cdiv className={styles.vaultButtons}\u003e\n        \u003cButton onClick={handleChange}\u003eChange\u003c/Button\u003e\n        \u003cButton onClick={handleCreateNew}\u003eCreate New\u003c/Button\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Error States\nThe hook tracks:\n- **Load errors**: Failed to fetch current path\n- **Switch errors**: Invalid vault, permission denied\n- **Create errors**: Path exists, permission denied\n\n## BLOCKED BY\n- scribe-roo.3 (Vault IPC handlers) - Need window.scribe.vault API\n\n## UNBLOCKS\n- scribe-roo.13 (Vault path display)\n- scribe-roo.15 (Vault switching UI)\n- scribe-roo.16 (Create new vault)\n\n## Files\n- apps/desktop/renderer/src/hooks/useVaultPath.ts (NEW)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.649771-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.13","title":"Implement vault path display (read-only)","description":"# Implement Vault Path Display (Read-Only)\n\n## What\nDisplay the current vault path in GeneralSettings. This is the first step before implementing full vault switching.\n\n## Why\n- **User Visibility**: Users should know where their notes are stored\n- **Incremental Delivery**: Ship read-only display before full switching capability\n- **Foundation**: UI structure needed for vault management buttons\n\n## Technical Approach\n\n### Component Implementation\n```tsx\n// VaultLocationSetting.tsx\nimport { Text, Button } from '@scribe/design-system';\nimport { useVaultPath } from '../../../hooks/useVaultPath';\n\nexport function VaultLocationSetting() {\n  const { path, isLoading, error } = useVaultPath();\n  \n  if (isLoading) {\n    return (\n      \u003cdiv className={styles.vaultLocation}\u003e\n        \u003cText variant=\"body\" color=\"muted\"\u003eLoading vault path...\u003c/Text\u003e\n      \u003c/div\u003e\n    );\n  }\n  \n  if (error) {\n    return (\n      \u003cdiv className={styles.vaultLocation}\u003e\n        \u003cText variant=\"body\" color=\"danger\"\u003e{error}\u003c/Text\u003e\n      \u003c/div\u003e\n    );\n  }\n  \n  return (\n    \u003cdiv className={styles.vaultLocation}\u003e\n      \u003cText variant=\"code\" className={styles.vaultPath}\u003e\n        {path}\n      \u003c/Text\u003e\n      \n      \u003cdiv className={styles.vaultActions}\u003e\n        \u003cButton variant=\"secondary\" disabled\u003e\n          Change\n        \u003c/Button\u003e\n        \u003cButton variant=\"secondary\" disabled\u003e\n          Create New\n        \u003c/Button\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Path Display Styling\n```typescript\n// Add to GeneralSettings.css.ts\nexport const vaultLocation = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[3],\n});\n\nexport const vaultPath = style({\n  fontFamily: 'var(--font-mono)',\n  backgroundColor: vars.color.backgroundAlt,\n  padding: `${vars.spacing[2]} ${vars.spacing[3]}`,\n  borderRadius: vars.radius.sm,\n  wordBreak: 'break-all',  // Handle long paths\n});\n\nexport const vaultActions = style({\n  display: 'flex',\n  gap: vars.spacing[2],\n});\n```\n\n### Initial State (Buttons Disabled)\nFor this task, buttons are disabled placeholders. They'll be enabled in subsequent tasks:\n- **Change**: Enabled in scribe-roo.15\n- **Create New**: Enabled in scribe-roo.16\n\n### Path Truncation (Optional)\nFor very long paths, consider truncating with ellipsis in the middle:\n```typescript\nfunction truncatePath(path: string, maxLength = 50): string {\n  if (path.length \u003c= maxLength) return path;\n  \n  const start = path.slice(0, 20);\n  const end = path.slice(-25);\n  return `${start}...${end}`;\n}\n```\n\nOr use CSS text-overflow with a title attribute for full path on hover.\n\n### Accessibility\n- Path should be selectable for copy/paste\n- Consider adding a \"Copy path\" button for convenience\n\n## BLOCKED BY\n- scribe-roo.8 (GeneralSettings structure) - Need the container\n- scribe-roo.12 (useVaultPath hook) - Need the data hook\n\n## UNBLOCKS\n- scribe-roo.15 (Vault switching UI)\n\n## Files\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx (add VaultLocationSetting)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.718636-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.14","title":"Implement vault switching backend (restart-based MVP)","description":"# Implement Vault Switching (Restart Required - MVP)\n\n## What\nImplement vault switching that requires an app restart. This is the **safe MVP approach** - full hot-reload is a stretch goal in a separate task.\n\n## Why\n- **Lower Risk**: App restart is a known-safe state transition\n- **Simpler Implementation**: No engine cleanup/re-initialization logic needed\n- **User Acceptable**: Most settings changes in desktop apps require restart\n- **Foundation**: Config persistence is needed for hot-reload anyway\n\n## Technical Approach\n\n### Implementation (Simple)\n```typescript\n// In vaultHandlers.ts\nipcMain.handle(IPC_CHANNELS.VAULT_SET_PATH, async (_, newPath: string) =\u003e {\n  // 1. Validate the new path is a valid vault\n  const isValid = await isValidVault(newPath);\n  if (!isValid) {\n    return { \n      success: false, \n      path: newPath, \n      error: 'Not a valid Scribe vault. Missing required folders.' \n    };\n  }\n  \n  // 2. Save new path to config\n  const config = await loadConfig();\n  await saveConfig({ ...config, vaultPath: newPath });\n  \n  // 3. Return success with restart required flag\n  return { \n    success: true, \n    path: newPath, \n    requiresRestart: true \n  };\n});\n```\n\n### UI Flow\n1. User selects new vault via folder picker\n2. System validates it's a valid vault\n3. If valid: Save path to config, show \"Restart Required\" dialog\n4. User clicks \"Restart Now\" → app.relaunch() + app.exit()\n5. On restart, app loads with new vault path from config\n\n### Config Integration\n```typescript\n// AppConfig extension\ninterface AppConfig {\n  lastOpenedNoteId?: string;\n  theme?: 'light' | 'dark' | 'system';\n  vaultPath?: string;  // NEW\n}\n```\n\n### Restart Dialog\n```tsx\n// In GeneralSettings after successful vault switch\n\u003cDialog\u003e\n  \u003cDialogTitle\u003eRestart Required\u003c/DialogTitle\u003e\n  \u003cDialogContent\u003e\n    Scribe needs to restart to switch to the new vault.\n  \u003c/DialogContent\u003e\n  \u003cDialogActions\u003e\n    \u003cButton onClick={handleRestartLater}\u003eLater\u003c/Button\u003e\n    \u003cButton onClick={handleRestartNow} variant=\"primary\"\u003eRestart Now\u003c/Button\u003e\n  \u003c/DialogActions\u003e\n\u003c/Dialog\u003e\n```\n\n### Main Process: Load Vault from Config\n```typescript\n// In main.ts initialization\nconst config = await loadConfig();\nconst vaultPath = config.vaultPath || getDefaultVaultPath();\nconst vault = new FileSystemVault(createVaultPath(vaultPath));\n```\n\n## Scope\n- Vault path validation ✓\n- Config persistence ✓\n- Restart dialog UI ✓\n- app.relaunch() integration ✓\n- **NOT in scope**: Engine hot-reload (separate stretch goal task)\n\n## Files\n- apps/desktop/electron/main/src/handlers/vaultHandlers.ts\n- apps/desktop/electron/main/src/main.ts (load vault from config)\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx (restart dialog)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T14:56:10.788654-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.15","title":"Implement vault switching UI with validation","description":"# Implement Vault Switching UI with Validation\n\n## What\nEnable the \"Change\" button in vault settings, allowing users to select and switch to a different vault folder. Uses the restart-based approach (not hot-reload).\n\n## Why\n- **Primary Vault Management Feature**: Users need to switch between vaults\n- **Validation Feedback**: Clear errors when selected folder isn't a valid vault\n- **Complete User Flow**: From folder selection to restart prompt\n\n## Technical Approach\n\n### UI Flow (Restart-Based)\n1. User clicks \"Change\" button\n2. Native folder picker opens (via dialog:selectFolder)\n3. User selects a folder\n4. System validates the folder is a valid vault\n5. If invalid: Show inline error message\n6. If valid: Save to config, show restart dialog\n7. User clicks \"Restart Now\" or \"Later\"\n\n### Component Implementation\n```tsx\nfunction VaultLocationSetting() {\n  const [currentPath, setCurrentPath] = useState\u003cstring | null\u003e(null);\n  const [validationError, setValidationError] = useState\u003cstring | null\u003e(null);\n  const [showRestartDialog, setShowRestartDialog] = useState(false);\n  \n  // Load current vault path on mount\n  useEffect(() =\u003e {\n    window.scribe.vault.getPath().then(setCurrentPath);\n  }, []);\n  \n  const handleChangeVault = async () =\u003e {\n    setValidationError(null);\n    \n    // 1. Open folder picker\n    const selectedPath = await window.scribe.dialog.selectFolder({\n      title: 'Select Scribe Vault',\n      defaultPath: currentPath || undefined,\n    });\n    \n    if (!selectedPath) return; // User cancelled\n    \n    // 2. Validate and set path (handler does validation)\n    const result = await window.scribe.vault.setPath(selectedPath);\n    \n    if (!result.success) {\n      setValidationError(result.error || 'Failed to switch vault');\n      return;\n    }\n    \n    // 3. Show restart dialog\n    if (result.requiresRestart) {\n      setShowRestartDialog(true);\n    }\n  };\n  \n  return (\n    \u003cdiv\u003e\n      \u003cText variant=\"code\"\u003e{currentPath}\u003c/Text\u003e\n      {validationError \u0026\u0026 \u003cText color=\"danger\"\u003e{validationError}\u003c/Text\u003e}\n      \u003cButton onClick={handleChangeVault}\u003eChange\u003c/Button\u003e\n      \n      {showRestartDialog \u0026\u0026 (\n        \u003cRestartDialog \n          onRestartNow={() =\u003e window.scribe.app.relaunch()}\n          onLater={() =\u003e setShowRestartDialog(false)}\n        /\u003e\n      )}\n    \u003c/div\u003e\n  );\n}\n```\n\n### Restart Dialog\n```tsx\nfunction RestartDialog({ onRestartNow, onLater }) {\n  return (\n    \u003cOverlay open onClose={onLater}\u003e\n      \u003cSurface\u003e\n        \u003cText variant=\"heading3\"\u003eRestart Required\u003c/Text\u003e\n        \u003cText\u003eScribe needs to restart to use the new vault.\u003c/Text\u003e\n        \u003cdiv\u003e\n          \u003cButton variant=\"secondary\" onClick={onLater}\u003eLater\u003c/Button\u003e\n          \u003cButton variant=\"primary\" onClick={onRestartNow}\u003eRestart Now\u003c/Button\u003e\n        \u003c/div\u003e\n      \u003c/Surface\u003e\n    \u003c/Overlay\u003e\n  );\n}\n```\n\n### Error Messages (per spec)\n- Invalid vault: \"Not a valid Scribe vault. Missing required folders.\"\n\n## Dependencies\n- scribe-roo.2 (Folder picker IPC) - Need dialog:selectFolder\n- scribe-roo.3 (Vault IPC handlers) - Need vault:setPath, vault:validate  \n- scribe-roo.13 (Vault display) - Need existing UI structure\n- scribe-roo.14 (Vault switching backend) - Need restart-based switching logic\n\nNote: Does NOT require hot-reload (scribe-roo.19). Restart is acceptable for MVP.\n\n## Files\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.857309-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.16","title":"Implement create new vault functionality","description":"# Implement Create New Vault Functionality\n\n## What\nEnable the \"Create New\" button to create a fresh vault at a user-selected location, then prompt for restart.\n\n## Why\n- **New User Onboarding**: First-time users need to create their initial vault\n- **Multiple Vaults**: Power users may want separate vaults for different purposes\n\n## Technical Approach\n\n### UI Flow (Restart-Based)\n1. User clicks \"Create New\" button\n2. Native folder picker opens\n3. User selects a location\n4. System calls vault:create to initialize vault structure\n5. If success: Show restart dialog\n6. On restart: App loads with new vault\n\n### Component Implementation\n```tsx\nconst handleCreateVault = async () =\u003e {\n  const selectedPath = await window.scribe.dialog.selectFolder({\n    title: 'Choose Location for New Vault',\n  });\n  \n  if (!selectedPath) return;\n  \n  const result = await window.scribe.vault.create(selectedPath);\n  \n  if (!result.success) {\n    setCreationError(result.error);\n    return;\n  }\n  \n  // Show restart dialog (vault:create sets config)\n  setShowRestartDialog(true);\n};\n```\n\n### Backend Handler\n```typescript\nipcMain.handle(IPC_CHANNELS.VAULT_CREATE, async (_, path: string) =\u003e {\n  // Check if vault already exists\n  const exists = await isValidVault(path);\n  if (exists) {\n    return { success: false, error: 'A vault already exists here' };\n  }\n  \n  // Create vault structure\n  await initializeVault(createVaultPath(path));\n  \n  // Save to config for restart\n  await saveConfig({ ...config, vaultPath: path });\n  \n  return { success: true, path, requiresRestart: true };\n});\n```\n\n### Vault Structure Created\n```\nselected-path/\n├── notes/\n└── quarantine/\n```\n\n## Dependencies\n- scribe-roo.2 (Folder picker)\n- scribe-roo.3 (Vault IPC)\n- scribe-roo.14 (Vault switching backend - for config persistence)\n- scribe-roo.15 (Vault switching UI - for restart dialog pattern)\n\n## Files\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx\n- apps/desktop/electron/main/src/handlers/vaultHandlers.ts","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.927967-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.17","title":"Add integration tests for Settings page","description":"# Add Integration Tests for Settings Page\n\n## What\nCreate comprehensive integration tests for the Settings page functionality.\n\n## Why\n- **Confidence**: Ensure settings page works end-to-end\n- **Regression Prevention**: Catch breaking changes in future updates\n- **Documentation**: Tests serve as living documentation of expected behavior\n\n## Technical Approach\n\n### Test Structure\n```typescript\n// settings.integration.test.ts\ndescribe('Settings Page', () =\u003e {\n  describe('Opening/Closing', () =\u003e {\n    it('opens settings when gear icon is clicked');\n    it('closes settings when X button is clicked');\n    it('closes settings when Escape key is pressed');\n    it('opens with General section selected by default');\n  });\n  \n  describe('Section Navigation', () =\u003e {\n    it('switches to Changelog section when clicked');\n    it('switches back to General section when clicked');\n    it('maintains section selection while open');\n  });\n  \n  describe('Theme Setting', () =\u003e {\n    it('displays current theme selection');\n    it('changes theme to Dark when Dark segment clicked');\n    it('changes theme to Light when Light segment clicked');\n    it('changes theme to System when System segment clicked');\n    it('persists theme selection after closing settings');\n  });\n  \n  describe('Version Setting', () =\u003e {\n    it('displays current app version');\n    it('shows Check for Updates button in idle state');\n    it('shows Checking... when update check in progress');\n    it('shows Restart to Update when update ready');\n  });\n  \n  describe('Vault Location', () =\u003e {\n    it('displays current vault path');\n    it('opens folder picker when Change button clicked');\n    it('shows error for invalid vault selection');\n    it('switches vault when valid vault selected');\n    it('creates new vault when Create New selected');\n  });\n});\n```\n\n### Test Setup\n```typescript\n// Test setup with mock vault\nbeforeEach(async () =\u003e {\n  testContext = await setupTestContext();\n  // Create test vaults for switching tests\n  testVault1 = await createTestVault('vault-1');\n  testVault2 = await createTestVault('vault-2');\n});\n\nafterEach(async () =\u003e {\n  await cleanupTestContext(testContext);\n  await cleanupTestVault(testVault1);\n  await cleanupTestVault(testVault2);\n});\n```\n\n### Key Test Scenarios\n\n#### Theme Switching\n```typescript\nit('changes theme to Dark when Dark segment clicked', async () =\u003e {\n  // Open settings\n  await clickGearIcon();\n  \n  // Click Dark segment\n  const darkSegment = screen.getByRole('radio', { name: /dark/i });\n  await userEvent.click(darkSegment);\n  \n  // Verify theme changed\n  expect(document.documentElement.classList.contains('darkTheme')).toBe(true);\n  \n  // Verify persisted to config\n  const config = await window.scribe.app.getConfig();\n  expect(config.theme).toBe('dark');\n});\n```\n\n#### Vault Switching\n```typescript\nit('switches vault when valid vault selected', async () =\u003e {\n  // Mock folder picker to return testVault2 path\n  vi.spyOn(window.scribe.dialog, 'selectFolder').mockResolvedValue(testVault2.path);\n  \n  // Open settings and click Change\n  await clickGearIcon();\n  await userEvent.click(screen.getByText('Change'));\n  \n  // Wait for switch to complete\n  await waitFor(() =\u003e {\n    expect(screen.getByText(testVault2.path)).toBeInTheDocument();\n  });\n  \n  // Verify note list refreshed\n  const notes = await window.scribe.notes.list();\n  expect(notes).toEqual(testVault2.expectedNotes);\n});\n```\n\n#### Invalid Vault Error\n```typescript\nit('shows error for invalid vault selection', async () =\u003e {\n  // Mock folder picker to return invalid path\n  const invalidPath = '/tmp/not-a-vault';\n  vi.spyOn(window.scribe.dialog, 'selectFolder').mockResolvedValue(invalidPath);\n  \n  // Open settings and click Change\n  await clickGearIcon();\n  await userEvent.click(screen.getByText('Change'));\n  \n  // Verify error shown\n  expect(screen.getByText(/not a valid scribe vault/i)).toBeInTheDocument();\n  \n  // Verify vault path unchanged\n  expect(screen.getByText(testVault1.path)).toBeInTheDocument();\n});\n```\n\n### Test Coverage Goals\n- All happy paths for settings interactions\n- Error states for vault operations\n- Keyboard navigation (Escape to close)\n- State persistence (theme, vault path)\n- UI state management (loading, disabled buttons)\n\n## BLOCKED BY\n- scribe-roo.7 (App.tsx integration) - Need complete Settings page\n- scribe-roo.15 (Vault switching UI) - Need vault switching implemented\n- scribe-roo.16 (Create new vault) - Need vault creation implemented\n\n## Files\n- apps/desktop/settings.integration.test.ts (NEW)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.99816-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.18","title":"Add unit tests for vault IPC handlers","description":"# Add Unit Tests for Vault IPC Handlers\n\n## What\nCreate unit tests for the vault IPC handlers (vault:getPath, vault:setPath, vault:create, vault:validate).\n\n## Why\n- **Isolated Testing**: Test main process logic without full app\n- **Error Scenarios**: Easy to simulate error conditions\n- **Fast Feedback**: Unit tests run much faster than integration tests\n\n## Technical Approach\n\n### Test Structure\n```typescript\n// vaultHandlers.test.ts\nimport { describe, it, expect, vi, beforeEach } from 'vitest';\nimport { registerVaultHandlers } from './vaultHandlers';\nimport * as vaultModule from '@scribe/storage-fs';\n\n// Mock ipcMain\nconst mockIpcMain = {\n  handle: vi.fn(),\n};\n\ndescribe('Vault Handlers', () =\u003e {\n  beforeEach(() =\u003e {\n    vi.clearAllMocks();\n  });\n  \n  describe('vault:getPath', () =\u003e {\n    it('returns current vault path from config');\n    it('returns default path if none configured');\n  });\n  \n  describe('vault:validate', () =\u003e {\n    it('returns valid:true for valid vault');\n    it('returns valid:false with missing dirs for invalid vault');\n    it('handles non-existent path gracefully');\n  });\n  \n  describe('vault:setPath', () =\u003e {\n    it('validates path before saving');\n    it('returns error for invalid vault');\n    it('saves new path to config on success');\n    it('returns requiresRestart: true on success');\n  });\n  \n  describe('vault:create', () =\u003e {\n    it('returns error if vault already exists');\n    it('calls initializeVault for new path');\n    it('saves path to config after creation');\n    it('returns requiresRestart: true on success');\n    it('returns error if creation fails');\n    it('handles permission denied gracefully');\n  });\n});\n```\n\n### Mock Setup\n```typescript\nconst mockConfig = {\n  vaultPath: '/mock/vault',\n};\n\n// Mock storage-fs module\nvi.mock('@scribe/storage-fs', () =\u003e ({\n  isValidVault: vi.fn(),\n  initializeVault: vi.fn(),\n  createVaultPath: vi.fn((p) =\u003e p),\n}));\n\n// Mock config module\nvi.mock('./config', () =\u003e ({\n  loadConfig: vi.fn(() =\u003e mockConfig),\n  saveConfig: vi.fn(),\n}));\n```\n\n### Key Test Cases\n\n#### vault:validate\n```typescript\nit('returns valid:false with missing dirs for invalid vault', async () =\u003e {\n  vi.mocked(vaultModule.isValidVault).mockResolvedValue(false);\n  \n  const handler = getRegisteredHandler('vault:validate');\n  const result = await handler({}, '/some/path');\n  \n  expect(result).toEqual({\n    valid: false,\n    missingDirs: ['notes', 'quarantine'],\n  });\n});\n```\n\n#### vault:setPath (MVP - restart-based)\n```typescript\nit('saves new path to config and returns requiresRestart', async () =\u003e {\n  vi.mocked(vaultModule.isValidVault).mockResolvedValue(true);\n  \n  const handler = getRegisteredHandler('vault:setPath');\n  const result = await handler({}, '/new/path');\n  \n  expect(saveConfig).toHaveBeenCalledWith(\n    expect.objectContaining({ vaultPath: '/new/path' })\n  );\n  expect(result).toEqual({ \n    success: true, \n    path: '/new/path',\n    requiresRestart: true \n  });\n});\n\nit('returns error for invalid vault without saving', async () =\u003e {\n  vi.mocked(vaultModule.isValidVault).mockResolvedValue(false);\n  \n  const handler = getRegisteredHandler('vault:setPath');\n  const result = await handler({}, '/invalid/path');\n  \n  expect(saveConfig).not.toHaveBeenCalled();\n  expect(result).toEqual({\n    success: false,\n    path: '/invalid/path',\n    error: 'Not a valid Scribe vault. Missing required folders.',\n  });\n});\n```\n\n#### vault:create\n```typescript\nit('returns error if vault already exists', async () =\u003e {\n  vi.mocked(vaultModule.isValidVault).mockResolvedValue(true);\n  \n  const handler = getRegisteredHandler('vault:create');\n  const result = await handler({}, '/existing/vault');\n  \n  expect(vaultModule.initializeVault).not.toHaveBeenCalled();\n  expect(result).toEqual({\n    success: false,\n    path: '/existing/vault',\n    error: 'A vault already exists at this location',\n  });\n});\n\nit('creates vault, saves config, and returns requiresRestart', async () =\u003e {\n  vi.mocked(vaultModule.isValidVault).mockResolvedValue(false);\n  vi.mocked(vaultModule.initializeVault).mockResolvedValue(undefined);\n  \n  const handler = getRegisteredHandler('vault:create');\n  const result = await handler({}, '/new/vault');\n  \n  expect(vaultModule.initializeVault).toHaveBeenCalledWith('/new/vault');\n  expect(saveConfig).toHaveBeenCalledWith(\n    expect.objectContaining({ vaultPath: '/new/vault' })\n  );\n  expect(result).toEqual({\n    success: true,\n    path: '/new/vault',\n    requiresRestart: true,\n  });\n});\n\nit('handles permission denied gracefully', async () =\u003e {\n  vi.mocked(vaultModule.isValidVault).mockResolvedValue(false);\n  vi.mocked(vaultModule.initializeVault).mockRejectedValue(\n    new Error('EACCES: permission denied')\n  );\n  \n  const handler = getRegisteredHandler('vault:create');\n  const result = await handler({}, '/protected/path');\n  \n  expect(result).toEqual({\n    success: false,\n    path: '/protected/path',\n    error: expect.stringContaining('permission'),\n  });\n});\n```\n\n### Helper Function\n```typescript\nfunction getRegisteredHandler(channel: string) {\n  const call = mockIpcMain.handle.mock.calls.find(\n    ([c]) =\u003e c === channel\n  );\n  if (!call) throw new Error(\\`Handler for ${channel} not registered\\`);\n  return call[1];\n}\n```\n\n## BLOCKED BY\n- scribe-roo.3 (Vault IPC handlers) - Need handlers to test\n\n## Files\n- apps/desktop/electron/main/src/handlers/vaultHandlers.test.ts (NEW)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T14:56:11.070483-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.19","title":"Implement engine hot-reload for vault switching (stretch goal)","description":"# Engine Hot-Reload for Vault Switching (Stretch Goal)\n\n## What\nEnable switching vaults at runtime without requiring an app restart. This is a **stretch goal** that builds on the MVP restart-based approach.\n\n## Why\n- **Better UX**: No restart interruption\n- **Power User Feature**: Frequent vault switchers benefit\n- **Technical Achievement**: Shows robust engine architecture\n\n## Prerequisites\n- [deleted:[deleted:scribe-roo].14] (restart-based switching) must be complete first\n- All other Settings page features working\n\n## Technical Approach\n\n### EngineOrchestrator.switchVault()\n```typescript\nasync switchVault(newVaultPath: string): Promise\u003cVaultSwitchResult\u003e {\n  // 1. Validate new vault\n  const isValid = await isValidVault(newVaultPath);\n  if (!isValid) {\n    return { success: false, error: 'Not a valid vault' };\n  }\n  \n  // 2. Cleanup existing engines\n  await this.shutdown();\n  \n  // 3. Create new vault instance\n  this.vault = new FileSystemVault(createVaultPath(newVaultPath));\n  await this.vault.load();\n  \n  // 4. Re-initialize engines\n  this.graphEngine = new GraphEngine();\n  this.searchEngine = new SearchEngine();\n  this.taskIndex = new TaskIndex(...);\n  \n  // 5. Rebuild indexes\n  await this.initialize();\n  \n  return { success: true, path: newVaultPath };\n}\n```\n\n### Renderer Notification\n```typescript\n// Main process after switch\nBrowserWindow.getAllWindows().forEach(win =\u003e {\n  win.webContents.send('vault:switched', { path: newVaultPath });\n});\n\n// Renderer subscription\nuseEffect(() =\u003e {\n  return window.scribe.vault.onSwitched((newPath) =\u003e {\n    // Clear current note\n    // Refresh note list\n    // Reset navigation history\n  });\n}, []);\n```\n\n### Edge Cases\n- Current note doesn't exist in new vault → show welcome state\n- Switch fails mid-operation → attempt rollback\n- Large vault → show loading indicator during reindex\n\n## Risk Assessment\n- **High Complexity**: Engine lifecycle management\n- **Testing Critical**: Need extensive integration tests\n- **Rollback Difficult**: If switch fails partially\n\n## Recommendation\nImplement only after restart-based switching is stable and well-tested. Consider this for v1.1 or later.\n\n## Files\n- apps/desktop/electron/main/src/EngineOrchestrator.ts\n- apps/desktop/electron/main/src/handlers/vaultHandlers.ts\n- packages/shared/src/ipc-contract.ts (vault:switched event)","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T15:06:57.582811-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.2","title":"Add folder picker IPC handler (dialog:selectFolder)","description":"# Add Folder Picker IPC Handler (dialog:selectFolder)\n\n## What\nAdd a new IPC channel that opens the native OS folder picker dialog and returns the selected path.\n\n## Why\n- **Required for Vault Management**: Users need to select folders when changing vault location or creating new vaults\n- **No Existing Handler**: The current IPC contract doesn't include folder/file dialogs\n- **Security**: Renderer process can't access dialog.showOpenDialog directly due to sandboxing\n\n## Technical Approach\n\n### IPC Contract Addition\n```typescript\n// In packages/shared/src/ipc-contract.ts\nexport const IPC_CHANNELS = {\n  // ... existing channels\n  DIALOG_SELECT_FOLDER: 'dialog:selectFolder',\n} as const;\n\n// Add to ScribeAPI interface\nexport interface DialogAPI {\n  selectFolder(options?: { title?: string; defaultPath?: string }): Promise\u003cstring | null\u003e;\n}\n```\n\n### Main Process Handler\n```typescript\n// In apps/desktop/electron/main/src/handlers/dialogHandlers.ts\nimport { dialog } from 'electron';\nimport { IPC_CHANNELS } from '@scribe/shared';\n\nexport function registerDialogHandlers(): void {\n  ipcMain.handle(\n    IPC_CHANNELS.DIALOG_SELECT_FOLDER,\n    async (_, options?: { title?: string; defaultPath?: string }) =\u003e {\n      const result = await dialog.showOpenDialog({\n        title: options?.title ?? 'Select Folder',\n        defaultPath: options?.defaultPath,\n        properties: ['openDirectory', 'createDirectory'],\n      });\n      \n      if (result.canceled || result.filePaths.length === 0) {\n        return null;\n      }\n      \n      return result.filePaths[0];\n    }\n  );\n}\n```\n\n### Preload Bridge\n```typescript\n// Add to window.scribe in preload.ts\ndialog: {\n  selectFolder: (options?: { title?: string; defaultPath?: string }) =\u003e\n    ipcRenderer.invoke(IPC_CHANNELS.DIALOG_SELECT_FOLDER, options),\n}\n```\n\n### Options\n- `title`: Dialog window title (default: \"Select Folder\")\n- `defaultPath`: Initial directory to display (useful for showing current vault path)\n- `properties`: `openDirectory` (folders only), `createDirectory` (allow new folder button)\n\n### Return Value\n- `string`: Absolute path to selected folder\n- `null`: User cancelled the dialog\n\n### Platform Considerations\n- macOS: Native NSOpenPanel\n- Windows: Native folder browser\n- Linux: GTK file chooser (if available)\n\n## Parallel Safe\nYes - no dependencies on other tasks.\n\n## Files\n- packages/shared/src/ipc-contract.ts\n- apps/desktop/electron/main/src/handlers/dialogHandlers.ts (NEW)\n- apps/desktop/electron/preload/src/preload.ts\n- apps/desktop/electron/main/src/main.ts (register handlers)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T14:56:09.954885-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.20","title":"Add SettingsIcon to design system icons","description":"# Add SettingsIcon to Design System\n\n## What\nExport the Settings (gear/cog) icon from Lucide React in the design system icons.\n\n## Why\n- **Required for scribe-roo.4**: The sidebar gear icon needs this icon\n- **Common Pattern**: Settings icon will be used in multiple places\n\n## Implementation\n```typescript\n// In packages/design-system/src/icons/icons.ts (or index.ts)\nexport { Settings as SettingsIcon } from 'lucide-react';\n```\n\nOr if using a custom mapping:\n```typescript\n// Add to the exports\nSettingsIcon,\n```\n\n## Verification\nLucide React has the Settings icon (gear/cog shape). Verify it exists:\nhttps://lucide.dev/icons/settings\n\n## Files\n- packages/design-system/src/icons/index.ts (add export)\n\n## Parallel Safe\nYES - no dependencies.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T15:08:43.778268-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.21","title":"Add app:relaunch IPC handler for vault switching restart","description":"# Add app:relaunch IPC Handler\n\n## What\nAdd an IPC handler that relaunches the Electron app. Required for vault switching to take effect.\n\n## Why\n- **Vault Switching Requires Restart**: The restart-based vault switching approach (scribe-roo.14) needs a way to restart the app\n- **No Existing Handler**: There's currently no IPC channel for app.relaunch()\n- **Clean Restart**: app.relaunch() + app.exit() provides a clean restart\n\n## Technical Approach\n\n### IPC Contract\n```typescript\n// In packages/shared/src/ipc-contract.ts\nexport const IPC_CHANNELS = {\n  // ... existing\n  APP_RELAUNCH: 'app:relaunch',\n} as const;\n```\n\n### Main Process Handler\n```typescript\n// In appHandlers.ts\nipcMain.handle(IPC_CHANNELS.APP_RELAUNCH, () =\u003e {\n  app.relaunch();\n  app.exit(0);\n});\n```\n\n### Preload Bridge\n```typescript\n// Add to window.scribe.app\napp: {\n  // ... existing\n  relaunch: () =\u003e ipcRenderer.invoke(IPC_CHANNELS.APP_RELAUNCH),\n}\n```\n\n## Files\n- packages/shared/src/ipc-contract.ts\n- apps/desktop/electron/main/src/handlers/appHandlers.ts\n- apps/desktop/electron/preload/src/preload.ts\n\n## Parallel Safe\nYES - No dependencies on other Settings tasks. Can be done alongside scribe-roo.2 and scribe-roo.3.","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T15:11:37.305926-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.3","title":"Add vault IPC handlers (vault:getPath, vault:setPath, vault:create)","description":"# Add Vault IPC Handlers (vault:getPath, vault:setPath, vault:create)\n\n## What\nAdd IPC channels for vault management: reading current path, switching vaults, and creating new vaults.\n\n## Why\n- **Settings Page Requirement**: Users need to see their current vault location and optionally change it\n- **Multi-Vault Support Foundation**: Enables users to work with different vaults\n- **New User Onboarding**: Creating a vault is essential for first-time setup\n\n## Technical Approach\n\n### IPC Contract Additions\n```typescript\n// In packages/shared/src/ipc-contract.ts\nexport const IPC_CHANNELS = {\n  // ... existing\n  VAULT_GET_PATH: 'vault:getPath',\n  VAULT_SET_PATH: 'vault:setPath',\n  VAULT_CREATE: 'vault:create',\n  VAULT_VALIDATE: 'vault:validate',\n} as const;\n\nexport interface VaultAPI {\n  getPath(): Promise\u003cstring\u003e;\n  setPath(path: string): Promise\u003cVaultSwitchResult\u003e;\n  create(path: string): Promise\u003cVaultCreateResult\u003e;\n  validate(path: string): Promise\u003cVaultValidationResult\u003e;\n}\n\nexport interface VaultSwitchResult {\n  success: boolean;\n  path: string;\n  error?: string;\n}\n\nexport interface VaultCreateResult {\n  success: boolean;\n  path: string;\n  error?: string;\n}\n\nexport interface VaultValidationResult {\n  valid: boolean;\n  missingDirs?: string[];\n}\n```\n\n### Handler Implementations\n\n#### vault:getPath\nSimply returns the current vault path from EngineOrchestrator or config.\n\n#### vault:validate\nUses existing `isValidVault()` from storage-fs to check if path is valid vault.\n\n#### vault:setPath (Complex - See scribe-roo.14)\nThis is the complex one that requires engine hot-reload. Initial implementation:\n1. Validate the new path is a valid vault\n2. If invalid, return error\n3. If valid, update config and notify renderer\n4. Full engine hot-reload handled in separate task (scribe-roo.14)\n\n#### vault:create\nUses existing `initializeVault()` from storage-fs:\n1. Validate path doesn't already contain a vault\n2. Call `initializeVault(path)` to create structure\n3. Optionally switch to the new vault\n\n### AppConfig Extension\n```typescript\n// In apps/desktop/electron/main/src/handlers/types.ts\nexport interface AppConfig {\n  lastOpenedNoteId?: string;\n  theme?: 'light' | 'dark' | 'system';\n  vaultPath?: string;  // NEW - stores current vault location\n}\n```\n\n### Error Handling\n- Invalid path: Return `{ success: false, error: 'Path does not exist' }`\n- Not a vault: Return `{ success: false, error: 'Not a valid Scribe vault. Missing required folders.' }`\n- Permission denied: Return `{ success: false, error: 'Permission denied' }`\n- Path already exists (for create): Return `{ success: false, error: 'Vault already exists at this location' }`\n\n## Dependencies\n- scribe-roo.14 (Engine hot-reload) - Full vault switching implementation depends on this\n\n## Parallel Safe\nPartially - Basic handlers can be built independently, but full vault switching needs scribe-roo.14.\n\n## Files\n- packages/shared/src/ipc-contract.ts\n- apps/desktop/electron/main/src/handlers/vaultHandlers.ts (NEW)\n- apps/desktop/electron/preload/src/preload.ts\n- apps/desktop/electron/main/src/handlers/types.ts (AppConfig extension)\n- apps/desktop/electron/main/src/main.ts (register handlers)","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T14:56:10.026087-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.4","title":"Replace sidebar footer with settings gear icon","description":"# Replace Sidebar Footer with Settings Gear Icon\n\n## What\nRemove the current sidebar footer (avatar, \"Guest User\", version indicator, theme toggle) and replace it with a minimal settings gear icon button.\n\n## Why\n- **Settings Access Point**: The gear icon is the entry point to the Settings page\n- **Cleaner UI**: Current footer is cluttered; settings belong in a dedicated page\n- **Familiar Pattern**: Gear icon for settings is a universal UI convention\n\n## Current Footer Structure (to be replaced)\n```tsx\n// Current footer in Sidebar.tsx\n\u003cdiv className={footerSection}\u003e\n  \u003cdiv className={footerUser}\u003e\n    \u003cimg src={avatarPlaceholder} className={footerAvatar} /\u003e\n    \u003cspan className={footerUsername}\u003eGuest User\u003c/span\u003e\n  \u003c/div\u003e\n  \u003cdiv className={footerControls}\u003e\n    \u003cspan className={versionIndicator}\u003ev{__APP_VERSION__}\u003c/span\u003e\n    \u003cbutton onClick={onThemeToggle}\u003e\n      {currentTheme === 'dark' ? \u003cSunIcon /\u003e : \u003cMoonIcon /\u003e}\n    \u003c/button\u003e\n  \u003c/div\u003e\n\u003c/div\u003e\n```\n\n## New Footer Structure\n```tsx\n\u003cdiv className={footerSection}\u003e\n  \u003cbutton \n    className={settingsButton}\n    onClick={onOpenSettings}\n    aria-label=\"Open settings\"\n  \u003e\n    \u003cSettingsIcon size={20} /\u003e\n  \u003c/button\u003e\n\u003c/div\u003e\n```\n\n## Technical Changes\n\n### Props Update\n```typescript\n// Remove from SidebarProps\n- onThemeToggle: () =\u003e void;\n- currentTheme: 'light' | 'dark';\n\n// Add to SidebarProps\n+ onOpenSettings: () =\u003e void;\n```\n\n### CSS Updates\n- Keep footerSection styling (positioning at bottom)\n- Remove footerUser, footerAvatar, footerUsername, footerControls styles\n- Add settingsButton style (centered, hover state, icon sizing)\n\n### Icon\nUse existing `SettingsIcon` from design system, or add one if missing. Fallback to a gear SVG:\n```tsx\n// Gear icon (cog) - common settings icon\n\u003csvg viewBox=\"0 0 24 24\" fill=\"none\" stroke=\"currentColor\"\u003e\n  \u003cpath d=\"M12 15a3 3 0 100-6 3 3 0 000 6z\" /\u003e\n  \u003cpath d=\"M19.4 15a1.65 1.65 0 00.33 1.82l...\" /\u003e\n\u003c/svg\u003e\n```\n\n### App.tsx Integration\nThe Sidebar already receives callbacks from App.tsx. Add `onOpenSettings` that calls `setIsSettingsOpen(true)` (state managed by useSettingsPage hook).\n\n## Considerations\n- **Version Display**: Moves to Settings \u003e General section\n- **Theme Toggle**: Moves to Settings \u003e General section\n- **Guest User**: Can be removed entirely (no login system yet)\n- **Tooltip**: Consider adding \"Settings\" tooltip on hover\n\n## Parallel Safe\nYes - no dependencies on other tasks. Can be built before SettingsPage exists (just need the onClick handler stub).\n\n## Files\n- apps/desktop/renderer/src/components/Sidebar/Sidebar.tsx\n- apps/desktop/renderer/src/components/Sidebar/Sidebar.css.ts","status":"tombstone","priority":1,"issue_type":"task","created_at":"2025-12-23T14:56:10.095631-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.5","title":"Create SettingsPage modal shell with sidebar layout","description":"# Create SettingsPage Modal Shell with Sidebar Layout\n\n## What\nBuild the main SettingsPage component: a full-screen modal with a VS Code/macOS Settings-style sidebar navigation pattern. This task includes:\n- The useSettingsPage hook (previously scribe-roo.6)\n- The ChangelogSettings placeholder section (previously scribe-roo.9)\n\nBoth are trivially small and tightly coupled to this shell.\n\n## Why\n- **Core UI Container**: This is the main shell that houses all settings sections\n- **UX Pattern**: Sidebar + content area is the most scalable pattern for settings\n- **Reuses Overlay**: Leverages existing design system Overlay primitive for modal behavior\n\n## Technical Approach\n\n### useSettingsPage Hook (inline with component)\n```typescript\nexport type SettingsSection = 'general' | 'changelog';\n\nexport function useSettingsPage() {\n  const [isOpen, setIsOpen] = useState(false);\n  const [activeSection, setActiveSection] = useState\u003cSettingsSection\u003e('general');\n  \n  const open = useCallback(() =\u003e {\n    setIsOpen(true);\n    setActiveSection('general');\n  }, []);\n  \n  const close = useCallback(() =\u003e setIsOpen(false), []);\n  \n  return { isOpen, open, close, activeSection, setActiveSection };\n}\n```\n\n### ChangelogSettings (placeholder)\n```tsx\nexport function ChangelogSettings() {\n  return (\n    \u003cdiv className={styles.changelogSettings}\u003e\n      \u003cText variant=\"heading3\"\u003eChangelog\u003c/Text\u003e\n      \u003cText variant=\"body\" color=\"muted\"\u003e\n        Release notes and version history will appear here in a future update.\n      \u003c/Text\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Component Structure\n```tsx\nexport function SettingsPage({ isOpen, onClose }: SettingsPageProps) {\n  const [activeSection, setActiveSection] = useState\u003cSettingsSection\u003e('general');\n  \n  if (!isOpen) return null;\n  \n  return (\n    \u003cOverlay open={isOpen} onClose={onClose} closeOnEscape\u003e\n      \u003cSurface className={styles.settingsContainer}\u003e\n        \u003cheader className={styles.header}\u003e\n          \u003cText variant=\"heading2\"\u003eSettings\u003c/Text\u003e\n          \u003cbutton onClick={onClose} aria-label=\"Close settings\"\u003e\u003cXIcon /\u003e\u003c/button\u003e\n        \u003c/header\u003e\n        \u003cdiv className={styles.content}\u003e\n          \u003cSettingsSidebar activeSection={activeSection} onSelect={setActiveSection} /\u003e\n          \u003cmain className={styles.mainContent}\u003e\n            {activeSection === 'general' \u0026\u0026 \u003cGeneralSettings /\u003e}\n            {activeSection === 'changelog' \u0026\u0026 \u003cChangelogSettings /\u003e}\n          \u003c/main\u003e\n        \u003c/div\u003e\n      \u003c/Surface\u003e\n    \u003c/Overlay\u003e\n  );\n}\n```\n\n### Layout (sidebar + content, VS Code pattern)\n- Full viewport (100vw x 100vh)\n- Sidebar: ~200px fixed width\n- Content: Flex grow, scrollable\n- Header: Fixed top with title + close button\n\n### Files to Create\n- SettingsPage.tsx (component + hook)\n- SettingsPage.css.ts\n- SettingsSidebar.tsx + css\n- ChangelogSettings.tsx (simple placeholder)\n- index.ts (barrel export)\n\n## Parallel Safe\nYES - No dependencies. Can be built independently of the gear icon.\n\n## Files\n- apps/desktop/renderer/src/components/Settings/SettingsPage.tsx (NEW)\n- apps/desktop/renderer/src/components/Settings/SettingsPage.css.ts (NEW)\n- apps/desktop/renderer/src/components/Settings/SettingsSidebar.tsx (NEW)\n- apps/desktop/renderer/src/components/Settings/ChangelogSettings.tsx (NEW)\n- apps/desktop/renderer/src/hooks/useSettingsPage.ts (NEW)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.16838-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.6","title":"Create useSettingsPage hook for state management","description":"# Create useSettingsPage Hook for State Management\n\n## What\nCreate a custom hook to manage Settings page state: open/close, active section, and any transient settings state.\n\n## Why\n- **Centralized State**: Keep settings-related state in one place\n- **Reusability**: Can be used from App.tsx and passed down\n- **Separation of Concerns**: UI logic separate from component rendering\n- **Future Expansion**: Easy to add more state (unsaved changes warning, etc.)\n\n## Technical Approach\n\n### Hook API\n```typescript\n// useSettingsPage.ts\nexport type SettingsSection = 'general' | 'changelog';\n\nexport interface UseSettingsPageReturn {\n  // Modal state\n  isOpen: boolean;\n  open: () =\u003e void;\n  close: () =\u003e void;\n  toggle: () =\u003e void;\n  \n  // Section navigation\n  activeSection: SettingsSection;\n  setActiveSection: (section: SettingsSection) =\u003e void;\n}\n\nexport function useSettingsPage(): UseSettingsPageReturn {\n  const [isOpen, setIsOpen] = useState(false);\n  const [activeSection, setActiveSection] = useState\u003cSettingsSection\u003e('general');\n  \n  const open = useCallback(() =\u003e {\n    setIsOpen(true);\n    setActiveSection('general'); // Reset to default on open\n  }, []);\n  \n  const close = useCallback(() =\u003e {\n    setIsOpen(false);\n  }, []);\n  \n  const toggle = useCallback(() =\u003e {\n    setIsOpen(prev =\u003e !prev);\n  }, []);\n  \n  return {\n    isOpen,\n    open,\n    close,\n    toggle,\n    activeSection,\n    setActiveSection,\n  };\n}\n```\n\n### Usage in App.tsx\n```tsx\nfunction App() {\n  const settings = useSettingsPage();\n  \n  return (\n    \u003cdiv className={styles.app}\u003e\n      \u003cSidebar \n        onOpenSettings={settings.open}\n        // ... other props\n      /\u003e\n      \n      \u003cSettingsPage \n        isOpen={settings.isOpen}\n        onClose={settings.close}\n        activeSection={settings.activeSection}\n        onSelectSection={settings.setActiveSection}\n      /\u003e\n      \n      {/* ... rest of app */}\n    \u003c/div\u003e\n  );\n}\n```\n\n### Future Extensions\nThis hook can be extended to support:\n- **Dirty state tracking**: Warn before closing with unsaved changes\n- **Keyboard shortcuts**: Cmd+, to open settings\n- **Deep linking**: Open to specific section (e.g., from toast \"Update Settings\")\n- **History**: Remember last visited section\n\n### Potential Addition: Keyboard Shortcut\n```typescript\n// Inside the hook\nuseEffect(() =\u003e {\n  const handleKeyDown = (e: KeyboardEvent) =\u003e {\n    // Cmd+, (macOS) or Ctrl+, (Windows/Linux) opens settings\n    if ((e.metaKey || e.ctrlKey) \u0026\u0026 e.key === ',') {\n      e.preventDefault();\n      toggle();\n    }\n  };\n  \n  window.addEventListener('keydown', handleKeyDown);\n  return () =\u003e window.removeEventListener('keydown', handleKeyDown);\n}, [toggle]);\n```\n\n## Parallel Safe\nYes - no dependencies. Can be built independently.\n\n## Files\n- apps/desktop/renderer/src/hooks/useSettingsPage.ts (NEW)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.237266-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.7","title":"Integrate SettingsPage into App.tsx","description":"# Integrate SettingsPage into App.tsx\n\n## What\nWire up the SettingsPage component and useSettingsPage hook into the main App.tsx, connecting it to the sidebar gear icon.\n\n## Why\n- **Entry Point Connection**: Links the gear icon click to opening settings\n- **State Hosting**: App.tsx is the appropriate level to host settings state\n- **Coordinated Rendering**: Settings modal needs to render at the app level to overlay everything\n\n## Technical Approach\n\n### App.tsx Changes\n```tsx\n// App.tsx\nimport { SettingsPage } from './components/Settings';\nimport { useSettingsPage } from './hooks/useSettingsPage';\n\nfunction App() {\n  // ... existing hooks\n  const settings = useSettingsPage();\n  \n  return (\n    \u003cdiv className={styles.app}\u003e\n      \u003cdiv className={styles.titlebarDragRegion} /\u003e\n      \n      \u003cErrorBoundary name=\"Sidebar\"\u003e\n        \u003cSidebar \n          // ... existing props\n          onOpenSettings={settings.open}  // NEW: replace onThemeToggle\n          // REMOVE: onThemeToggle, currentTheme\n        /\u003e\n      \u003c/ErrorBoundary\u003e\n      \n      {/* Main content area */}\n      \u003cEditorCommandProvider\u003e\n        \u003cdiv className={styles.mainContent}\u003e\n          {/* ... existing content */}\n        \u003c/div\u003e\n      \u003c/EditorCommandProvider\u003e\n      \n      {/* Settings modal - renders at app level to overlay everything */}\n      \u003cSettingsPage \n        isOpen={settings.isOpen}\n        onClose={settings.close}\n      /\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Remove Theme Toggle Props\nSince theme toggle moves to Settings, remove from Sidebar props:\n```typescript\n// Before\n\u003cSidebar\n  onThemeToggle={() =\u003e setTheme(resolvedTheme === 'dark' ? 'light' : 'dark')}\n  currentTheme={resolvedTheme}\n  // ...\n/\u003e\n\n// After\n\u003cSidebar\n  onOpenSettings={settings.open}\n  // ...\n/\u003e\n```\n\n### Rendering Order\nSettingsPage should render AFTER the main content but is a portal-based overlay, so order in JSX doesn't strictly matter. However, for clarity:\n```tsx\n{/* Main app UI */}\n\u003cSidebar ... /\u003e\n\u003cmain ... /\u003e\n\n{/* Overlays (render last for z-index clarity) */}\n\u003cCommandPalette ... /\u003e\n\u003cSettingsPage ... /\u003e\n\u003cToast ... /\u003e\n```\n\n### ErrorBoundary\nConsider wrapping SettingsPage in ErrorBoundary:\n```tsx\n\u003cErrorBoundary name=\"Settings\"\u003e\n  \u003cSettingsPage ... /\u003e\n\u003c/ErrorBoundary\u003e\n```\n\n## BLOCKED BY\n- scribe-roo.4 (Sidebar gear icon) - Need onOpenSettings prop\n- scribe-roo.5 (SettingsPage shell) - Need component to render\n- scribe-roo.6 (useSettingsPage hook) - Need state management\n\n## Files\n- apps/desktop/renderer/src/App.tsx","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.306119-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.8","title":"Implement GeneralSettings section structure","description":"# Implement GeneralSettings Section Structure\n\n## What\nBuild the GeneralSettings component that contains Vault Location, Version, and Theme settings.\n\n## Why\n- **Main Settings Section**: General is the default and most important section\n- **Organizes Related Settings**: Groups vault, version, and theme logically\n- **Foundation for Functionality**: This structure enables the actual setting implementations\n\n## Technical Approach\n\n### Component Structure\n```tsx\n// GeneralSettings.tsx\nexport function GeneralSettings() {\n  return (\n    \u003cdiv className={styles.generalSettings}\u003e\n      \u003cSettingsGroup title=\"Vault Location\"\u003e\n        \u003cVaultLocationSetting /\u003e\n      \u003c/SettingsGroup\u003e\n      \n      \u003cSettingsGroup title=\"Version\"\u003e\n        \u003cVersionSetting /\u003e\n      \u003c/SettingsGroup\u003e\n      \n      \u003cSettingsGroup title=\"Theme\"\u003e\n        \u003cThemeSetting /\u003e\n      \u003c/SettingsGroup\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### SettingsGroup Helper\n```tsx\n// SettingsGroup - reusable container for each setting\ninterface SettingsGroupProps {\n  title: string;\n  description?: string;\n  children: ReactNode;\n}\n\nfunction SettingsGroup({ title, description, children }: SettingsGroupProps) {\n  return (\n    \u003csection className={styles.settingsGroup}\u003e\n      \u003cdiv className={styles.settingsGroupHeader}\u003e\n        \u003cText variant=\"label\" className={styles.settingsGroupTitle}\u003e{title}\u003c/Text\u003e\n        {description \u0026\u0026 (\n          \u003cText variant=\"body\" color=\"muted\"\u003e{description}\u003c/Text\u003e\n        )}\n      \u003c/div\u003e\n      \u003cdiv className={styles.settingsGroupContent}\u003e\n        {children}\n      \u003c/div\u003e\n    \u003c/section\u003e\n  );\n}\n```\n\n### Layout Pattern\n```\nVault Location\n------------------------------------------------\n/Users/erik/Scribe/vault\n[Change]  [Create New]\n\nVersion\n------------------------------------------------\nv1.2.3\n[Check for Updates]\n\nTheme\n------------------------------------------------\n[Dark | Light | System]\n```\n\n### Styling\n```typescript\n// GeneralSettings.css.ts\nexport const generalSettings = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[8],  // Large gap between groups\n});\n\nexport const settingsGroup = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[3],\n});\n\nexport const settingsGroupHeader = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[1],\n  borderBottom: `1px solid ${vars.color.border}`,\n  paddingBottom: vars.spacing[2],\n});\n\nexport const settingsGroupContent = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[2],\n});\n```\n\n### Placeholder Content (Initial)\nInitially, each setting can be a placeholder:\n```tsx\nfunction VaultLocationSetting() {\n  return (\n    \u003cdiv\u003e\n      \u003cText variant=\"body\" color=\"muted\"\u003eLoading vault path...\u003c/Text\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n## BLOCKED BY\n- scribe-roo.5 (SettingsPage shell) - Needs to render inside SettingsPage\n\n## UNBLOCKS\n- scribe-roo.10 (Theme setting)\n- scribe-roo.11 (Version/Update setting)\n- scribe-roo.13 (Vault display)\n\n## Files\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.tsx (NEW)\n- apps/desktop/renderer/src/components/Settings/GeneralSettings.css.ts (NEW)","status":"tombstone","priority":2,"issue_type":"task","created_at":"2025-12-23T14:56:10.374812-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
{"id":"scribe-roo.9","title":"Create ChangelogSettings placeholder section","description":"# Create ChangelogSettings Placeholder Section\n\n## What\nCreate a placeholder Changelog section that displays \"Coming soon\" or similar placeholder content.\n\n## Why\n- **Spec Requirement**: The spec explicitly includes Changelog as a section (placeholder for now)\n- **UI Completeness**: Users can see the section exists even if not functional\n- **Future Foundation**: Easy to implement actual changelog later\n\n## Technical Approach\n\n### Simple Placeholder\n```tsx\n// ChangelogSettings.tsx\nimport { Text } from '@scribe/design-system';\nimport * as styles from './ChangelogSettings.css';\n\nexport function ChangelogSettings() {\n  return (\n    \u003cdiv className={styles.changelogSettings}\u003e\n      \u003cText variant=\"heading3\"\u003eChangelog\u003c/Text\u003e\n      \u003cText variant=\"body\" color=\"muted\"\u003e\n        Release notes and version history will appear here in a future update.\n      \u003c/Text\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Alternative: Fetch from CHANGELOG.md\nFor a more useful placeholder, could display the CHANGELOG.md content:\n```tsx\nexport function ChangelogSettings() {\n  // Could fetch CHANGELOG.md content and render as markdown\n  // For now, just placeholder\n  return (\n    \u003cdiv className={styles.changelogSettings}\u003e\n      \u003cText variant=\"heading3\"\u003eWhat's New\u003c/Text\u003e\n      \u003cdiv className={styles.placeholder}\u003e\n        \u003cText variant=\"body\" color=\"muted\"\u003e\n          Changelog coming soon. For now, see release notes on GitHub.\n        \u003c/Text\u003e\n        \u003cButton \n          variant=\"secondary\" \n          onClick={() =\u003e window.scribe.shell.openExternal('https://github.com/scribe/releases')}\n        \u003e\n          View on GitHub\n        \u003c/Button\u003e\n      \u003c/div\u003e\n    \u003c/div\u003e\n  );\n}\n```\n\n### Styling\n```typescript\n// ChangelogSettings.css.ts\nexport const changelogSettings = style({\n  display: 'flex',\n  flexDirection: 'column',\n  gap: vars.spacing[4],\n});\n\nexport const placeholder = style({\n  display: 'flex',\n  flexDirection: 'column',\n  alignItems: 'flex-start',\n  gap: vars.spacing[3],\n  padding: vars.spacing[6],\n  backgroundColor: vars.color.backgroundAlt,\n  borderRadius: vars.radius.md,\n});\n```\n\n## Low Priority\nThis is P3 as it's just a placeholder. Can be implemented quickly after the main settings structure is in place.\n\n## BLOCKED BY\n- scribe-roo.5 (SettingsPage shell) - Needs to render inside SettingsPage\n\n## Files\n- apps/desktop/renderer/src/components/Settings/ChangelogSettings.tsx (NEW)\n- apps/desktop/renderer/src/components/Settings/ChangelogSettings.css.ts (NEW, optional)","status":"tombstone","priority":3,"issue_type":"task","created_at":"2025-12-23T14:56:10.443953-06:00","updated_at":"2025-12-27T21:23:28.900336-06:00","deleted_at":"2025-12-27T21:23:28.900336-06:00","deleted_by":"batch delete","delete_reason":"batch delete","original_type":"task"}
